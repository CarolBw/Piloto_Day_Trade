{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXHMLxtWZFb2KUcDNmCAC7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolBw/Piloto_Day_Trade/blob/main/Piloto_Day_Trade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/MVP_Objetivo.md\n",
        "#@title **Objetivo do Projeto**\n",
        "\n",
        "### 1. Prop√≥sito do MVP\n",
        "\n",
        "Este projeto tem como objetivo principal a cria√ß√£o de um pipeline para extra√ß√£o, transforma√ß√£o, carga, an√°lise e previs√£o da movimenta√ß√£o intradi√°ria dos pre√ßos de um ativo financeiro em intervalos de 5 minutos. O modelo preditivo central ser√° baseado em redes neurais recorrentes (LSTM), mas outras abordagens ser√£o exploradas. O MVP visa garantir previs√µes para embasar decis√µes estrat√©gicas de day trade.\n",
        "\n",
        "### 2. Problema a Ser Resolvido\n",
        "\n",
        "A alta volatilidade dos mercados financeiros exige ferramentas robustas para antecipa√ß√£o de movimentos de pre√ßo. A dificuldade est√° em capturar padr√µes de curto prazo e projet√°-los com precis√£o. Traders e investidores necessitam de um modelo que consiga interpretar os padr√µes hist√≥ricos e transform√°-los em previs√µes √∫teis.\n",
        "\n",
        "### 3. Pipeline do Projeto\n",
        "\n",
        "O projeto ser√° estruturado em sete etapas principais:\n",
        "\n",
        "1. **Extra√ß√£o e armazenamento dos dados brutos:** Coleta de dados hist√≥ricos de ativos financeiros em intervalos de 15 minutos utilizando a API do Yahoo Finance (yfinance). Os dados ser√£o armazenados em um reposit√≥rio GitHub sincronizado com Google Colab, garantindo acesso remoto e backup na nuvem.\n",
        "\n",
        "2. **Limpeza e organiza√ß√£o dos dados:** Padroniza√ß√£o de colunas, tratamento de dados ausentes, elimina√ß√£o de duplicatas e organiza√ß√£o cronol√≥gica. Resultado salvo como `dados_limpos.csv`.\n",
        "\n",
        "3. **Transforma√ß√£o e engenharia de features:** Adi√ß√£o de indicadores t√©cnicos (como m√©dias m√≥veis, RSI, MACD), cria√ß√£o de vari√°veis de lag e retornos. Resultado salvo como `dados_transformados.csv`.\n",
        "\n",
        "4. **Modelagem e estrutura√ß√£o do banco de dados:**\n",
        "\n",
        "   a) Organiza√ß√£o em arquivos CSV:\n",
        "\n",
        "   - `dados_brutos.csv`: dados originais extra√≠dos da API.\n",
        "   - `dados_limpos.csv`: ap√≥s limpeza e padroniza√ß√£o.\n",
        "   - `dados_transformados.csv`: ap√≥s adi√ß√£o de features t√©cnicas.\n",
        "   - `dados_final.csv`: vers√£o padronizada e normalizada dos dados.\n",
        "\n",
        "   b) Banco de dados dimensional:\n",
        "\n",
        "   - **Fato**: `fato_precos`, contendo os valores de fechamento e chaves para dimens√µes.\n",
        "   - **Dimens√µes**:\n",
        "     - `dim_tempo`: atributos temporais.\n",
        "     - `dim_indicadores`: indicadores t√©cnicos.\n",
        "     - `dim_lags`: varia√ß√µes e lags recentes.\n",
        "\n",
        "   Um **Cat√°logo de Dados** ser√° elaborado com descri√ß√£o, dom√≠nio, categorias e linhagem de cada vari√°vel.\n",
        "\n",
        "5. **Carga e Pipeline ETL:** Pipeline estruturado com as seguintes etapas:\n",
        "\n",
        "   - **Extra√ß√£o:** via API do Yahoo Finance.\n",
        "   - **Limpeza:** tratamento e estrutura√ß√£o b√°sica.\n",
        "   - **Transforma√ß√£o:** gera√ß√£o de vari√°veis t√©cnicas e derivadas.\n",
        "   - **Carga:** integra√ß√£o dos dados transformados no banco dimensional (fato e dimens√µes).\n",
        "\n",
        "6. **Treinamento e ajuste do modelo:** Implementa√ß√£o e ajuste de modelos preditivos (LSTM como baseline), com avalia√ß√£o por m√©tricas como MSE e R¬≤.\n",
        "\n",
        "7. **Interpreta√ß√£o dos resultados e resposta √†s perguntas:** Valida√ß√£o das previs√µes, an√°lise de vari√°veis relevantes e contribui√ß√£o dos resultados para decis√µes de trading.\n",
        "\n",
        "### 4. Perguntas a Serem Respondidas\n",
        "\n",
        "- √â poss√≠vel prever com precis√£o a movimenta√ß√£o intradi√°ria de um ativo a cada 15 minutos?\n",
        "- Os dados do dia anterior fornecem informa√ß√µes suficientes para a previs√£o do dia seguinte?\n",
        "- A modelagem com LSTM captura corretamente as tend√™ncias de curto prazo?\n",
        "- A previs√£o da movimenta√ß√£o intradi√°ria tamb√©m permite derivar com precis√£o as targets globais do dia (abertura, m√≠nima, m√°xima e fechamento)?\n",
        "- Quais indicadores t√©cnicos e features s√£o mais relevantes para melhorar a acur√°cia do modelo?\n",
        "- Como considerar corretamente as quebras de fim de semana (exemplo: prever a segunda-feira usando os dados de sexta-feira)?\n",
        "- A normaliza√ß√£o e padroniza√ß√£o das vari√°veis melhora a precis√£o do modelo?\n",
        "\n",
        "### 5. Crit√©rios de Sucesso\n",
        "\n",
        "Para que o MVP seja considerado bem-sucedido o esperado √© que:\n",
        "\n",
        "1. O pipeline de extra√ß√£o, transforma√ß√£o e previs√£o funcione de forma eficiente.\n",
        "2. O modelo consiga prever a movimenta√ß√£o dos pre√ßos com um erro m√©dio aceit√°vel (avaliado por MSE ou R2).\n",
        "3. A previs√£o de targets globais (abertura, m√°xima, m√≠nima, fechamento) seja consistente com os valores reais.\n",
        "4. O modelo consiga lidar corretamente com fins de semana e feriados.\n",
        "5. As previs√µes sejam suficientes para auxiliar na tomada de decis√£o de trading.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj0A_HHDW-dj",
        "outputId": "348639af-f378-4de3-a892-f885ffd4b4d7",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/MVP_Objetivo.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "No6u9fG0h8-A",
        "outputId": "5ef92609-2fc7-4899-8506-2fe3d9877742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.env\n"
          ]
        }
      ],
      "source": [
        "#@title ## Escrevendo vari√°veis sensiveis\n",
        "\n",
        "%%writefile /content/.env\n",
        "\n",
        "PROJECT_NAME=Piloto_Day_Trade\n",
        "\n",
        "# Vari√°veis de ambiente para o Github\n",
        "GITHUB_USERNAME=CarolBw\n",
        "GITHUB_TOKEN =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\n",
        "EMAIL=carolbrescowitt@yahoo.com.br\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Instalando depend√™ncias\n",
        "'''\n",
        "Usamos `-q` para ocultar a sa√≠da detalhada e mostrar apenas a barra de progresso\n",
        "\n",
        "'''\n",
        "!pip install -q tensorflow > /dev/null  # Framework para redes neurais e deep learning\n",
        "!pip install -q keras > /dev/null  # Biblioteca de alto n√≠vel para redes neurais\n",
        "!pip install -q pandas > /dev/null  # Manipula√ß√£o e an√°lise de dados\n",
        "!pip install -q numpy > /dev/null  # Computa√ß√£o num√©rica eficiente\n",
        "!pip install -q matplotlib > /dev/null  # Visualiza√ß√£o de gr√°ficos e an√°lise explorat√≥ria\n",
        "!pip install -q scikit-learn > /dev/null  # Ferramentas para pr√©-processamento e m√©tricas de avalia√ß√£o\n",
        "!pip install -q gitpython > /dev/null  # Gerenciamento de reposit√≥rios Git via Python\n",
        "!pip install -q python-dotenv > /dev/null  # Manipula√ß√£o de vari√°veis de ambiente\n",
        "!pip install -q seaborn > /dev/null  # Biblioteca de visualiza√ß√£o estat√≠stica baseada no Matplotlib\n",
        "!pip install -q yfinance > /dev/null  # Coleta de dados financeiros diretamente do Yahoo Finance\n",
        "!pip install -q sqlalchemy > /dev/null  # ORM para interagir com bancos de dados relacionais\n",
        "!pip install -q dotenv > /dev/null # Manipula√ß√£o de vari√°veis de ambiente\n",
        "\n",
        "# Importa√ß√µes das bibliotecas\n",
        "import pandas as pd  # Manipula√ß√£o de DataFrames\n",
        "import numpy as np  # C√°lculos num√©ricos e matrizes\n",
        "import matplotlib.pyplot as plt  # Gera√ß√£o de gr√°ficos\n",
        "import sqlite3  # Integra√ß√£o com banco de dados SQLite\n",
        "\n",
        "# Pr√©-processamento dos dados\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Normaliza√ß√£o e padroniza√ß√£o dos dados\n",
        "from sklearn.model_selection import train_test_split  # Divis√£o dos dados em treino e teste\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # Avalia√ß√£o do desempenho do modelo\n",
        "\n",
        "# Constru√ß√£o do modelo preditivo\n",
        "from keras.models import Sequential  # Modelo sequencial de rede neural\n",
        "from keras.layers import Dense  # Camada densa para aprendizado profundo\n",
        "\n",
        "# Controle de vers√£o e vari√°veis de ambiente\n",
        "import git  # Gerenciamento do reposit√≥rio Git\n",
        "import dotenv  # Carregamento de vari√°veis de ambiente\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LWOFHzJ6IupA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capturamdo todas as dependencias do ambiente nesta primeira etapa\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "ujEHOrH9cTIQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Configurando sincroniza√ß√£o com Github\n",
        "\n",
        "%%writefile /content/configurar_git.py\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "def git_config():\n",
        "    \"\"\"Configura o Git localmente e sincroniza com o reposit√≥rio remoto no GitHub.\"\"\"\n",
        "\n",
        "    # Carregar vari√°veis de ambiente do arquivo .env\n",
        "    load_dotenv(dotenv_path='/content/.env')\n",
        "\n",
        "    # Obter as vari√°veis de ambiente do .env para o GitHub\n",
        "    GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
        "    EMAIL = os.getenv('EMAIL')\n",
        "    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "    PROJECT_NAME = os.getenv('PROJECT_NAME')\n",
        "    REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{PROJECT_NAME}.git\"\n",
        "\n",
        "    # Configurar o Git localmente com as credenciais\n",
        "    os.system(f'git config --global user.name \"{GITHUB_USERNAME}\"')\n",
        "    os.system(f'git config --global user.email \"{EMAIL}\"')\n",
        "\n",
        "    # Verificar se o diret√≥rio do projeto j√° existe e se √© um reposit√≥rio Git v√°lido\n",
        "    if os.path.isdir(PROJECT_NAME):\n",
        "        print(f\"O diret√≥rio '{PROJECT_NAME}' j√° existe. Entrando no diret√≥rio e sincronizando...\")\n",
        "\n",
        "        os.chdir(PROJECT_NAME)  # Entrar na pasta do projeto\n",
        "\n",
        "        # Garantir que estamos na branch main\n",
        "        os.system(\"git branch -M main\")\n",
        "\n",
        "        # Remover qualquer configura√ß√£o errada do reposit√≥rio remoto e adicionar novamente\n",
        "        os.system(\"git remote remove origin\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Puxar as √∫ltimas atualiza√ß√µes do GitHub, tratando hist√≥ricos n√£o relacionados\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "    else:\n",
        "        print(f\"Clonando o reposit√≥rio '{PROJECT_NAME}'...\")\n",
        "\n",
        "        # Clonar o reposit√≥rio remoto\n",
        "        os.system(f\"git clone {REPO_URL}\")\n",
        "        os.chdir(PROJECT_NAME)  # Entrar no diret√≥rio ap√≥s o clone\n",
        "\n",
        "        # Inicializar o reposit√≥rio Git local (se necess√°rio) e configurar remoto\n",
        "        os.system(\"git branch -M main\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Realizar o pull inicial para garantir que a branch main est√° sincronizada\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "\n",
        "    print(f\"‚úÖ Configura√ß√£o do Git conclu√≠da e sincronizada com a branch main do reposit√≥rio{REPO_URL}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    git_config()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSdFzemI9yY",
        "outputId": "154b58ee-0461-46ce-f76b-1466ab6f1f81",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/configurar_git.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sincronizando reposit√≥rio\n",
        "\n",
        "from configurar_git import git_config\n",
        "git_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLWe41oYxhcr",
        "outputId": "050c3fac-5220-4a76-fc97-4cfacd12f4c8",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando o reposit√≥rio 'Piloto_Day_Trade'...\n",
            "‚úÖ Configura√ß√£o do Git conclu√≠da e sincronizada com a branch main do reposit√≥riohttps://CarolBw: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@github.com/CarolBw/Piloto_Day_Trade.git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Definindo estrutura de pastas do projeto\n",
        "\n",
        "\"\"\"\n",
        "Estrutura inicial do reposit√≥rio Piloto_Day_Trade:\n",
        "\n",
        "|- notebooks/         ‚Üí Jupyter Notebooks para explora√ß√£o e an√°lises\n",
        "|- scripts/           ‚Üí Fun√ß√µes reutiliz√°veis (pr√©-processamento, modelagem, avalia√ß√£o, etc.)\n",
        "|- data/              ‚Üí Dados organizados em 3 n√≠veis:\n",
        "   |- raw/            ‚Üí Dados brutos extra√≠dos diretamente de fontes externas\n",
        "   |- cleaned/        ‚Üí Dados limpos com tratamento b√°sico (ex: datas, nulos, nomes de colunas)\n",
        "   |- transformed/    ‚Üí Dados com features criadas e prontos para modelagem\n",
        "|- modelagem/         ‚Üí Modelagem do banco de dados.\n",
        "   |- database/       ‚Üí Banco de dados\n",
        "   |- catalog/        ‚Üí Cat√°logo de dados\n",
        "   |- esquema/        ‚Üí Esquema do banco de dados\n",
        "|- workflows/         ‚Üí Pipelines\n",
        "|- models/            ‚Üí Modelos treinados\n",
        "   |- scalers/        ‚Üí Scalers salvos (MinMaxScaler, StandardScaler, etc.)\n",
        "|- reports/           ‚Üí Resultados, gr√°ficos, relat√≥rios de performance\n",
        "|- MVP_Objetivo.md    ‚Üí Documento explicando o objetivo do projeto\n",
        "|- README.md          ‚Üí Instru√ß√µes gerais do projeto\n",
        "|-.env                ‚Üí Vari√°veis de ambiente e configura√ß√µes sens√≠veis\n",
        "|- requirements.txt   ‚Üí Lista de depend√™ncias\n",
        "|- LICENCE            ‚Üí Licen√ßa do projeto\n",
        "\"\"\"\n",
        "\n",
        "# Criar estrutura de diret√≥rios\n",
        "%cd /content/\n",
        "\n",
        "!mkdir -p /content/Piloto_Day_Trade/notebooks\n",
        "!mkdir -p /content/Piloto_Day_Trade/scripts\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/raw\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/cleaned\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/transformed\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/catalog\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/esquema\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/database\n",
        "!mkdir -p /content/Piloto_Day_Trade/models\n",
        "!mkdir -p /content/Piloto_Day_Trade/models/scalers\n",
        "!mkdir -p /content/Piloto_Day_Trade/reports\n",
        "!mkdir -p /content/Piloto_Day_Trade/workflows\n",
        "\n",
        "# Criar arquivos principais\n",
        "!touch /content/Piloto_Day_Trade/.gitignore\n",
        "!touch /content/Piloto_Day_Trade/README.md\n",
        "!touch /content/Piloto_Day_Trade/LICENCE\n",
        "\n"
      ],
      "metadata": {
        "id": "vVkhl3kbZKbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "53461433-e610-44b9-aece-7a801778087b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover arquivos existentes (ajuste conforme seus arquivos reais)\n",
        "!mv /content/.env /content/Piloto_Day_Trade/.env\n",
        "!mv /content/configurar_git.py /content/Piloto_Day_Trade/scripts/Operacional/configurar_git.py\n",
        "!mv /content/requirements.txt /content/Piloto_Day_Trade/requirements.txt\n",
        "!mv /content/MVP_Objetivo.md /content/Piloto_Day_Trade/MVP_Objetivo.md"
      ],
      "metadata": {
        "id": "6YEIOMuuWI4K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver estrutura de diret√≥rios\n",
        "!apt-get install tree -y > /dev/null 2>&1 # Instala o tree e oculta a saida da instala√ß√£o\n",
        "!tree /content/Piloto_Day_Trade -d\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X7oQ6eFTvuc",
        "outputId": "4cd686eb-6e06-4376-f467-d32bd6572321"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/Piloto_Day_Trade\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mdata\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mcleaned\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mraw\u001b[0m\n",
            "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34mtransformed\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mmodelagem\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mcatalog\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mdatabase\u001b[0m\n",
            "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34mesquema\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mmodels\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mLSTM_v1\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mscalers\u001b[0m\n",
            "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34mXGBoost_v1\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mnotebooks\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mreports\u001b[0m\n",
            "‚îú‚îÄ‚îÄ \u001b[01;34mscripts\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mModelagem_machine_learning\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mOperacional\u001b[0m\n",
            "‚îÇ¬†¬† ‚îú‚îÄ‚îÄ \u001b[01;34mPipelines\u001b[0m\n",
            "‚îÇ¬†¬† ‚îî‚îÄ‚îÄ \u001b[01;34m__pycache__\u001b[0m\n",
            "‚îî‚îÄ‚îÄ \u001b[01;34mworkflows\u001b[0m\n",
            "\n",
            "20 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fun√ß√£o operacional\n",
        "# para atualizar o reposit√≥rio facilmente ao longo do desenvolvimento sem erros de sincroniza√ß√£o\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def atualizar_repo(commit_message):\n",
        "    \"\"\"Atualiza o reposit√≥rio remoto e mostra quantos arquivos foram comitados.\"\"\"\n",
        "    repo_path = \"/content/Piloto_Day_Trade\"\n",
        "\n",
        "    if not os.path.exists(os.path.join(repo_path, \".git\")):\n",
        "        print(\"üö´ Este diret√≥rio n√£o √© um reposit√≥rio Git.\")\n",
        "        return\n",
        "\n",
        "    os.chdir(repo_path)\n",
        "\n",
        "    # Adiciona todos os arquivos\n",
        "    subprocess.run([\"git\", \"add\", \".\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    # Executa o commit e captura a sa√≠da completa (stdout + stderr)\n",
        "    result = subprocess.run(\n",
        "        [\"git\", \"commit\", \"-m\", commit_message],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    # Juntamos as sa√≠das para an√°lise\n",
        "    output = result.stdout + result.stderr\n",
        "\n",
        "    if \"files changed\" in output:\n",
        "        # Procura a linha com o resumo da altera√ß√£o\n",
        "        for linha in output.splitlines():\n",
        "            if \"files changed\" in linha:\n",
        "                print(f\"üìù {linha}\")\n",
        "                break\n",
        "    elif \"nothing to commit\" in output:\n",
        "        print(\"‚ÑπÔ∏è Nenhuma altera√ß√£o para comitar.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Resultado inesperado do Git:\")\n",
        "        print(output)\n",
        "\n",
        "    # Envia para o reposit√≥rio remoto\n",
        "    subprocess.run([\"git\", \"push\", \"origin\", \"main\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    print(\"‚úÖ Reposit√≥rio atualizado.\")\n"
      ],
      "metadata": {
        "id": "TGqg5UeqMKbl",
        "cellView": "form"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Extra√ß√£o de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/extracao_dados.py\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "def extrair_dados(ticker, dias, intervalo, dados_brutos):\n",
        "    \"\"\"Extrai e organiza dados do Yahoo Finance no intervalo correto.\"\"\"\n",
        "\n",
        "    df_total = pd.DataFrame()  # DataFrame para armazenar os dados\n",
        "    data_inicio = datetime.today() - timedelta(days=dias)  # Data inicial\n",
        "    data_fim = datetime.today() + timedelta(days=1)\n",
        "\n",
        "    # Verifica se o arquivo de dados brutos existe\n",
        "    if os.path.exists(dados_brutos):\n",
        "        df = pd.read_csv(dados_brutos, index_col=0, parse_dates=True)\n",
        "\n",
        "        if not df.empty:\n",
        "            # Atualiza a data de in√≠cio para a √∫ltima data dispon√≠vel nos dados brutos\n",
        "            ultima_data = pd.to_datetime(df.index.max())\n",
        "            data_inicio = ultima_data + timedelta(minutes=30)\n",
        "\n",
        "    print(f\"üîÑ Extraindo dados de {data_inicio.strftime('%Y-%m-%d %H:%M:%S')} at√© {data_fim.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # Extrai os dados do Yahoo Finance\n",
        "    df_novo = yf.download(\n",
        "        ticker,\n",
        "        start=data_inicio.strftime(\"%Y-%m-%d\"),\n",
        "        end=data_fim.strftime(\"%Y-%m-%d\"),\n",
        "        interval=intervalo,\n",
        "        progress=True\n",
        "    )\n",
        "\n",
        "    if not df_novo.empty:\n",
        "        # Apenas converte para \"America/Sao_Paulo\" se j√° tiver timezone\n",
        "        if df_novo.index.tzinfo is not None:\n",
        "            df_novo.index = df_novo.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "        # Concatena os novos dados com os existentes e remove duplicatas\n",
        "        df_total = pd.concat([df_total, df_novo]).drop_duplicates().sort_index()\n",
        "\n",
        "        # Remove linhas com mais de 50% de valores nulos\n",
        "        df_total = df_total.dropna(thresh=df_total.shape[1] * 0.5)\n",
        "\n",
        "        # Salva os dados atualizados no arquivo CSV\n",
        "        df_total.to_csv(dados_brutos)\n",
        "        print(\"‚úÖ Dados salvos com sucesso.\")\n",
        "\n",
        "    # Filtra os dados para o hor√°rio entre 10:00 e 18:00\n",
        "    df_filtrado = df_total.between_time(\"10:00\", \"18:00\")\n",
        "\n",
        "    # Exibe os 10 primeiros e os 10 √∫ltimos registros\n",
        "    print(\"√öltimos 10 dados filtrados:\")\n",
        "    print(df_filtrado.tail(10))\n",
        "    print(\"Primeiros 10 dados filtrados:\")\n",
        "    print(df_filtrado.head(10))\n",
        "\n",
        "    return df_filtrado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ticker = \"BBDC4.SA\"  # Ticker da a√ß√£o\n",
        "    intervalo = \"5m\"  # Intervalo de tempo (5 minutos)\n",
        "    dias = 45  # N√∫mero de dias a partir de hoje para buscar os dados\n",
        "    dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "    df = extrair_dados(ticker, dias, intervalo, dados_brutos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3JYaCsNw5fQ",
        "outputId": "1e257a07-e4c0-4a06-ebb3-7b8ca7be8aeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/extracao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executando extra√ß√£o de dados extra√ß√£o de dados\n",
        "from Piloto_Day_Trade.scripts.Pipeline.extracao_dados import extrair_dados\n",
        "\n",
        "ticker = \"BBDC4.SA\"  # Ticker da a√ß√£o\n",
        "intervalo = \"5m\"  # Intervalo de tempo\n",
        "dias = 45  # N√∫mero de dias a partir de hoje para buscar os dados\n",
        "dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "df = extrair_dados(ticker, dias, intervalo, dados_brutos)"
      ],
      "metadata": {
        "id": "OgEhS9Rwx_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Limpeza de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/limpeza_dados.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def limpeza_dados(df):\n",
        "    # Verificar se os dados est√£o corretos\n",
        "    print(\"Dados originais:\")\n",
        "    print(df.head())\n",
        "    print(df.info())\n",
        "\n",
        "    # Remover as primeiras duas linhas (com 'Ticker' e 'Datetime')\n",
        "    df = df.iloc[2:].copy()\n",
        "\n",
        "    # Verificar ap√≥s a remo√ß√£o das linhas iniciais\n",
        "    print(\"Ap√≥s remo√ß√£o das duas primeiras linhas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que o √≠ndice esteja no formato de data e hora (timezone UTC)\n",
        "    df.index = pd.to_datetime(df.index, utc=True)\n",
        "\n",
        "    # Definir o fuso hor√°rio como \"America/Sao_Paulo\"\n",
        "    df.index = df.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "    # Remover a refer√™ncia de fuso hor√°rio (deixar o hor√°rio local sem informa√ß√£o de timezone)\n",
        "    df.index = df.index.tz_localize(None)\n",
        "\n",
        "    # Criar a coluna 'hora' com base no √≠ndice\n",
        "    df['hora'] = df.index.strftime('%H:%M:%S')\n",
        "\n",
        "    # Renomear o √≠ndice para 'data'\n",
        "    df.index.name = 'data'\n",
        "\n",
        "    # Resetar o √≠ndice para transformar o Datetime em uma coluna normal\n",
        "    df = df.reset_index()\n",
        "\n",
        "    # Verificar ap√≥s a transforma√ß√£o do √≠ndice\n",
        "    print(\"\\nAp√≥s convers√£o de √≠ndice:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Remover o hor√°rio da coluna 'data', mantendo apenas a data\n",
        "    df['data'] = df['data'].dt.date\n",
        "\n",
        "    # Mapeamento das colunas para nomes padronizados\n",
        "    mapeamento_colunas = {\n",
        "        'Close': 'fechamento',\n",
        "        'High': 'maximo',\n",
        "        'Low': 'minimo',\n",
        "        'Open': 'abertura',\n",
        "        'Volume': 'volume'\n",
        "    }\n",
        "\n",
        "    # Renomear as colunas\n",
        "    df.rename(columns=mapeamento_colunas, inplace=True)\n",
        "\n",
        "    # Converte e arredonda as colunas num√©ricas\n",
        "    for col in ['abertura', 'minimo', 'maximo', 'fechamento']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').round(2)\n",
        "\n",
        "    # Converte a coluna 'volume' para n√∫mero inteiro\n",
        "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce', downcast='integer')\n",
        "\n",
        "    # Reorganiza as colunas na ordem desejada\n",
        "    df = df[['data', 'hora', 'abertura', 'minimo', 'maximo', 'fechamento', 'volume']]\n",
        "\n",
        "    # Verificar ap√≥s reorganizar as colunas\n",
        "    print(\"\\nAp√≥s reorganizar as colunas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Verificar e remover duplicatas mantendo a primeira ocorr√™ncia\n",
        "    df = df.drop_duplicates(keep='first')\n",
        "\n",
        "    # Remover as linhas com 50% ou mais de valores nulos\n",
        "    df = df.dropna(thresh=df.shape[1] * 0.5)\n",
        "\n",
        "    # Verificar ap√≥s remo√ß√£o de duplicatas e nulos\n",
        "    print(\"\\nAp√≥s remover duplicatas e nulos:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que 'data' e 'hora' estejam no formato datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d')\n",
        "    df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S').dt.time\n",
        "\n",
        "    # Filtra apenas os dias √∫teis (segunda a sexta)\n",
        "    df = df[df['data'].dt.weekday < 5]\n",
        "\n",
        "    # Verificar ap√≥s filtrar dias √∫teis\n",
        "    print(\"\\nAp√≥s filtrar apenas os dias √∫teis:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Filtra apenas hor√°rios entre 09:55 e 18:05\n",
        "    df = df[(df['hora'] >= pd.to_datetime('09:55:00').time()) &\n",
        "            (df['hora'] <= pd.to_datetime('18:05:00').time())]\n",
        "\n",
        "    # Verificar ap√≥s filtrar o intervalo de hor√°rio\n",
        "    print(\"\\nAp√≥s filtrar o intervalo de hor√°rio (09:55-18:05):\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Caso o DataFrame fique vazio, informar o motivo\n",
        "    if df.empty:\n",
        "        print(\"O DataFrame ficou vazio ap√≥s o filtro de hor√°rio. Verifique se os dados est√£o dentro do intervalo de 09:55-18:05.\")\n",
        "    else:\n",
        "        print(\"\\nLimpeza de dados conclu√≠da com sucesso.\")\n",
        "\n",
        "    # Ordenar os dados\n",
        "    df = df.sort_values([\"data\", \"hora\"], ascending=[False, True])\n",
        "    print(\"\\nDados limpos e ordenados:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Salva os dados limpos em CSV\n",
        "    df.to_csv(f\"/content/Piloto_Day_Trade/data/cleaned/dados_limpos.csv\", index=False)\n",
        "    print(f\"\\nOs dados foram limpos e salvos em csv.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ler os dados brutos\n",
        "    dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "    # Aplicar limpeza nos dados\n",
        "    df_limpo = limpeza_dados(dados_brutos)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHkNWR1-QS4",
        "outputId": "2644cc82-a2e1-4af6-a042-b0d681f6b8c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/limpeza_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Aplicando limpeza de dados\n",
        "from Piloto_Day_Trade.scripts.Pipeline.limpeza_dados import limpeza_dados\n",
        "\n",
        "dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/raw/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "df_limpo = limpeza_dados(dados_brutos)\n",
        "\n"
      ],
      "metadata": {
        "id": "97mwKCsf1V3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Transforma√ß√£o de dados\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/transformacao_dados.py\n",
        "\n",
        "\"\"\"\n",
        "Fun√ß√£o de Transforma√ß√£o de Dados para Modelagem Preditiva\n",
        "Processa e transforma os dados para an√°lise e previs√£o, gerando um conjunto\n",
        "de caracter√≠sticas para serem utilizadas no treinamento dos modelos.\n",
        "\n",
        "Objetivos:\n",
        "- Criar um dataset com vari√°veis relevantes para o modelo.\n",
        "- Incluir indicadores t√©cnicos, estat√≠sticas de volatilidade, m√©dias m√≥veis e outras features.\n",
        "- Permitir a experimenta√ß√£o com diferentes combina√ß√µes de features.\n",
        "\n",
        "Estrat√©gia:\n",
        "- Durante os testes de parametriza√ß√£o e treinamento, ser√£o geradas diferentes vers√µes do dataset,\n",
        "refinando a sele√ß√£o de features a medida que geramos acur√°cia.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carregar vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "def carregar_dados(arquivo):\n",
        "    \"\"\"Carrega um CSV e retorna um DataFrame, ou um DataFrame vazio se o arquivo n√£o existir.\"\"\"\n",
        "    if isinstance(arquivo, pd.DataFrame):\n",
        "        return arquivo  # Se j√° for um DataFrame, retorna diretamente\n",
        "\n",
        "    if not os.path.exists(arquivo):\n",
        "        print(f\"‚ö†Ô∏è O arquivo {arquivo} n√£o existe. Criando um novo DataFrame vazio.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(arquivo, parse_dates=[\"data\"])\n",
        "        print(f\"‚úÖ Arquivo {arquivo} carregado com {len(df)} linhas.\")\n",
        "        return df if not df.empty else pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao carregar {arquivo}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def obter_ultima_data(df):\n",
        "    \"\"\"Retorna a √∫ltima data dispon√≠vel nos dados.\"\"\"\n",
        "    if \"data\" in df.columns and not df.empty:\n",
        "        ultima_data = df[\"data\"].max()\n",
        "        print(f\"üìÖ √öltima data encontrada nos dados: {ultima_data}\")\n",
        "        return ultima_data\n",
        "    return None\n",
        "\n",
        "def filtrar_novos_dados(df, ultima_data):\n",
        "    \"\"\"Filtra os dados para incluir apenas os novos registros.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado limpo dispon√≠vel.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if ultima_data:\n",
        "        df_novo = df[df[\"data\"] > ultima_data]\n",
        "        print(f\"üìä Dados novos filtrados: {len(df_novo)} registros encontrados.\")\n",
        "        return df_novo\n",
        "    return df\n",
        "\n",
        "def calcular_indicadores(df):\n",
        "    \"\"\"Calcula indicadores t√©cnicos e gera novas features para an√°lise de dados financeiros.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado dispon√≠vel para calcular indicadores.\")\n",
        "        return df\n",
        "\n",
        "    colunas_necessarias = [\"data\", \"hora\", \"abertura\", \"minimo\", \"maximo\", \"fechamento\", \"volume\"]\n",
        "\n",
        "    if not all(col in df.columns for col in colunas_necessarias):\n",
        "        print(\"‚ùå Dados insuficientes para c√°lculo de indicadores.\")\n",
        "        return df\n",
        "\n",
        "    # Ordena√ß√£o correta dos dados\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[True, True])\n",
        "\n",
        "    # C√°lculo do retorno percentual e volatilidade\n",
        "    df['retorno'] = df['fechamento'].pct_change()\n",
        "    df['volatilidade'] = df['retorno'].rolling(20).std()\n",
        "\n",
        "    # M√©dias m√≥veis\n",
        "    df['SMA_10'] = df['fechamento'].rolling(10).mean()\n",
        "    df['EMA_10'] = df['fechamento'].ewm(span=10, adjust=False).mean()\n",
        "\n",
        "    # MACD e linha de sinal\n",
        "    df['MACD'] = df['fechamento'].ewm(span=12).mean() - df['fechamento'].ewm(span=26).mean()\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=9).mean()\n",
        "\n",
        "    # RSI (√çndice de For√ßa Relativa)\n",
        "    ganho = df['retorno'].clip(lower=0)\n",
        "    perda = -df['retorno'].clip(upper=0)\n",
        "    media_ganho = ganho.ewm(span=14).mean()\n",
        "    media_perda = perda.ewm(span=14).mean() + 1e-10\n",
        "    df['rsi'] = 100 - (100 / (1 + (media_ganho / media_perda)))\n",
        "\n",
        "    # OBV (On Balance Volume)\n",
        "    df['OBV'] = (df['volume'] * np.sign(df['fechamento'].diff())).fillna(0).cumsum()\n",
        "\n",
        "    # Criar lags para fechamento, retorno e volume\n",
        "    for lag in range(1, 4):\n",
        "        df[f'fechamento_lag{lag}'] = df['fechamento'].shift(lag)\n",
        "        df[f'retorno_lag{lag}'] = df['retorno'].shift(lag)\n",
        "        df[f'volume_lag{lag}'] = df['volume'].shift(lag)\n",
        "\n",
        "    # Substituir NaN por zero onde necess√°rio\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Ordena√ß√£o final\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[False, True])\n",
        "\n",
        "    print(f\"‚úÖ Indicadores calculados. Tamanho final do DataFrame: {len(df)} linhas.\")\n",
        "    return df\n",
        "\n",
        "def adicionar_features_temporais(df):\n",
        "    \"\"\"Adiciona colunas temporais para an√°lise de s√©ries temporais.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado dispon√≠vel para processamento.\")\n",
        "        return df\n",
        "\n",
        "    # Converter 'data' para datetime se necess√°rio\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "\n",
        "    # Criar coluna do dia da semana para entrada e previs√£o\n",
        "    df['dia_da_semana_entrada'] = df['data'].dt.weekday  # 0 = Segunda, 6 = Domingo\n",
        "    df['data_previsao'] = df['data'] + pd.DateOffset(days=1)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Ajustar casos de sexta-feira para segunda-feira\n",
        "    df.loc[df['dia_da_semana_entrada'] == 4, 'data_previsao'] += pd.DateOffset(days=2)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Verificar se 'hora' est√° presente e converter corretamente\n",
        "    if 'hora' in df.columns:\n",
        "        df['hora'] = pd.to_datetime(df['hora'].astype(str), format='%H:%M:%S', errors='coerce').dt.time\n",
        "\n",
        "        # Criar colunas de hora e minuto\n",
        "        df['hora_num'] = df['hora'].apply(lambda x: x.hour if pd.notnull(x) else np.nan)\n",
        "        df['minuto'] = df['hora'].apply(lambda x: x.minute if pd.notnull(x) else np.nan)\n",
        "\n",
        "        # Criar coluna indicando se o mercado est√° aberto (entre 10h e 17h)\n",
        "        df['mercado_aberto'] = ((df['hora_num'] >= 10) & (df['hora_num'] <= 17)).astype(int)\n",
        "    else:\n",
        "        df['hora_num'] = np.nan\n",
        "        df['minuto'] = np.nan\n",
        "        df['mercado_aberto'] = 0\n",
        "\n",
        "    return df\n",
        "\n",
        "def transformar_dados(dados_limpos, dados_transformados):\n",
        "    \"\"\"Executa o processo de transforma√ß√£o dos dados.\"\"\"\n",
        "\n",
        "    df_transformado = carregar_dados(dados_transformados)\n",
        "    df_limpo = carregar_dados(dados_limpos)\n",
        "\n",
        "\n",
        "    if df_transformado.empty:\n",
        "        print(\"üìÇ Nenhum dado transformado encontrado. Criando novo DataFrame.\")\n",
        "\n",
        "    ultima_data = obter_ultima_data(df_transformado)\n",
        "    novos_dados = filtrar_novos_dados(df_limpo, ultima_data)\n",
        "\n",
        "    if not novos_dados.empty:\n",
        "        novos_dados = calcular_indicadores(novos_dados)\n",
        "        novos_dados = adicionar_features_temporais(novos_dados)\n",
        "        df_final = pd.concat([df_transformado, novos_dados], ignore_index=True) if not df_transformado.empty else novos_dados\n",
        "\n",
        "        pasta = os.path.dirname(dados_transformados)\n",
        "        if not os.path.exists(pasta):\n",
        "            os.makedirs(pasta)\n",
        "            print(f\"üìÇ Criando diret√≥rio: {pasta}\")\n",
        "\n",
        "        df_final.to_csv(dados_transformados, index=False)\n",
        "        print(f\"‚úÖ Dados transformados salvos em {dados_transformados} ({len(df_final)} registros)\")\n",
        "        print(f\"üìÖ √öltima data dispon√≠vel nos dados: {df_final['data'].max()}\")\n",
        "        print(f\"df_final: {df_final.head(5)}\")\n",
        "        return df_final\n",
        "    else:\n",
        "        print(\"‚è≠Ô∏è Nenhum novo dado para processar.\")\n",
        "        print(f\"üìÖ √öltima data dispon√≠vel nos dados: {df_transformado['data'].max()}\")\n",
        "        print(f\"df_transformado: {df_transformado.head(5)}\")\n",
        "        return df_transformado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados_limpos = '/content/Piloto_Day_Trade/data/dados_limpos.csv'\n",
        "    path_dados_transformados = '/content/Piloto_Day_Trade/data/dados_transformados_3103.csv'\n",
        "    df_transformado =transformar_dados(path_dados_limpos, path_dados_transformados)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH35zARUD6jA",
        "outputId": "9ce3d8fc-d574-4782-852e-2c7fe234d923"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/transformacao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.transformacao_dados import transformar_dados\n",
        "\n",
        "#@title Aplicando transforma√ß√£o de dados\n",
        "path_dados_limpos = '/content/Piloto_Day_Trade/data/cleaned/dados_limpos.csv'\n",
        "path_dados_transformados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "df_transformado = transformar_dados(path_dados_limpos, path_dados_transformados)\n"
      ],
      "metadata": {
        "id": "5bG6Yqpyuawu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados\n",
        "df_transformado = pd.read_csv('/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv')\n"
      ],
      "metadata": {
        "id": "6Kd2TDjqmGVo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando os tipos de dados\n",
        "df_transformado.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4G3hB-sknn-j",
        "outputId": "2845fd79-ab19-4c24-f8c1-c119a9f285c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data                       object\n",
              "hora                       object\n",
              "abertura                  float64\n",
              "minimo                    float64\n",
              "maximo                    float64\n",
              "fechamento                float64\n",
              "volume                      int64\n",
              "retorno                   float64\n",
              "volatilidade              float64\n",
              "SMA_10                    float64\n",
              "EMA_10                    float64\n",
              "MACD                      float64\n",
              "Signal_Line               float64\n",
              "rsi                       float64\n",
              "OBV                       float64\n",
              "fechamento_lag1           float64\n",
              "retorno_lag1              float64\n",
              "volume_lag1               float64\n",
              "fechamento_lag2           float64\n",
              "retorno_lag2              float64\n",
              "volume_lag2               float64\n",
              "fechamento_lag3           float64\n",
              "retorno_lag3              float64\n",
              "volume_lag3               float64\n",
              "dia_da_semana_entrada       int64\n",
              "data_previsao              object\n",
              "dia_da_semana_previsao      int64\n",
              "hora_num                    int64\n",
              "minuto                      int64\n",
              "mercado_aberto              int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>data</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abertura</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minimo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maximo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volatilidade</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MACD</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Signal_Line</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rsi</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBV</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_entrada</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_previsao</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_previsao</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora_num</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minuto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mercado_aberto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Banco de dados"
      ],
      "metadata": {
        "id": "Ap-meZswIhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n",
        "\n",
        "#@title Defini√ß√£o do esquema - Modelo Estrela\n",
        "\n",
        "O modelo estrela foi escolhido por sua simplicidade e clareza na organiza√ß√£o dos dados para an√°lise. Ele √© ideal para consultas r√°pidas e an√°lise preditiva. No nosso projeto, temos um √∫nico fato (pre√ßos OHLC) e m√∫ltiplas vari√°veis explicativas que os influenciam.\n",
        "\n",
        "A estrutura facilita agrega√ß√µes temporais e an√°lises do comportamento dos pre√ßos, sendo tamb√©m eficiente para alimentar o pipeline de machine learning. Ao organizar as vari√°veis preditoras ao redor das medidas de pre√ßo, conseguimos isolar responsabilidades e tornar as an√°lises mais precisas e escal√°veis.\n",
        "\n",
        "## Tabela Fato: `fato_precos`\n",
        "| Coluna         | Tipo   | Descri√ß√£o                                   |\n",
        "|----------------|--------|---------------------------------------------|\n",
        "| id_fato_precos | int    | PK, identificador √∫nico da linha            |\n",
        "| id_tempo       | int    | FK para a dimens√£o tempo                    |\n",
        "| abertura       | float  | Pre√ßo de abertura                           |\n",
        "| minimo         | float  | Pre√ßo m√≠nimo                                |\n",
        "| maximo         | float  | Pre√ßo m√°ximo                                |\n",
        "| fechamento     | float  | Pre√ßo de fechamento (vari√°vel alvo)         |\n",
        "\n",
        "## Dimens√£o: `dim_tempo`\n",
        "| Coluna                | Tipo   | Descri√ß√£o                                 |\n",
        "|------------------------|--------|-------------------------------------------|\n",
        "| id_tempo              | int    | PK                                        |\n",
        "| data                  | object | Data da observa√ß√£o                        |\n",
        "| hora                  | object | Hora da observa√ß√£o                        |\n",
        "| dia_da_semana_entrada | int    | Dia da semana da entrada (0=Seg, 6=Dom)   |\n",
        "\n",
        "## Dimens√£o: `dim_indicadores`\n",
        "| Coluna       | Tipo   | Descri√ß√£o                                       |\n",
        "|--------------|--------|--------------------------------------------------|\n",
        "| id_indicadores | int  | PK                                               |\n",
        "| id_tempo     | int    | FK para a dimens√£o tempo                        |\n",
        "| SMA_10       | float  | M√©dia m√≥vel simples de 10 per√≠odos              |\n",
        "| EMA_10       | float  | M√©dia m√≥vel exponencial de 10 per√≠odos          |\n",
        "| MACD         | float  | Moving Average Convergence Divergence           |\n",
        "| Signal_Line  | float  | Linha de sinal do MACD                          |\n",
        "| rsi          | float  | √çndice de for√ßa relativa                        |\n",
        "| OBV          | float  | On-Balance Volume                               |\n",
        "| retorno      | float  | Retorno do per√≠odo                              |\n",
        "| volatilidade | float  | Volatilidade do per√≠odo                         |\n",
        "\n",
        "## Dimens√£o: `dim_lags`\n",
        "| Coluna          | Tipo   | Descri√ß√£o                                       |\n",
        "|-----------------|--------|--------------------------------------------------|\n",
        "| id_lags         | int    | PK                                              |\n",
        "| id_tempo        | int    | FK para a dimens√£o tempo                        |\n",
        "| fechamento_lag1 | float  | Fechamento no candle anterior (1 lag)          |\n",
        "| retorno_lag1    | float  | Retorno do candle anterior (1 lag)             |\n",
        "| volume_lag1     | float  | Volume do candle anterior (1 lag)              |\n",
        "| fechamento_lag2 | float  | Fechamento dois candles atr√°s (2 lags)         |\n",
        "| retorno_lag2    | float  | Retorno dois candles atr√°s (2 lags)            |\n",
        "| volume_lag2     | float  | Volume dois candles atr√°s (2 lags)             |\n",
        "| fechamento_lag3 | float  | Fechamento tr√™s candles atr√°s (3 lags)         |\n",
        "| retorno_lag3    | float  | Retorno tr√™s candles atr√°s (3 lags)            |\n",
        "| volume_lag3     | float  | Volume tr√™s candles atr√°s (3 lags)             |\n",
        "\n",
        "## Dimens√£o: `dim_operacional`\n",
        "| Coluna                 | Tipo   | Descri√ß√£o                                      |\n",
        "|------------------------|--------|------------------------------------------------|\n",
        "| id_operacional         | int    | PK                                             |\n",
        "| id_tempo               | int    | FK para a dimens√£o tempo                       |\n",
        "| data_previsao          | object | Data prevista para o modelo                    |\n",
        "| dia_da_semana_previsao | int    | Dia da semana da previs√£o                      |\n",
        "| hora_num               | int    | Hora como n√∫mero inteiro                       |\n",
        "| minuto                 | int    | Minuto da observa√ß√£o                           |\n",
        "| mercado_aberto         | int    | Indicador bin√°rio (1=aberto, 0=fechado)        |\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "kuxIPKOgzMvy",
        "outputId": "edb8b7a4-cc95-4076-8961-4bd709ee8ece"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n",
        "\n",
        "#@title Script para gerar o cat√°logo de dados\n",
        "\"\"\"\n",
        "Cat√°logo de Dados contendo minimamente uma descri√ß√£o detalhada dos dados e seus dom√≠nios,\n",
        "contendo valores m√≠nimos e m√°ximos esperados para dados num√©ricos, e poss√≠veis categorias para dados categ√≥ricos.\n",
        "\n",
        "Este modelo deve tamb√©m descrever a linhagem dos dados, de onde os mesmos foram baixados\n",
        "e qual t√©cnica foi utilizada para compor o conjunto de dados, caso haja.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Define colunas de cada tabela com tipos\n",
        "tabelas = {\n",
        "    \"fato_precos\": {\n",
        "        \"id_fato_precos\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"abertura\": \"float\",\n",
        "        \"minimo\": \"float\",\n",
        "        \"maximo\": \"float\",\n",
        "        \"fechamento\": \"float\"\n",
        "    },\n",
        "    \"dim_tempo\": {\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data\": \"object\",\n",
        "        \"hora\": \"object\",\n",
        "        \"dia_da_semana_entrada\": \"int\"\n",
        "    },\n",
        "    \"dim_indicadores\": {\n",
        "        \"id_indicadores\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"SMA_10\": \"float\",\n",
        "        \"EMA_10\": \"float\",\n",
        "        \"MACD\": \"float\",\n",
        "        \"Signal_Line\": \"float\",\n",
        "        \"rsi\": \"float\",\n",
        "        \"OBV\": \"float\",\n",
        "        \"retorno\": \"float\",\n",
        "        \"volatilidade\": \"float\"\n",
        "    },\n",
        "    \"dim_lags\": {\n",
        "        \"id_lags\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"fechamento_lag1\": \"float\",\n",
        "        \"retorno_lag1\": \"float\",\n",
        "        \"volume_lag1\": \"float\",\n",
        "        \"fechamento_lag2\": \"float\",\n",
        "        \"retorno_lag2\": \"float\",\n",
        "        \"volume_lag2\": \"float\",\n",
        "        \"fechamento_lag3\": \"float\",\n",
        "        \"retorno_lag3\": \"float\",\n",
        "        \"volume_lag3\": \"float\"\n",
        "    },\n",
        "    \"dim_operacional\": {\n",
        "        \"id_operacional\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data_previsao\": \"object\",\n",
        "        \"dia_da_semana_previsao\": \"int\",\n",
        "        \"hora_num\": \"int\",\n",
        "        \"minuto\": \"int\",\n",
        "        \"mercado_aberto\": \"int\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def dominio(col, tipo):\n",
        "    if tipo in [\"float\", \"int\"]:\n",
        "        if \"retorno\" in col:\n",
        "            return \"-0.05 a 0.05 (retorno percentual por intervalo de 5 min)\"\n",
        "        elif \"volatilidade\" in col:\n",
        "            return \"0 a 0.1 (desvio padr√£o do retorno por janela de tempo)\"\n",
        "        elif \"abertura\" in col or \"fechamento\" in col or \"minimo\" in col or \"maximo\" in col:\n",
        "            return \"10.0 a 50.0 (valores t√≠picos para BBDC4)\"\n",
        "        elif \"MACD\" in col or \"Signal\" in col:\n",
        "            return \"-5 a 5\"\n",
        "        elif \"rsi\" in col:\n",
        "            return \"0 a 100\"\n",
        "        elif \"OBV\" in col:\n",
        "            return \"valor acumulativo, depende do ativo\"\n",
        "        elif \"volume\" in col:\n",
        "            return \"0 a 1.000.000 (valores inteiros positivos)\"\n",
        "        elif \"dia_da_semana\" in col:\n",
        "            return \"0=Segunda, ..., 6=Domingo\"\n",
        "        elif \"mercado_aberto\" in col:\n",
        "            return \"0=Fechado, 1=Aberto\"\n",
        "        else:\n",
        "            return \"valores num√©ricos cont√≠nuos\"\n",
        "    elif tipo == \"object\":\n",
        "        if \"data\" in col:\n",
        "            return \"formato YYYY-MM-DD\"\n",
        "        elif \"hora\" in col:\n",
        "            return \"formato HH:MM:SS\"\n",
        "        else:\n",
        "            return \"texto livre\"\n",
        "    return \"n√£o especificado\"\n",
        "\n",
        "def descricao(col):\n",
        "    descricoes = {\n",
        "        \"abertura\": \"Pre√ßo de abertura do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"minimo\": \"Menor pre√ßo do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"maximo\": \"Maior pre√ßo do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"fechamento\": \"Pre√ßo de fechamento do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"retorno\": \"Retorno percentual do ativo no intervalo de 5 minutos\",\n",
        "        \"volatilidade\": \"Volatilidade dos retornos do ativo em janela deslizante\",\n",
        "        \"SMA_10\": \"M√©dia m√≥vel simples de 10 per√≠odos calculada sobre os pre√ßos\",\n",
        "        \"EMA_10\": \"M√©dia m√≥vel exponencial de 10 per√≠odos\",\n",
        "        \"MACD\": \"Moving Average Convergence Divergence, indicador t√©cnico\",\n",
        "        \"Signal_Line\": \"Linha de sinal do MACD\",\n",
        "        \"rsi\": \"√çndice de for√ßa relativa (RSI), oscilador t√©cnico\",\n",
        "        \"OBV\": \"On Balance Volume, indicador t√©cnico baseado em volume\",\n",
        "        \"hora_num\": \"Hora expressa como n√∫mero inteiro\",\n",
        "        \"minuto\": \"Minuto do intervalo de tempo\",\n",
        "        \"mercado_aberto\": \"Indica se o mercado est√° aberto no hor√°rio (1) ou n√£o (0)\"\n",
        "    }\n",
        "    for key in descricoes:\n",
        "        if key in col:\n",
        "            return descricoes[key]\n",
        "    if \"lag\" in col:\n",
        "        return f\"Valor defasado de {col.replace('_lag', '')}\"\n",
        "    if \"dia_da_semana\" in col:\n",
        "        return \"Dia da semana correspondente √† data\"\n",
        "    if \"id_\" in col:\n",
        "        return \"Identificador √∫nico para relacionar com outras tabelas\"\n",
        "    return \"\"\n",
        "\n",
        "def tecnica(col):\n",
        "    if any(ind in col for ind in [\"SMA\", \"EMA\", \"MACD\", \"Signal\", \"rsi\", \"OBV\"]):\n",
        "        return \"calculado internamente via engenharia de features t√©cnicas\"\n",
        "    if \"lag\" in col:\n",
        "        return \"calculado como valor defasado (lag)\"\n",
        "    if col in [\"data\", \"hora\", \"hora_num\", \"minuto\", \"dia_da_semana_entrada\", \"dia_da_semana_previsao\"]:\n",
        "        return \"extra√≠do de data/hora original\"\n",
        "    if col == \"mercado_aberto\":\n",
        "        return \"derivado da data/hora com base em calend√°rio de mercado\"\n",
        "    return \"c√≥pia ou identificador\"\n",
        "\n",
        "linhagem = \"Fonte: Yahoo Finance via yfinance\"\n",
        "\n",
        "linhas = []\n",
        "for tabela, colunas in tabelas.items():\n",
        "    for col, tipo in colunas.items():\n",
        "        linhas.append({\n",
        "            \"tabela\": tabela,\n",
        "            \"coluna\": col,\n",
        "            \"tipo\": tipo,\n",
        "            \"descricao\": descricao(col),\n",
        "            \"dominio\": dominio(col, tipo),\n",
        "            \"tecnica\": tecnica(col),\n",
        "            \"linhagem\": linhagem\n",
        "        })\n",
        "\n",
        "catalogo_df = pd.DataFrame(linhas)\n",
        "catalogo_df.to_csv(\"/content/Piloto_Day_Trade/modelagem/catalogo_dados.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "_Gn9fb5M4S1f",
        "outputId": "043bbdb6-f76c-47fb-accb-1f6677660cca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar a gera√ß√£o do Catalogo de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "o6QQCeAF1qvO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Gerando cat√°logo de dados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC29xOqV95Z_",
        "outputId": "f59b30e7-e64a-4050-a8fc-35530eec0c5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Atualiza√ß√£o do reposit√≥rio conclu√≠da!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n",
        "\n",
        "# @title Script para criar banco de dados e tabelas\n",
        "\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
        "\n",
        "# Conecta ao banco (cria se n√£o existir)\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Comandos SQL para criar as tabelas\n",
        "sql_script = \"\"\"\n",
        "-- Cria√ß√£o da Tabela Fato\n",
        "CREATE TABLE IF NOT EXISTS fato_precos (\n",
        "    id_fato_precos INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    abertura REAL,\n",
        "    minimo REAL,\n",
        "    maximo REAL,\n",
        "    fechamento REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Tempo\n",
        "CREATE TABLE IF NOT EXISTS dim_tempo (\n",
        "    id_tempo INTEGER PRIMARY KEY,\n",
        "    data TEXT,\n",
        "    hora TEXT,\n",
        "    dia_da_semana_entrada INTEGER\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Indicadores T√©cnicos\n",
        "CREATE TABLE IF NOT EXISTS dim_indicadores (\n",
        "    id_indicadores INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    SMA_10 REAL,\n",
        "    EMA_10 REAL,\n",
        "    MACD REAL,\n",
        "    Signal_Line REAL,\n",
        "    rsi REAL,\n",
        "    OBV REAL,\n",
        "    retorno REAL,\n",
        "    volatilidade REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Lags\n",
        "CREATE TABLE IF NOT EXISTS dim_lags (\n",
        "    id_lags INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    fechamento_lag1 REAL,\n",
        "    retorno_lag1 REAL,\n",
        "    volume_lag1 REAL,\n",
        "    fechamento_lag2 REAL,\n",
        "    retorno_lag2 REAL,\n",
        "    volume_lag2 REAL,\n",
        "    fechamento_lag3 REAL,\n",
        "    retorno_lag3 REAL,\n",
        "    volume_lag3 REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Operacional\n",
        "CREATE TABLE IF NOT EXISTS dim_operacional (\n",
        "    id_operacional INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    data_previsao TEXT,\n",
        "    dia_da_semana_previsao INTEGER,\n",
        "    hora_num INTEGER,\n",
        "    minuto INTEGER,\n",
        "    mercado_aberto INTEGER,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Executa o script SQL\n",
        "cursor.executescript(sql_script)\n",
        "\n",
        "# Confirma e fecha\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"‚úÖ Banco e tabelas criados com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-OxeXvgYa_jC",
        "outputId": "2b9f1193-11a2-4be9-df79-733345229f2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Excecutar criar banco e tabelas\n",
        "!python /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "NGaGzrS1AQcj",
        "outputId": "9a76aa09-9c81-4c3f-b8d0-f6a635484d16"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Banco e tabelas criados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar cria√ß√£o do banco\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsDCNhgeA2WU",
        "outputId": "67c3ced0-b34c-4c96-f7fa-a6d630429946"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fato_precos',), ('dim_tempo',), ('dim_indicadores',), ('dim_lags',), ('dim_operacional',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar colunas\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"PRAGMA table_info(dim_tempo);\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM7plBnSFNHp",
        "outputId": "f9fa0f48-89d7-41ae-abe1-3803038bad9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'id_tempo', 'INTEGER', 0, None, 1), (1, 'data', 'TEXT', 0, None, 0), (2, 'hora', 'TEXT', 0, None, 0), (3, 'dia_da_semana_entrada', 'INTEGER', 0, None, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Definindo script de carga de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/carga_dados.py\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Caminho para o banco de dados\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "assert os.path.exists(db_path), f\"Banco de dados n√£o encontrado em {db_path}\"\n",
        "# Leitura dos dados a serem carregados\n",
        "df = pd.read_csv(\"/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv\")\n",
        "\n",
        "# Fun√ß√£o para carregar dados\n",
        "def carregar_dados(df: pd.DataFrame):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        id_tempo = idx + 1\n",
        "\n",
        "        # 1. Inserir na dim_tempo\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_tempo (id_tempo, data, hora, dia_da_semana_entrada)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, row['data'], row['hora'], row['dia_da_semana_entrada']))\n",
        "\n",
        "        # 2. Inserir na dim_indicadores\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_indicadores (id_indicadores, id_tempo, SMA_10, EMA_10, MACD, Signal_Line, rsi, OBV, retorno, volatilidade)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['SMA_10'], row['EMA_10'], row['MACD'], row['Signal_Line'], row['rsi'],\n",
        "              row['OBV'], row['retorno'], row['volatilidade']))\n",
        "\n",
        "        # 3. Inserir na dim_lags\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_lags (id_lags, id_tempo, fechamento_lag1, retorno_lag1, volume_lag1,\n",
        "                                  fechamento_lag2, retorno_lag2, volume_lag2,\n",
        "                                  fechamento_lag3, retorno_lag3, volume_lag3)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo,\n",
        "              row['fechamento_lag1'], row['retorno_lag1'], row['volume_lag1'],\n",
        "              row['fechamento_lag2'], row['retorno_lag2'], row['volume_lag2'],\n",
        "              row['fechamento_lag3'], row['retorno_lag3'], row['volume_lag3']))\n",
        "\n",
        "        # 4. Inserir na dim_operacional\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_operacional (id_operacional, id_tempo, data_previsao, dia_da_semana_previsao, hora_num, minuto, mercado_aberto)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['data_previsao'], row['dia_da_semana_previsao'],\n",
        "              row['hora_num'], row['minuto'], row['mercado_aberto']))\n",
        "\n",
        "        # 5. Inserir na fato_precos\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO fato_precos (id_fato_precos, id_tempo, abertura, minimo, maximo, fechamento)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['abertura'], row['minimo'], row['maximo'], row['fechamento']))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(f\"‚úÖ Carga conclu√≠da com {len(df)} registros.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    carregar_dados(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "injpAahyCCxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3e4e977b-8177-442d-9307-3c47dcbf47e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar realizar a carga de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zidwW0A7DfMa",
        "outputId": "cac96221-5118-47d1-9e79-11b79644c6e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Carga conclu√≠da com 2462 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a carga de dados\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "\n",
        "# Conex√£o e cursor\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Consulta nas tabelas principais\n",
        "tabelas = ['dim_tempo', 'dim_indicadores', 'dim_lags', 'dim_operacional', 'fato_precos']\n",
        "for tabela in tabelas:\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {tabela}\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"{tabela}: {count} registros\")\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksO0iYGrEEXF",
        "outputId": "844e25bd-e40f-4ff8-9514-7f1b5985b6cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_tempo: 2462 registros\n",
            "dim_indicadores: 2462 registros\n",
            "dim_lags: 2462 registros\n",
            "dim_operacional: 2462 registros\n",
            "fato_precos: 2462 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os primeiros 5 registros da fato_precos\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_check = pd.read_sql_query(\"SELECT * FROM fato_precos LIMIT 5\", conn)\n",
        "print(df_check)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0OFgWADGalR",
        "outputId": "e243258d-2c88-4410-d40c-fb5565d96723"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos  id_tempo  abertura  minimo  maximo  fechamento\n",
            "0               1         1     12.47   12.40   12.47       12.41\n",
            "1               2         2     12.41   12.37   12.45       12.41\n",
            "2               3         3     12.41   12.41   12.46       12.44\n",
            "3               4         4     12.44   12.38   12.45       12.39\n",
            "4               5         5     12.40   12.39   12.45       12.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta com JOIN para verificar o relacionamento entre as tabelas\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    ft.id_fato_precos,\n",
        "    dt.data,\n",
        "    dt.hora,\n",
        "    ft.abertura,\n",
        "    ft.fechamento,\n",
        "    di.SMA_10,\n",
        "    dl.fechamento_lag1,\n",
        "    do.data_previsao,\n",
        "    do.mercado_aberto\n",
        "FROM fato_precos ft\n",
        "JOIN dim_tempo dt ON ft.id_tempo = dt.id_tempo\n",
        "JOIN dim_indicadores di ON ft.id_tempo = di.id_tempo\n",
        "JOIN dim_lags dl ON ft.id_tempo = dl.id_tempo\n",
        "JOIN dim_operacional do ON ft.id_tempo = do.id_tempo\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "# Executando e exibindo\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_verificacao = pd.read_sql_query(query, conn)\n",
        "print(df_verificacao)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrqdeR8Gq1p",
        "outputId": "d1615268-e9fe-4496-904a-54dc0b16b88f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos        data      hora  abertura  fechamento  SMA_10  \\\n",
            "0               1  2025-04-08  10:00:00     12.47       12.41  12.379   \n",
            "1               2  2025-04-08  10:05:00     12.41       12.41  12.384   \n",
            "2               3  2025-04-08  10:10:00     12.41       12.44  12.389   \n",
            "3               4  2025-04-08  10:15:00     12.44       12.39  12.390   \n",
            "4               5  2025-04-08  10:20:00     12.40       12.43  12.397   \n",
            "\n",
            "   fechamento_lag1 data_previsao  mercado_aberto  \n",
            "0            12.40    2025-04-09               1  \n",
            "1            12.41    2025-04-09               1  \n",
            "2            12.41    2025-04-09               1  \n",
            "3            12.44    2025-04-09               1  \n",
            "4            12.39    2025-04-09               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escrevendo o Readme do projeto\n",
        "%%writefile /content/Piloto_Day_Trade/README.md\n",
        "\n",
        "# Objetivo do Projeto\n",
        "\n",
        "## 1. Prop√≥sito do MVP\n",
        "\n",
        "Este projeto tem como objetivo principal a cria√ß√£o de um pipeline para extra√ß√£o, transforma√ß√£o, carga, an√°lise e previs√£o da movimenta√ß√£o intradi√°ria dos pre√ßos de um ativo financeiro em intervalos de 5 minutos. O modelo preditivo central ser√° baseado em redes neurais recorrentes (LSTM), mas outras abordagens ser√£o exploradas. O MVP visa garantir previs√µes para embasar decis√µes estrat√©gicas de day trade.\n",
        "\n",
        "## 2. Problema a Ser Resolvido\n",
        "\n",
        "A alta volatilidade dos mercados financeiros exige ferramentas robustas para antecipa√ß√£o de movimentos de pre√ßo. A dificuldade est√° em capturar padr√µes de curto prazo e projet√°-los com precis√£o. Traders e investidores necessitam de um modelo que consiga interpretar os padr√µes hist√≥ricos e transform√°-los em previs√µes √∫teis.\n",
        "\n",
        "## 3. Pipeline do Projeto\n",
        "\n",
        "O pipeline est√° estruturado em sete etapas principais:\n",
        "\n",
        "### 3.1. Extra√ß√£o e armazenamento dos dados brutos\n",
        "- Coleta de dados hist√≥ricos do ativo BBDC4 em intervalos de 5 minutos, via API do Yahoo Finance (yfinance).\n",
        "- Armazenamento dos dados no GitHub sincronizado com Google Colab, com backup em nuvem.\n",
        "- Salvo como `dados_brutos.csv`\n",
        "\n",
        "### 3.2. Limpeza e organiza√ß√£o dos dados\n",
        "- Padroniza√ß√£o dos tipos de dados\n",
        "- Padroniza√ß√£o dos nomes de colunas\n",
        "- Remo√ß√£o de valores nulos ou duplicados\n",
        "- Remo√ß√£o de colunas desnecess√°rias\n",
        "- Ordena√ß√£o cronol√≥gica\n",
        "- Salvo como `dados_limpos.csv`\n",
        "\n",
        "### 3.3. Transforma√ß√£o de dados e engenharia de features\n",
        "- C√°lculo de indicadores t√©cnicos (SMA, EMA, MACD, RSI, OBV)\n",
        "- C√°lculo de retornos e vari√¢ncia (volatilidade)\n",
        "- Cria√ß√£o de vari√°veis de lag de pre√ßo, volume e retorno\n",
        "- Adi√ß√£o de vari√°veis temporais (hora, dia da semana, mercado aberto)\n",
        "- Salvo como `dados_transformados.csv`\n",
        "\n",
        "### 3.4. Modelagem e estrutura√ß√£o do banco dimensional\n",
        "- **Fato**: `fato_precos` com pre√ßos e chave para `dim_tempo`\n",
        "- **Dimens√µes**:\n",
        "  - `dim_tempo`: data, hora, dia da semana\n",
        "  - `dim_indicadores`: indicadores t√©cnicos\n",
        "  - `dim_lags`: lags de pre√ßo, volume, retorno\n",
        "  - `dim_operacional`: hora, minuto, data da previs√£o, mercado aberto\n",
        "- Banco gerado em SQLite via script automatizado (`banco_dimensional.db`)\n",
        "\n",
        "### 3.5. Carga (ETL)\n",
        "- **Extra√ß√£o:** via API (automatizada)\n",
        "- **Limpeza:** padroniza√ß√£o, remo√ß√£o de nulos/duplicatas\n",
        "- **Transforma√ß√£o:** features t√©cnicas e derivadas\n",
        "- **Carga:** popula√ß√£o das tabelas do banco dimensional\n",
        "- ETL organizado em scripts Python e automatizado\n",
        "\n",
        "### 3.6. Treinamento e ajuste do modelo preditivo\n",
        "- **Prepara√ß√£o dos dados**:\n",
        "  - Padroniza√ß√£o com StandardScaler para retornos e indicadores\n",
        "  - Normaliza√ß√£o com MinMaxScaler para pre√ßos e volumes\n",
        "  - Separar features (X) e targets (y)\n",
        "  - Divis√£o treino/teste com base em dias √∫tis\n",
        "- **Modelo base:** LSTM com duas camadas ocultas, camada densa e MSE como perda\n",
        "- **Avalia√ß√£o:** M√©tricas de MSE, R¬≤, compara√ß√£o com targets reais\n",
        "\n",
        "### 3.7. An√°lise dos resultados\n",
        "- Comparativo entre pre√ßos previstos vs. reais\n",
        "- Valida√ß√£o das previs√µes para abertura, m√°xima, m√≠nima e fechamento\n",
        "- Import√¢ncia das vari√°veis\n",
        "- Interpreta√ß√£o dos erros e poss√≠veis melhorias\n",
        "\n",
        "## 4. Perguntas a Serem Respondidas\n",
        "- √â poss√≠vel prever com precis√£o a movimenta√ß√£o intradi√°ria a cada 5 minutos?\n",
        "- Os dados do dia anterior s√£o suficientes para prever o comportamento do dia seguinte?\n",
        "- O modelo LSTM √© eficaz para padr√µes de curt√≠ssimo prazo?\n",
        "- √â vi√°vel derivar os targets globais do dia a partir das previs√µes intradi√°rias?\n",
        "- Quais indicadores mais contribuem para a previs√£o?\n",
        "- Como lidar corretamente com fins de semana e feriados?\n",
        "- A padroniza√ß√£o/normaliza√ß√£o das vari√°veis afeta o desempenho?\n",
        "\n",
        "## 5. Crit√©rios de Sucesso\n",
        "- Pipeline funcional de extra√ß√£o ‚Üí transforma√ß√£o ‚Üí carga ‚Üí previs√£o\n",
        "- Modelo com bom desempenho em MSE e R¬≤\n",
        "- Targets globais coerentes com valores reais\n",
        "- Correta gest√£o de datas (incluindo segundas-feiras)\n",
        "- Previs√µes utiliz√°veis para tomada de decis√£o\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "SCo7OFDwSG35",
        "outputId": "1abecda6-cef8-4b37-8ab8-08ecdc6257b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escrevendo Licen√ßa do projeto\n",
        "%%writefile /content/Piloto_Day_Trade/LICENSE\n",
        "\n",
        "Copyright (c) 2025 Carolina Brescowitt\n",
        "\n",
        "Todos os direitos reservados.\n",
        "\n",
        "Este software √© fornecido gratuitamente apenas para uso **pessoal, acad√™mico e de pesquisa**.\n",
        "\n",
        "O uso comercial deste software √© estritamente proibido sem uma **licen√ßa comercial paga**, a ser negociada com o autor.\n",
        "\n",
        "Empresas, startups, desenvolvedores ou qualquer entidade que deseje utilizar este c√≥digo em produtos, servi√ßos ou plataformas comerciais devem entrar em contato com o autor para **negociar os termos de licenciamento** (incluindo percentual, royalties ou valores fixos).\n",
        "\n",
        "√â proibida a redistribui√ß√£o ou sublicenciamento sem autoriza√ß√£o por escrito.\n",
        "\n",
        "Para mais informa√ß√µes, entre em contato: carolbrescowitt@yahoo.com.br\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guTRpOgpsxDC",
        "outputId": "e3236b30-1401-4e22-96b1-d57c5ba4ebec"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem de dados"
      ],
      "metadata": {
        "id": "ai-nFsCPCE4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Prepara√ß√£o de dados para LSTM\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/modelagem_machine_learning/preparar_dados_modelagem_LSTM.py\n",
        "\n",
        "\"\"\"\n",
        "Fun√ß√£o que prepara os dados transformados para modelagem com LSTM:\n",
        "- Aplica normaliza√ß√£o e padroniza√ß√£o\n",
        "- Cria sequ√™ncias de entrada e sa√≠da\n",
        "- Divide em treino e teste\n",
        "- Salva o scaler de pre√ßo para uso posterior nas previs√µes\n",
        "\n",
        "Retorna:\n",
        "    X_treino, X_teste, y_treino, y_teste: arrays prontos para modelagem LSTM\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "def preparar_dados_lstm(\n",
        "    path_dados,       # Caminho do CSV com os dados\n",
        "    tam_seq=32,       # Tamanho da sequ√™ncia para entrada na LSTM\n",
        "    tx_treino=0.8     # Propor√ß√£o dos dados para treino\n",
        "):\n",
        "    # Caminho do scaler\n",
        "    caminho_scaler_preco = '/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'\n",
        "\n",
        "    # Criar diret√≥rio do scaler se n√£o existir\n",
        "    os.makedirs(os.path.dirname(caminho_scaler_preco), exist_ok=True)\n",
        "\n",
        "    # Carregar dados transformados\n",
        "    df = pd.read_csv(path_dados)\n",
        "\n",
        "    # Garantir colunas de data como datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "    df['data_previsao'] = pd.to_datetime(df['data_previsao'], errors='coerce')\n",
        "\n",
        "    # Definir colunas de pre√ßo\n",
        "    preco_cols = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Garantir que n√£o h√° valores ausentes nos pre√ßos\n",
        "    df = df.dropna(subset=preco_cols)\n",
        "\n",
        "    # Salvar scaler de pre√ßo com base nos valores reais (antes da normaliza√ß√£o)\n",
        "    scaler_preco = MinMaxScaler()\n",
        "    scaler_preco.fit(df[preco_cols])\n",
        "    joblib.dump(scaler_preco, caminho_scaler_preco)\n",
        "\n",
        "    print(\"Scaler de pre√ßo salvo com sucesso.\")\n",
        "\n",
        "    # Definir colunas para padroniza√ß√£o e normaliza√ß√£o\n",
        "    padronizar_cols = ['retorno', 'volatilidade', 'MACD', 'Signal_Line', 'rsi']\n",
        "    normalizar_cols = ['abertura', 'minimo', 'maximo', 'fechamento', 'volume', 'SMA_10', 'EMA_10', 'OBV',\n",
        "                       'fechamento_lag1', 'retorno_lag1', 'volume_lag1',\n",
        "                       'fechamento_lag2', 'retorno_lag2', 'volume_lag2',\n",
        "                       'fechamento_lag3', 'retorno_lag3', 'volume_lag3']\n",
        "\n",
        "    # Inicializar scalers\n",
        "    scaler_standard = StandardScaler()\n",
        "    scaler_minmax = MinMaxScaler()\n",
        "\n",
        "    # Aplicar transforma√ß√µes\n",
        "    df[padronizar_cols] = scaler_standard.fit_transform(df[padronizar_cols])\n",
        "    df[normalizar_cols] = scaler_minmax.fit_transform(df[normalizar_cols])\n",
        "\n",
        "    # Converter colunas categ√≥ricas para int\n",
        "    categorias = ['dia_da_semana_entrada', 'dia_da_semana_previsao', 'hora_num', 'minuto', 'mercado_aberto']\n",
        "    df[categorias] = df[categorias].astype(int)\n",
        "\n",
        "    # Manter apenas colunas num√©ricas\n",
        "    df = df.select_dtypes(include=['number'])\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Salvar versao dados preparados\n",
        "    caminho_csv_preparado = '/content/Piloto_Day_Trade/data/transformed/dados_preparados_para_modelagem.csv'\n",
        "    df.to_csv(caminho_csv_preparado, index=False)\n",
        "    print(f\"‚úÖ Dados preparados salvos em: {caminho_csv_preparado}\")\n",
        "\n",
        "\n",
        "    # Fun√ß√£o para criar sequ√™ncias\n",
        "    def criar_sequencias(dados, tam_seq):\n",
        "        entradas, saidas = [], []\n",
        "        for i in range(len(dados) - tam_seq - 1):\n",
        "            entradas.append(dados.iloc[i:i+tam_seq].values)\n",
        "            saidas.append(dados.iloc[i+1:i+1+tam_seq][['abertura', 'maximo', 'minimo', 'fechamento']].values)\n",
        "        return np.array(entradas), np.array(saidas)\n",
        "\n",
        "    # Gerar X e y\n",
        "    X, y = criar_sequencias(df, tam_seq)\n",
        "\n",
        "    # Dividir entre treino e teste\n",
        "    tamanho_treino = int(tx_treino * len(X))\n",
        "    X_treino, X_teste = X[:tamanho_treino], X[tamanho_treino:]\n",
        "    y_treino, y_teste = y[:tamanho_treino], y[tamanho_treino:]\n",
        "\n",
        "    return X_treino, X_teste, y_treino, y_teste\n",
        "\n",
        "\n",
        "# Execu√ß√£o direta\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTR1S1f9y-f",
        "outputId": "bd6b0c80-c2b5-457e-b99f-d26e499f9b4a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/preparar_dados_modelagem_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "\n",
        "path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "    path_dados=path_dados,\n",
        "    tam_seq=96,\n",
        "    tx_treino=0.8\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9h6GHiRyiRI",
        "outputId": "da87ebf3-7c58-4d4f-f4c7-49826ca79de8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de pre√ßo salvo com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criar e treinar o modelo LSTM (Movimenta√ß√£o Intradi√°ria)\n",
        "# %%writefile /content/Piloto_Day_Trade/scripts/modelo_LSTM_v1.py\n",
        "\n",
        "# Tentativa inicial - Modelo base LSTM para previs√£o intradi√°ria de pre√ßos\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# üîß Constru√ß√£o do modelo\n",
        "LSTM_model = Sequential([\n",
        "\n",
        "    # Camada LSTM 1:\n",
        "    # - 100 unidades (aumentado para maior capacidade de captura de padr√µes temporais)\n",
        "    # - return_sequences=True para passar a sequ√™ncia completa para a pr√≥xima camada\n",
        "    # - input_shape: (32, n√∫mero de features) - sequ√™ncia de 32 timesteps com n features\n",
        "    LSTM(100, return_sequences=True, input_shape=(X_treino.shape[1], X_treino.shape[2])),\n",
        "\n",
        "    # Dropout leve para reduzir overfitting sem perder muito sinal\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada LSTM 2:\n",
        "    # - Outra LSTM com 100 unidades\n",
        "    # - Tamb√©m retorna sequ√™ncia, pois a sa√≠da √© uma sequ√™ncia (32 timestamps com 4 pre√ßos)\n",
        "    LSTM(100, return_sequences=True),\n",
        "\n",
        "    # Outro Dropout leve\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada densa intermedi√°ria:\n",
        "    # - 64 neur√¥nios com ativa√ß√£o ReLU\n",
        "    # - Introduz n√£o-linearidade e ajuda a refinar a sa√≠da da LSTM antes da previs√£o final\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    # Camada de sa√≠da:\n",
        "    # - 4 unidades: prevendo abertura, m√°xima, m√≠nima e fechamento por timestamp\n",
        "    # - Sem ativa√ß√£o, sa√≠da cont√≠nua (valores de pre√ßos normalizados)\n",
        "    Dense(4)\n",
        "])\n",
        "\n",
        "# üß† Compila√ß√£o do modelo\n",
        "# - Otimizador Adam, bom para problemas n√£o estacion√°rios como s√©ries temporais\n",
        "# - Fun√ß√£o de perda MSE (erro quadr√°tico m√©dio), apropriado para regress√£o\n",
        "LSTM_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# üöÇ Treinamento do modelo\n",
        "# - 20 √©pocas: n√∫mero inicial para observar o desempenho\n",
        "# - batch_size=16: menor para atualizar pesos com frequ√™ncia e lidar com varia√ß√£o dos dados\n",
        "historico = LSTM_model.fit(\n",
        "    X_treino, y_treino,\n",
        "    validation_data=(X_teste, y_teste),\n",
        "    epochs=20,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6lFmK-FMncY",
        "outputId": "140ed98d-f6ff-4f70-a3b2-1c3d6b255084"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 122ms/step - loss: 0.0654 - val_loss: 0.0076\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0059 - val_loss: 0.0049\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0015 - val_loss: 0.0026\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 115ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - loss: 9.3821e-04 - val_loss: 0.0024\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 8.7632e-04 - val_loss: 0.0018\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 116ms/step - loss: 8.1019e-04 - val_loss: 0.0019\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 7.5255e-04 - val_loss: 0.0015\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - loss: 8.4505e-04 - val_loss: 0.0021\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - loss: 7.6089e-04 - val_loss: 0.0016\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - loss: 6.6421e-04 - val_loss: 0.0020\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - loss: 6.3165e-04 - val_loss: 0.0018\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - loss: 6.2296e-04 - val_loss: 0.0017\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 5.9292e-04 - val_loss: 0.0020\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - loss: 6.8025e-04 - val_loss: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Incluindo Modelo LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiGwgsI6p9IC",
        "outputId": "d8d09ca7-1920-49f9-e63a-9307fb770ae6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Nenhuma altera√ß√£o para comitar.\n",
            "‚úÖ Reposit√≥rio atualizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Salvar LSTM versao 1\n",
        "# Criar diret√≥rio para modelos, se n√£o existir\n",
        "import os\n",
        "path_modelo = '/content/Piloto_Day_Trade/models/LSTM_v1'\n",
        "os.makedirs(path_modelo, exist_ok=True)\n",
        "\n",
        "# Salvar o modelo completo (estrutura + pesos + otimizador)\n",
        "LSTM_model.save(f'{path_modelo}/modelo_completo.keras')\n",
        "\n",
        "print(\"‚úÖ Modelo LSTM_v1 salvo com sucesso!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSGaNfmtKwU6",
        "outputId": "8cf550f2-653b-4212-f5bf-b726a277ebe0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM_v1 salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n",
        "\n",
        "#@title Calcular m√©tricas e avaliar modelo LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def avaliar_modelo_lstm(modelo, X_teste, y_teste, caminho_scaler='/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'):\n",
        "    \"\"\"\n",
        "    Avalia um modelo LSTM fornecido, imprimindo as principais m√©tricas e compara√ß√£o entre previs√µes e valores reais.\n",
        "\n",
        "    Par√¢metros:\n",
        "        modelo: modelo LSTM treinado\n",
        "        X_teste: dados de entrada de teste\n",
        "        y_teste: dados reais (targets) correspondentes ao teste\n",
        "        caminho_scaler: caminho do scaler salvo para invers√£o da normaliza√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    # Fazer previs√µes\n",
        "    y_previsto = modelo.predict(X_teste)\n",
        "\n",
        "    # Carregar o scaler de pre√ßos\n",
        "    scaler_precos = joblib.load(caminho_scaler)\n",
        "\n",
        "    # Colunas de pre√ßo\n",
        "    colunas_precos = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Redimensionar para (amostras, 4)\n",
        "    y_previsto_reshape = y_previsto.reshape(-1, 4)\n",
        "    y_teste_reshape = y_teste.reshape(-1, 4)\n",
        "\n",
        "    # Inverter normaliza√ß√£o\n",
        "    y_previsto_original = scaler_precos.inverse_transform(y_previsto_reshape)\n",
        "    y_teste_original = scaler_precos.inverse_transform(y_teste_reshape)\n",
        "\n",
        "    # DataFrames nomeados\n",
        "    df_previsto = pd.DataFrame(y_previsto_original, columns=colunas_precos)\n",
        "    df_real = pd.DataFrame(y_teste_original, columns=colunas_precos)\n",
        "\n",
        "    # Compara√ß√£o\n",
        "    comparacao = pd.DataFrame({\n",
        "        'Abertura_Real': df_real['abertura'],\n",
        "        'Abertura_Prevista': df_previsto['abertura'],\n",
        "        'Maximo_Real': df_real['maximo'],\n",
        "        'Maximo_Previsto': df_previsto['maximo'],\n",
        "        'Minimo_Real': df_real['minimo'],\n",
        "        'Minimo_Previsto': df_previsto['minimo'],\n",
        "        'Fechamento_Real': df_real['fechamento'],\n",
        "        'Fechamento_Previsto': df_previsto['fechamento']\n",
        "    })\n",
        "\n",
        "    print(\"\\nüìä Compara√ß√£o de previs√µes (valores reais):\")\n",
        "    print(comparacao.head(10))\n",
        "\n",
        "    # Fun√ß√£o auxiliar para m√©tricas\n",
        "    def calcular_metricas(y_real, y_previsto, nome):\n",
        "        mae = mean_absolute_error(y_real, y_previsto)\n",
        "        mse = mean_squared_error(y_real, y_previsto)\n",
        "        r2 = r2_score(y_real, y_previsto)\n",
        "        print(f\"{nome} - MAE: {mae:.4f}, MSE: {mse:.4f}, R¬≤: {r2:.4f}\")\n",
        "\n",
        "    print(\"\\nüìà M√©tricas de desempenho por coluna:\")\n",
        "    calcular_metricas(df_real['abertura'], df_previsto['abertura'], \"Abertura\")\n",
        "    calcular_metricas(df_real['maximo'], df_previsto['maximo'], \"M√°ximo\")\n",
        "    calcular_metricas(df_real['minimo'], df_previsto['minimo'], \"M√≠nimo\")\n",
        "    calcular_metricas(df_real['fechamento'], df_previsto['fechamento'], \"Fechamento\")\n",
        "\n",
        "    return df_real, df_previsto, comparacao\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FOx4USVH-3l",
        "outputId": "cd06638c-f6d7-401f-c2b4-14b9521ada70",
        "cellView": "form"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.calcular_metricas_avaliar_modelo import avaliar_modelo_lstm\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Caminhos e dados preparados\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "\n",
        "    # Preparar dados\n",
        "    from scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n",
        "\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1/modelo_completo.keras')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QigGTL3DWGTb",
        "outputId": "58a046aa-1ae2-4b7e-9f33-859a9b207bf8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de pre√ßo salvo com sucesso.\n",
            "‚úÖ Dados preparados salvos em: /content/Piloto_Day_Trade/data/transformed/dados_preparados_para_modelagem.csv\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step\n",
            "\n",
            "üìä Compara√ß√£o de previs√µes (valores reais):\n",
            "   Abertura_Real  Abertura_Prevista  Maximo_Real  Maximo_Previsto  \\\n",
            "0          11.75          11.797084        11.77        11.819266   \n",
            "1          11.75          11.738138        11.78        11.759627   \n",
            "2          11.77          11.735560        11.79        11.759824   \n",
            "3          11.78          11.764517        11.80        11.790069   \n",
            "4          11.78          11.761155        11.78        11.788537   \n",
            "5          11.75          11.758376        11.79        11.787605   \n",
            "6          11.76          11.758621        11.77        11.789828   \n",
            "7          11.75          11.727757        11.77        11.762376   \n",
            "8          11.75          11.699660        11.76        11.733210   \n",
            "9          11.75          11.666211        11.78        11.696817   \n",
            "\n",
            "   Minimo_Real  Minimo_Previsto  Fechamento_Real  Fechamento_Previsto  \n",
            "0        11.73        11.796309            11.77            11.799382  \n",
            "1        11.75        11.740110            11.78            11.744620  \n",
            "2        11.76        11.733368            11.79            11.743937  \n",
            "3        11.73        11.755706            11.76            11.771626  \n",
            "4        11.72        11.750199            11.75            11.768753  \n",
            "5        11.75        11.745906            11.76            11.765841  \n",
            "6        11.75        11.743665            11.75            11.764983  \n",
            "7        11.75        11.710895            11.75            11.734612  \n",
            "8        11.74        11.682524            11.75            11.707520  \n",
            "9        11.75        11.650184            11.78            11.675851  \n",
            "\n",
            "üìà M√©tricas de desempenho por coluna:\n",
            "Abertura - MAE: 0.0606, MSE: 0.0061, R¬≤: 0.7450\n",
            "M√°ximo - MAE: 0.0561, MSE: 0.0056, R¬≤: 0.7650\n",
            "M√≠nimo - MAE: 0.0647, MSE: 0.0065, R¬≤: 0.7285\n",
            "Fechamento - MAE: 0.0602, MSE: 0.0060, R¬≤: 0.7485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline de dados"
      ],
      "metadata": {
        "id": "TTzGcdW3uxIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for nome in os.listdir('/content/Piloto_Day_Trade/scripts'):\n",
        "    print(nome)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX641OOUuztF",
        "outputId": "6a417acf-8ba6-46c2-c70b-92398e23b6d0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operacional\n",
            "Pipelines\n",
            "Modelagem_machine_learning\n",
            "__pycache__\n",
            ".ipynb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def listar_arquivos_em_subpastas(pasta_base):\n",
        "    for raiz, subpastas, arquivos in os.walk(pasta_base):\n",
        "        nivel = raiz.replace(pasta_base, '').count(os.sep)\n",
        "        indent = ' ' * 4 * nivel\n",
        "        print(f\"{indent}{os.path.basename(raiz)}/\")\n",
        "        subindent = ' ' * 4 * (nivel + 1)\n",
        "        for arquivo in arquivos:\n",
        "            print(f\"{subindent}{arquivo}\")\n",
        "\n",
        "# Caminho da pasta onde est√£o os scripts\n",
        "pasta_scripts = \"/content/Piloto_Day_Trade/scripts\"\n",
        "listar_arquivos_em_subpastas(pasta_scripts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5_tfm2NxWQy",
        "outputId": "a938068d-3867-409d-e726-fa979b11a5bb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scripts/\n",
            "    Operacional/\n",
            "        configurar_git.py\n",
            "        .ipynb_checkpoints/\n",
            "    Pipelines/\n",
            "        criar_banco_dimensional.py\n",
            "        limpeza_dados.py\n",
            "        carga_dados.py\n",
            "        gerar_catalogo_dados.py\n",
            "        transformacao_dados.py\n",
            "        extracao_dados.py\n",
            "    Modelagem_machine_learning/\n",
            "        preparar_dados_modelagem_LSTM.py\n",
            "        previsoes_XGBoot.py\n",
            "        modelo_LSTM_v1.py\n",
            "        calcular_metricas_avaliar_modelo_LSTM.py\n",
            "        calcular_metricas_avaliar_modelo.py\n",
            "    __pycache__/\n",
            "        transformacao_dados_v2.cpython-311.pyc\n",
            "        calcular_metricas_avaliar_modelo.cpython-311.pyc\n",
            "        preparar_dados_modelagem_LSTM.cpython-311.pyc\n",
            "        extracao_dados.cpython-311.pyc\n",
            "        transformacao_dados.cpython-311.pyc\n",
            "        gerar_catalogo.cpython-311.pyc\n",
            "        limpeza_basica_dadosv2.cpython-311.pyc\n",
            "        gerar_catalogo_dados.cpython-311.pyc\n",
            "        limpeza_dados.cpython-311.pyc\n",
            "        extracao_dados_v2.cpython-311.pyc\n",
            "    .ipynb_checkpoints/\n",
            "        modelagem_dados_XGBoot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### Transformer para Capturar Tend√™ncias de Longo Prazo:\n",
        "\n",
        "\"\"\"\n",
        "Entrada: √öltimos dias √∫teis para identificar padr√µes de pre√ßo.\n",
        "\n",
        "Sa√≠da: Pre√ßos de abertura, m√°xima, m√≠nima e fechamento do pr√≥ximo dia √∫til.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7oG7QwBtKqT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}