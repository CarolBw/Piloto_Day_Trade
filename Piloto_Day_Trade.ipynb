{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXHMLxtWZFb2KUcDNmCAC7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolBw/Piloto_Day_Trade/blob/main/Piloto_Day_Trade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/MVP_Objetivo.md\n",
        "#@title **Objetivo do Projeto**\n",
        "\n",
        "### 1. Propósito do MVP\n",
        "\n",
        "Este projeto tem como objetivo principal a criação de um pipeline para extração, transformação, carga, análise e previsão da movimentação intradiária dos preços de um ativo financeiro em intervalos de 5 minutos. O modelo preditivo central será baseado em redes neurais recorrentes (LSTM), mas outras abordagens serão exploradas. O MVP visa garantir previsões para embasar decisões estratégicas de day trade.\n",
        "\n",
        "### 2. Problema a Ser Resolvido\n",
        "\n",
        "A alta volatilidade dos mercados financeiros exige ferramentas robustas para antecipação de movimentos de preço. A dificuldade está em capturar padrões de curto prazo e projetá-los com precisão. Traders e investidores necessitam de um modelo que consiga interpretar os padrões históricos e transformá-los em previsões úteis.\n",
        "\n",
        "### 3. Pipeline do Projeto\n",
        "\n",
        "O projeto será estruturado em sete etapas principais:\n",
        "\n",
        "1. **Extração e armazenamento dos dados brutos:** Coleta de dados históricos de ativos financeiros em intervalos de 15 minutos utilizando a API do Yahoo Finance (yfinance). Os dados serão armazenados em um repositório GitHub sincronizado com Google Colab, garantindo acesso remoto e backup na nuvem.\n",
        "\n",
        "2. **Limpeza e organização dos dados:** Padronização de colunas, tratamento de dados ausentes, eliminação de duplicatas e organização cronológica. Resultado salvo como `dados_limpos.csv`.\n",
        "\n",
        "3. **Transformação e engenharia de features:** Adição de indicadores técnicos (como médias móveis, RSI, MACD), criação de variáveis de lag e retornos. Resultado salvo como `dados_transformados.csv`.\n",
        "\n",
        "4. **Modelagem e estruturação do banco de dados:**\n",
        "\n",
        "   a) Organização em arquivos CSV:\n",
        "\n",
        "   - `dados_brutos.csv`: dados originais extraídos da API.\n",
        "   - `dados_limpos.csv`: após limpeza e padronização.\n",
        "   - `dados_transformados.csv`: após adição de features técnicas.\n",
        "   - `dados_final.csv`: versão padronizada e normalizada dos dados.\n",
        "\n",
        "   b) Banco de dados dimensional:\n",
        "\n",
        "   - **Fato**: `fato_precos`, contendo os valores de fechamento e chaves para dimensões.\n",
        "   - **Dimensões**:\n",
        "     - `dim_tempo`: atributos temporais.\n",
        "     - `dim_indicadores`: indicadores técnicos.\n",
        "     - `dim_lags`: variações e lags recentes.\n",
        "\n",
        "   Um **Catálogo de Dados** será elaborado com descrição, domínio, categorias e linhagem de cada variável.\n",
        "\n",
        "5. **Carga e Pipeline ETL:** Pipeline estruturado com as seguintes etapas:\n",
        "\n",
        "   - **Extração:** via API do Yahoo Finance.\n",
        "   - **Limpeza:** tratamento e estruturação básica.\n",
        "   - **Transformação:** geração de variáveis técnicas e derivadas.\n",
        "   - **Carga:** integração dos dados transformados no banco dimensional (fato e dimensões).\n",
        "\n",
        "6. **Treinamento e ajuste do modelo:** Implementação e ajuste de modelos preditivos (LSTM como baseline), com avaliação por métricas como MSE e R².\n",
        "\n",
        "7. **Interpretação dos resultados e resposta às perguntas:** Validação das previsões, análise de variáveis relevantes e contribuição dos resultados para decisões de trading.\n",
        "\n",
        "### 4. Perguntas a Serem Respondidas\n",
        "\n",
        "- É possível prever com precisão a movimentação intradiária de um ativo a cada 15 minutos?\n",
        "- Os dados do dia anterior fornecem informações suficientes para a previsão do dia seguinte?\n",
        "- A modelagem com LSTM captura corretamente as tendências de curto prazo?\n",
        "- A previsão da movimentação intradiária também permite derivar com precisão as targets globais do dia (abertura, mínima, máxima e fechamento)?\n",
        "- Quais indicadores técnicos e features são mais relevantes para melhorar a acurácia do modelo?\n",
        "- Como considerar corretamente as quebras de fim de semana (exemplo: prever a segunda-feira usando os dados de sexta-feira)?\n",
        "- A normalização e padronização das variáveis melhora a precisão do modelo?\n",
        "\n",
        "### 5. Critérios de Sucesso\n",
        "\n",
        "Para que o MVP seja considerado bem-sucedido o esperado é que:\n",
        "\n",
        "1. O pipeline de extração, transformação e previsão funcione de forma eficiente.\n",
        "2. O modelo consiga prever a movimentação dos preços com um erro médio aceitável (avaliado por MSE ou R2).\n",
        "3. A previsão de targets globais (abertura, máxima, mínima, fechamento) seja consistente com os valores reais.\n",
        "4. O modelo consiga lidar corretamente com fins de semana e feriados.\n",
        "5. As previsões sejam suficientes para auxiliar na tomada de decisão de trading.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj0A_HHDW-dj",
        "outputId": "348639af-f378-4de3-a892-f885ffd4b4d7",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/MVP_Objetivo.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "No6u9fG0h8-A",
        "outputId": "5ef92609-2fc7-4899-8506-2fe3d9877742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.env\n"
          ]
        }
      ],
      "source": [
        "#@title ## Escrevendo variáveis sensiveis\n",
        "\n",
        "%%writefile /content/.env\n",
        "\n",
        "PROJECT_NAME=Piloto_Day_Trade\n",
        "\n",
        "# Variáveis de ambiente para o Github\n",
        "GITHUB_USERNAME=CarolBw\n",
        "GITHUB_TOKEN =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\n",
        "EMAIL=carolbrescowitt@yahoo.com.br\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Instalando dependências\n",
        "'''\n",
        "Usamos `-q` para ocultar a saída detalhada e mostrar apenas a barra de progresso\n",
        "\n",
        "'''\n",
        "!pip install -q tensorflow > /dev/null  # Framework para redes neurais e deep learning\n",
        "!pip install -q keras > /dev/null  # Biblioteca de alto nível para redes neurais\n",
        "!pip install -q pandas > /dev/null  # Manipulação e análise de dados\n",
        "!pip install -q numpy > /dev/null  # Computação numérica eficiente\n",
        "!pip install -q matplotlib > /dev/null  # Visualização de gráficos e análise exploratória\n",
        "!pip install -q scikit-learn > /dev/null  # Ferramentas para pré-processamento e métricas de avaliação\n",
        "!pip install -q gitpython > /dev/null  # Gerenciamento de repositórios Git via Python\n",
        "!pip install -q python-dotenv > /dev/null  # Manipulação de variáveis de ambiente\n",
        "!pip install -q seaborn > /dev/null  # Biblioteca de visualização estatística baseada no Matplotlib\n",
        "!pip install -q yfinance > /dev/null  # Coleta de dados financeiros diretamente do Yahoo Finance\n",
        "!pip install -q sqlalchemy > /dev/null  # ORM para interagir com bancos de dados relacionais\n",
        "!pip install -q dotenv > /dev/null # Manipulação de variáveis de ambiente\n",
        "\n",
        "# Importações das bibliotecas\n",
        "import pandas as pd  # Manipulação de DataFrames\n",
        "import numpy as np  # Cálculos numéricos e matrizes\n",
        "import matplotlib.pyplot as plt  # Geração de gráficos\n",
        "import sqlite3  # Integração com banco de dados SQLite\n",
        "\n",
        "# Pré-processamento dos dados\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Normalização e padronização dos dados\n",
        "from sklearn.model_selection import train_test_split  # Divisão dos dados em treino e teste\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # Avaliação do desempenho do modelo\n",
        "\n",
        "# Construção do modelo preditivo\n",
        "from keras.models import Sequential  # Modelo sequencial de rede neural\n",
        "from keras.layers import Dense  # Camada densa para aprendizado profundo\n",
        "\n",
        "# Controle de versão e variáveis de ambiente\n",
        "import git  # Gerenciamento do repositório Git\n",
        "import dotenv  # Carregamento de variáveis de ambiente\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LWOFHzJ6IupA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capturamdo todas as dependencias do ambiente nesta primeira etapa\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "ujEHOrH9cTIQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Configurando sincronização com Github\n",
        "\n",
        "%%writefile /content/configurar_git.py\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "def git_config():\n",
        "    \"\"\"Configura o Git localmente e sincroniza com o repositório remoto no GitHub.\"\"\"\n",
        "\n",
        "    # Carregar variáveis de ambiente do arquivo .env\n",
        "    load_dotenv(dotenv_path='/content/.env')\n",
        "\n",
        "    # Obter as variáveis de ambiente do .env para o GitHub\n",
        "    GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
        "    EMAIL = os.getenv('EMAIL')\n",
        "    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "    PROJECT_NAME = os.getenv('PROJECT_NAME')\n",
        "    REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{PROJECT_NAME}.git\"\n",
        "\n",
        "    # Configurar o Git localmente com as credenciais\n",
        "    os.system(f'git config --global user.name \"{GITHUB_USERNAME}\"')\n",
        "    os.system(f'git config --global user.email \"{EMAIL}\"')\n",
        "\n",
        "    # Verificar se o diretório do projeto já existe e se é um repositório Git válido\n",
        "    if os.path.isdir(PROJECT_NAME):\n",
        "        print(f\"O diretório '{PROJECT_NAME}' já existe. Entrando no diretório e sincronizando...\")\n",
        "\n",
        "        os.chdir(PROJECT_NAME)  # Entrar na pasta do projeto\n",
        "\n",
        "        # Garantir que estamos na branch main\n",
        "        os.system(\"git branch -M main\")\n",
        "\n",
        "        # Remover qualquer configuração errada do repositório remoto e adicionar novamente\n",
        "        os.system(\"git remote remove origin\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Puxar as últimas atualizações do GitHub, tratando históricos não relacionados\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "    else:\n",
        "        print(f\"Clonando o repositório '{PROJECT_NAME}'...\")\n",
        "\n",
        "        # Clonar o repositório remoto\n",
        "        os.system(f\"git clone {REPO_URL}\")\n",
        "        os.chdir(PROJECT_NAME)  # Entrar no diretório após o clone\n",
        "\n",
        "        # Inicializar o repositório Git local (se necessário) e configurar remoto\n",
        "        os.system(\"git branch -M main\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Realizar o pull inicial para garantir que a branch main está sincronizada\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "\n",
        "    print(f\"✅ Configuração do Git concluída e sincronizada com a branch main do repositório{REPO_URL}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    git_config()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSdFzemI9yY",
        "outputId": "154b58ee-0461-46ce-f76b-1466ab6f1f81",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/configurar_git.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sincronizando repositório\n",
        "\n",
        "from configurar_git import git_config\n",
        "git_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLWe41oYxhcr",
        "outputId": "050c3fac-5220-4a76-fc97-4cfacd12f4c8",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando o repositório 'Piloto_Day_Trade'...\n",
            "✅ Configuração do Git concluída e sincronizada com a branch main do repositóriohttps://CarolBw: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@github.com/CarolBw/Piloto_Day_Trade.git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Definindo estrutura de pastas do projeto\n",
        "\n",
        "\"\"\"\n",
        "Estrutura inicial do repositório Piloto_Day_Trade:\n",
        "\n",
        "|- notebooks/         → Jupyter Notebooks para exploração e análises\n",
        "|- scripts/           → Funções reutilizáveis (pré-processamento, modelagem, avaliação, etc.)\n",
        "|- data/              → Dados organizados em 3 níveis:\n",
        "   |- raw/            → Dados brutos extraídos diretamente de fontes externas\n",
        "   |- cleaned/        → Dados limpos com tratamento básico (ex: datas, nulos, nomes de colunas)\n",
        "   |- transformed/    → Dados com features criadas e prontos para modelagem\n",
        "|- modelagem/         → Modelagem do banco de dados.\n",
        "   |- database/       → Banco de dados\n",
        "   |- catalog/        → Catálogo de dados\n",
        "   |- esquema/        → Esquema do banco de dados\n",
        "|- workflows/         → Pipelines\n",
        "|- models/            → Modelos treinados\n",
        "   |- scalers/        → Scalers salvos (MinMaxScaler, StandardScaler, etc.)\n",
        "|- reports/           → Resultados, gráficos, relatórios de performance\n",
        "|- MVP_Objetivo.md    → Documento explicando o objetivo do projeto\n",
        "|- README.md          → Instruções gerais do projeto\n",
        "|-.env                → Variáveis de ambiente e configurações sensíveis\n",
        "|- requirements.txt   → Lista de dependências\n",
        "|- LICENCE            → Licença do projeto\n",
        "\"\"\"\n",
        "\n",
        "# Criar estrutura de diretórios\n",
        "%cd /content/\n",
        "\n",
        "!mkdir -p /content/Piloto_Day_Trade/notebooks\n",
        "!mkdir -p /content/Piloto_Day_Trade/scripts\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/raw\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/cleaned\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/transformed\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/catalog\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/esquema\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/database\n",
        "!mkdir -p /content/Piloto_Day_Trade/models\n",
        "!mkdir -p /content/Piloto_Day_Trade/models/scalers\n",
        "!mkdir -p /content/Piloto_Day_Trade/reports\n",
        "!mkdir -p /content/Piloto_Day_Trade/workflows\n",
        "\n",
        "# Criar arquivos principais\n",
        "!touch /content/Piloto_Day_Trade/.gitignore\n",
        "!touch /content/Piloto_Day_Trade/README.md\n",
        "!touch /content/Piloto_Day_Trade/LICENCE\n",
        "\n"
      ],
      "metadata": {
        "id": "vVkhl3kbZKbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "53461433-e610-44b9-aece-7a801778087b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mover arquivos existentes (ajuste conforme seus arquivos reais)\n",
        "!mv /content/.env /content/Piloto_Day_Trade/.env\n",
        "!mv /content/configurar_git.py /content/Piloto_Day_Trade/scripts/Operacional/configurar_git.py\n",
        "!mv /content/requirements.txt /content/Piloto_Day_Trade/requirements.txt\n",
        "!mv /content/MVP_Objetivo.md /content/Piloto_Day_Trade/MVP_Objetivo.md"
      ],
      "metadata": {
        "id": "6YEIOMuuWI4K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver estrutura de diretórios\n",
        "!apt-get install tree -y > /dev/null 2>&1 # Instala o tree e oculta a saida da instalação\n",
        "!tree /content/Piloto_Day_Trade -d\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X7oQ6eFTvuc",
        "outputId": "4cd686eb-6e06-4376-f467-d32bd6572321"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m/content/Piloto_Day_Trade\u001b[0m\n",
            "├── \u001b[01;34mdata\u001b[0m\n",
            "│   ├── \u001b[01;34mcleaned\u001b[0m\n",
            "│   ├── \u001b[01;34mraw\u001b[0m\n",
            "│   └── \u001b[01;34mtransformed\u001b[0m\n",
            "├── \u001b[01;34mmodelagem\u001b[0m\n",
            "│   ├── \u001b[01;34mcatalog\u001b[0m\n",
            "│   ├── \u001b[01;34mdatabase\u001b[0m\n",
            "│   └── \u001b[01;34mesquema\u001b[0m\n",
            "├── \u001b[01;34mmodels\u001b[0m\n",
            "│   ├── \u001b[01;34mLSTM_v1\u001b[0m\n",
            "│   ├── \u001b[01;34mscalers\u001b[0m\n",
            "│   └── \u001b[01;34mXGBoost_v1\u001b[0m\n",
            "├── \u001b[01;34mnotebooks\u001b[0m\n",
            "├── \u001b[01;34mreports\u001b[0m\n",
            "├── \u001b[01;34mscripts\u001b[0m\n",
            "│   ├── \u001b[01;34mModelagem_machine_learning\u001b[0m\n",
            "│   ├── \u001b[01;34mOperacional\u001b[0m\n",
            "│   ├── \u001b[01;34mPipelines\u001b[0m\n",
            "│   └── \u001b[01;34m__pycache__\u001b[0m\n",
            "└── \u001b[01;34mworkflows\u001b[0m\n",
            "\n",
            "20 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função operacional\n",
        "# para atualizar o repositório facilmente ao longo do desenvolvimento sem erros de sincronização\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def atualizar_repo(commit_message):\n",
        "    \"\"\"Atualiza o repositório remoto e mostra quantos arquivos foram comitados.\"\"\"\n",
        "    repo_path = \"/content/Piloto_Day_Trade\"\n",
        "\n",
        "    if not os.path.exists(os.path.join(repo_path, \".git\")):\n",
        "        print(\"🚫 Este diretório não é um repositório Git.\")\n",
        "        return\n",
        "\n",
        "    os.chdir(repo_path)\n",
        "\n",
        "    # Adiciona todos os arquivos\n",
        "    subprocess.run([\"git\", \"add\", \".\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    # Executa o commit e captura a saída completa (stdout + stderr)\n",
        "    result = subprocess.run(\n",
        "        [\"git\", \"commit\", \"-m\", commit_message],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    # Juntamos as saídas para análise\n",
        "    output = result.stdout + result.stderr\n",
        "\n",
        "    if \"files changed\" in output:\n",
        "        # Procura a linha com o resumo da alteração\n",
        "        for linha in output.splitlines():\n",
        "            if \"files changed\" in linha:\n",
        "                print(f\"📝 {linha}\")\n",
        "                break\n",
        "    elif \"nothing to commit\" in output:\n",
        "        print(\"ℹ️ Nenhuma alteração para comitar.\")\n",
        "    else:\n",
        "        print(\"⚠️ Resultado inesperado do Git:\")\n",
        "        print(output)\n",
        "\n",
        "    # Envia para o repositório remoto\n",
        "    subprocess.run([\"git\", \"push\", \"origin\", \"main\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    print(\"✅ Repositório atualizado.\")\n"
      ],
      "metadata": {
        "id": "TGqg5UeqMKbl",
        "cellView": "form"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Extração de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/extracao_dados.py\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "def extrair_dados(ticker, dias, intervalo, dados_brutos):\n",
        "    \"\"\"Extrai e organiza dados do Yahoo Finance no intervalo correto.\"\"\"\n",
        "\n",
        "    df_total = pd.DataFrame()  # DataFrame para armazenar os dados\n",
        "    data_inicio = datetime.today() - timedelta(days=dias)  # Data inicial\n",
        "    data_fim = datetime.today() + timedelta(days=1)\n",
        "\n",
        "    # Verifica se o arquivo de dados brutos existe\n",
        "    if os.path.exists(dados_brutos):\n",
        "        df = pd.read_csv(dados_brutos, index_col=0, parse_dates=True)\n",
        "\n",
        "        if not df.empty:\n",
        "            # Atualiza a data de início para a última data disponível nos dados brutos\n",
        "            ultima_data = pd.to_datetime(df.index.max())\n",
        "            data_inicio = ultima_data + timedelta(minutes=30)\n",
        "\n",
        "    print(f\"🔄 Extraindo dados de {data_inicio.strftime('%Y-%m-%d %H:%M:%S')} até {data_fim.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # Extrai os dados do Yahoo Finance\n",
        "    df_novo = yf.download(\n",
        "        ticker,\n",
        "        start=data_inicio.strftime(\"%Y-%m-%d\"),\n",
        "        end=data_fim.strftime(\"%Y-%m-%d\"),\n",
        "        interval=intervalo,\n",
        "        progress=True\n",
        "    )\n",
        "\n",
        "    if not df_novo.empty:\n",
        "        # Apenas converte para \"America/Sao_Paulo\" se já tiver timezone\n",
        "        if df_novo.index.tzinfo is not None:\n",
        "            df_novo.index = df_novo.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "        # Concatena os novos dados com os existentes e remove duplicatas\n",
        "        df_total = pd.concat([df_total, df_novo]).drop_duplicates().sort_index()\n",
        "\n",
        "        # Remove linhas com mais de 50% de valores nulos\n",
        "        df_total = df_total.dropna(thresh=df_total.shape[1] * 0.5)\n",
        "\n",
        "        # Salva os dados atualizados no arquivo CSV\n",
        "        df_total.to_csv(dados_brutos)\n",
        "        print(\"✅ Dados salvos com sucesso.\")\n",
        "\n",
        "    # Filtra os dados para o horário entre 10:00 e 18:00\n",
        "    df_filtrado = df_total.between_time(\"10:00\", \"18:00\")\n",
        "\n",
        "    # Exibe os 10 primeiros e os 10 últimos registros\n",
        "    print(\"Últimos 10 dados filtrados:\")\n",
        "    print(df_filtrado.tail(10))\n",
        "    print(\"Primeiros 10 dados filtrados:\")\n",
        "    print(df_filtrado.head(10))\n",
        "\n",
        "    return df_filtrado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ticker = \"BBDC4.SA\"  # Ticker da ação\n",
        "    intervalo = \"5m\"  # Intervalo de tempo (5 minutos)\n",
        "    dias = 45  # Número de dias a partir de hoje para buscar os dados\n",
        "    dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "    df = extrair_dados(ticker, dias, intervalo, dados_brutos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3JYaCsNw5fQ",
        "outputId": "1e257a07-e4c0-4a06-ebb3-7b8ca7be8aeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/extracao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executando extração de dados extração de dados\n",
        "from Piloto_Day_Trade.scripts.Pipeline.extracao_dados import extrair_dados\n",
        "\n",
        "ticker = \"BBDC4.SA\"  # Ticker da ação\n",
        "intervalo = \"5m\"  # Intervalo de tempo\n",
        "dias = 45  # Número de dias a partir de hoje para buscar os dados\n",
        "dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "df = extrair_dados(ticker, dias, intervalo, dados_brutos)"
      ],
      "metadata": {
        "id": "OgEhS9Rwx_Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Limpeza de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/limpeza_dados.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def limpeza_dados(df):\n",
        "    # Verificar se os dados estão corretos\n",
        "    print(\"Dados originais:\")\n",
        "    print(df.head())\n",
        "    print(df.info())\n",
        "\n",
        "    # Remover as primeiras duas linhas (com 'Ticker' e 'Datetime')\n",
        "    df = df.iloc[2:].copy()\n",
        "\n",
        "    # Verificar após a remoção das linhas iniciais\n",
        "    print(\"Após remoção das duas primeiras linhas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que o índice esteja no formato de data e hora (timezone UTC)\n",
        "    df.index = pd.to_datetime(df.index, utc=True)\n",
        "\n",
        "    # Definir o fuso horário como \"America/Sao_Paulo\"\n",
        "    df.index = df.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "    # Remover a referência de fuso horário (deixar o horário local sem informação de timezone)\n",
        "    df.index = df.index.tz_localize(None)\n",
        "\n",
        "    # Criar a coluna 'hora' com base no índice\n",
        "    df['hora'] = df.index.strftime('%H:%M:%S')\n",
        "\n",
        "    # Renomear o índice para 'data'\n",
        "    df.index.name = 'data'\n",
        "\n",
        "    # Resetar o índice para transformar o Datetime em uma coluna normal\n",
        "    df = df.reset_index()\n",
        "\n",
        "    # Verificar após a transformação do índice\n",
        "    print(\"\\nApós conversão de índice:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Remover o horário da coluna 'data', mantendo apenas a data\n",
        "    df['data'] = df['data'].dt.date\n",
        "\n",
        "    # Mapeamento das colunas para nomes padronizados\n",
        "    mapeamento_colunas = {\n",
        "        'Close': 'fechamento',\n",
        "        'High': 'maximo',\n",
        "        'Low': 'minimo',\n",
        "        'Open': 'abertura',\n",
        "        'Volume': 'volume'\n",
        "    }\n",
        "\n",
        "    # Renomear as colunas\n",
        "    df.rename(columns=mapeamento_colunas, inplace=True)\n",
        "\n",
        "    # Converte e arredonda as colunas numéricas\n",
        "    for col in ['abertura', 'minimo', 'maximo', 'fechamento']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').round(2)\n",
        "\n",
        "    # Converte a coluna 'volume' para número inteiro\n",
        "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce', downcast='integer')\n",
        "\n",
        "    # Reorganiza as colunas na ordem desejada\n",
        "    df = df[['data', 'hora', 'abertura', 'minimo', 'maximo', 'fechamento', 'volume']]\n",
        "\n",
        "    # Verificar após reorganizar as colunas\n",
        "    print(\"\\nApós reorganizar as colunas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Verificar e remover duplicatas mantendo a primeira ocorrência\n",
        "    df = df.drop_duplicates(keep='first')\n",
        "\n",
        "    # Remover as linhas com 50% ou mais de valores nulos\n",
        "    df = df.dropna(thresh=df.shape[1] * 0.5)\n",
        "\n",
        "    # Verificar após remoção de duplicatas e nulos\n",
        "    print(\"\\nApós remover duplicatas e nulos:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que 'data' e 'hora' estejam no formato datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d')\n",
        "    df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S').dt.time\n",
        "\n",
        "    # Filtra apenas os dias úteis (segunda a sexta)\n",
        "    df = df[df['data'].dt.weekday < 5]\n",
        "\n",
        "    # Verificar após filtrar dias úteis\n",
        "    print(\"\\nApós filtrar apenas os dias úteis:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Filtra apenas horários entre 09:55 e 18:05\n",
        "    df = df[(df['hora'] >= pd.to_datetime('09:55:00').time()) &\n",
        "            (df['hora'] <= pd.to_datetime('18:05:00').time())]\n",
        "\n",
        "    # Verificar após filtrar o intervalo de horário\n",
        "    print(\"\\nApós filtrar o intervalo de horário (09:55-18:05):\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Caso o DataFrame fique vazio, informar o motivo\n",
        "    if df.empty:\n",
        "        print(\"O DataFrame ficou vazio após o filtro de horário. Verifique se os dados estão dentro do intervalo de 09:55-18:05.\")\n",
        "    else:\n",
        "        print(\"\\nLimpeza de dados concluída com sucesso.\")\n",
        "\n",
        "    # Ordenar os dados\n",
        "    df = df.sort_values([\"data\", \"hora\"], ascending=[False, True])\n",
        "    print(\"\\nDados limpos e ordenados:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Salva os dados limpos em CSV\n",
        "    df.to_csv(f\"/content/Piloto_Day_Trade/data/cleaned/dados_limpos.csv\", index=False)\n",
        "    print(f\"\\nOs dados foram limpos e salvos em csv.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ler os dados brutos\n",
        "    dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "    # Aplicar limpeza nos dados\n",
        "    df_limpo = limpeza_dados(dados_brutos)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHkNWR1-QS4",
        "outputId": "2644cc82-a2e1-4af6-a042-b0d681f6b8c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/limpeza_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Aplicando limpeza de dados\n",
        "from Piloto_Day_Trade.scripts.Pipeline.limpeza_dados import limpeza_dados\n",
        "\n",
        "dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/raw/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "df_limpo = limpeza_dados(dados_brutos)\n",
        "\n"
      ],
      "metadata": {
        "id": "97mwKCsf1V3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Transformação de dados\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/Pipeline/transformacao_dados.py\n",
        "\n",
        "\"\"\"\n",
        "Função de Transformação de Dados para Modelagem Preditiva\n",
        "Processa e transforma os dados para análise e previsão, gerando um conjunto\n",
        "de características para serem utilizadas no treinamento dos modelos.\n",
        "\n",
        "Objetivos:\n",
        "- Criar um dataset com variáveis relevantes para o modelo.\n",
        "- Incluir indicadores técnicos, estatísticas de volatilidade, médias móveis e outras features.\n",
        "- Permitir a experimentação com diferentes combinações de features.\n",
        "\n",
        "Estratégia:\n",
        "- Durante os testes de parametrização e treinamento, serão geradas diferentes versões do dataset,\n",
        "refinando a seleção de features a medida que geramos acurácia.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carregar variáveis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "def carregar_dados(arquivo):\n",
        "    \"\"\"Carrega um CSV e retorna um DataFrame, ou um DataFrame vazio se o arquivo não existir.\"\"\"\n",
        "    if isinstance(arquivo, pd.DataFrame):\n",
        "        return arquivo  # Se já for um DataFrame, retorna diretamente\n",
        "\n",
        "    if not os.path.exists(arquivo):\n",
        "        print(f\"⚠️ O arquivo {arquivo} não existe. Criando um novo DataFrame vazio.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(arquivo, parse_dates=[\"data\"])\n",
        "        print(f\"✅ Arquivo {arquivo} carregado com {len(df)} linhas.\")\n",
        "        return df if not df.empty else pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao carregar {arquivo}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def obter_ultima_data(df):\n",
        "    \"\"\"Retorna a última data disponível nos dados.\"\"\"\n",
        "    if \"data\" in df.columns and not df.empty:\n",
        "        ultima_data = df[\"data\"].max()\n",
        "        print(f\"📅 Última data encontrada nos dados: {ultima_data}\")\n",
        "        return ultima_data\n",
        "    return None\n",
        "\n",
        "def filtrar_novos_dados(df, ultima_data):\n",
        "    \"\"\"Filtra os dados para incluir apenas os novos registros.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"⚠️ Nenhum dado limpo disponível.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if ultima_data:\n",
        "        df_novo = df[df[\"data\"] > ultima_data]\n",
        "        print(f\"📊 Dados novos filtrados: {len(df_novo)} registros encontrados.\")\n",
        "        return df_novo\n",
        "    return df\n",
        "\n",
        "def calcular_indicadores(df):\n",
        "    \"\"\"Calcula indicadores técnicos e gera novas features para análise de dados financeiros.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"⚠️ Nenhum dado disponível para calcular indicadores.\")\n",
        "        return df\n",
        "\n",
        "    colunas_necessarias = [\"data\", \"hora\", \"abertura\", \"minimo\", \"maximo\", \"fechamento\", \"volume\"]\n",
        "\n",
        "    if not all(col in df.columns for col in colunas_necessarias):\n",
        "        print(\"❌ Dados insuficientes para cálculo de indicadores.\")\n",
        "        return df\n",
        "\n",
        "    # Ordenação correta dos dados\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[True, True])\n",
        "\n",
        "    # Cálculo do retorno percentual e volatilidade\n",
        "    df['retorno'] = df['fechamento'].pct_change()\n",
        "    df['volatilidade'] = df['retorno'].rolling(20).std()\n",
        "\n",
        "    # Médias móveis\n",
        "    df['SMA_10'] = df['fechamento'].rolling(10).mean()\n",
        "    df['EMA_10'] = df['fechamento'].ewm(span=10, adjust=False).mean()\n",
        "\n",
        "    # MACD e linha de sinal\n",
        "    df['MACD'] = df['fechamento'].ewm(span=12).mean() - df['fechamento'].ewm(span=26).mean()\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=9).mean()\n",
        "\n",
        "    # RSI (Índice de Força Relativa)\n",
        "    ganho = df['retorno'].clip(lower=0)\n",
        "    perda = -df['retorno'].clip(upper=0)\n",
        "    media_ganho = ganho.ewm(span=14).mean()\n",
        "    media_perda = perda.ewm(span=14).mean() + 1e-10\n",
        "    df['rsi'] = 100 - (100 / (1 + (media_ganho / media_perda)))\n",
        "\n",
        "    # OBV (On Balance Volume)\n",
        "    df['OBV'] = (df['volume'] * np.sign(df['fechamento'].diff())).fillna(0).cumsum()\n",
        "\n",
        "    # Criar lags para fechamento, retorno e volume\n",
        "    for lag in range(1, 4):\n",
        "        df[f'fechamento_lag{lag}'] = df['fechamento'].shift(lag)\n",
        "        df[f'retorno_lag{lag}'] = df['retorno'].shift(lag)\n",
        "        df[f'volume_lag{lag}'] = df['volume'].shift(lag)\n",
        "\n",
        "    # Substituir NaN por zero onde necessário\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Ordenação final\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[False, True])\n",
        "\n",
        "    print(f\"✅ Indicadores calculados. Tamanho final do DataFrame: {len(df)} linhas.\")\n",
        "    return df\n",
        "\n",
        "def adicionar_features_temporais(df):\n",
        "    \"\"\"Adiciona colunas temporais para análise de séries temporais.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"⚠️ Nenhum dado disponível para processamento.\")\n",
        "        return df\n",
        "\n",
        "    # Converter 'data' para datetime se necessário\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "\n",
        "    # Criar coluna do dia da semana para entrada e previsão\n",
        "    df['dia_da_semana_entrada'] = df['data'].dt.weekday  # 0 = Segunda, 6 = Domingo\n",
        "    df['data_previsao'] = df['data'] + pd.DateOffset(days=1)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Ajustar casos de sexta-feira para segunda-feira\n",
        "    df.loc[df['dia_da_semana_entrada'] == 4, 'data_previsao'] += pd.DateOffset(days=2)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Verificar se 'hora' está presente e converter corretamente\n",
        "    if 'hora' in df.columns:\n",
        "        df['hora'] = pd.to_datetime(df['hora'].astype(str), format='%H:%M:%S', errors='coerce').dt.time\n",
        "\n",
        "        # Criar colunas de hora e minuto\n",
        "        df['hora_num'] = df['hora'].apply(lambda x: x.hour if pd.notnull(x) else np.nan)\n",
        "        df['minuto'] = df['hora'].apply(lambda x: x.minute if pd.notnull(x) else np.nan)\n",
        "\n",
        "        # Criar coluna indicando se o mercado está aberto (entre 10h e 17h)\n",
        "        df['mercado_aberto'] = ((df['hora_num'] >= 10) & (df['hora_num'] <= 17)).astype(int)\n",
        "    else:\n",
        "        df['hora_num'] = np.nan\n",
        "        df['minuto'] = np.nan\n",
        "        df['mercado_aberto'] = 0\n",
        "\n",
        "    return df\n",
        "\n",
        "def transformar_dados(dados_limpos, dados_transformados):\n",
        "    \"\"\"Executa o processo de transformação dos dados.\"\"\"\n",
        "\n",
        "    df_transformado = carregar_dados(dados_transformados)\n",
        "    df_limpo = carregar_dados(dados_limpos)\n",
        "\n",
        "\n",
        "    if df_transformado.empty:\n",
        "        print(\"📂 Nenhum dado transformado encontrado. Criando novo DataFrame.\")\n",
        "\n",
        "    ultima_data = obter_ultima_data(df_transformado)\n",
        "    novos_dados = filtrar_novos_dados(df_limpo, ultima_data)\n",
        "\n",
        "    if not novos_dados.empty:\n",
        "        novos_dados = calcular_indicadores(novos_dados)\n",
        "        novos_dados = adicionar_features_temporais(novos_dados)\n",
        "        df_final = pd.concat([df_transformado, novos_dados], ignore_index=True) if not df_transformado.empty else novos_dados\n",
        "\n",
        "        pasta = os.path.dirname(dados_transformados)\n",
        "        if not os.path.exists(pasta):\n",
        "            os.makedirs(pasta)\n",
        "            print(f\"📂 Criando diretório: {pasta}\")\n",
        "\n",
        "        df_final.to_csv(dados_transformados, index=False)\n",
        "        print(f\"✅ Dados transformados salvos em {dados_transformados} ({len(df_final)} registros)\")\n",
        "        print(f\"📅 Última data disponível nos dados: {df_final['data'].max()}\")\n",
        "        print(f\"df_final: {df_final.head(5)}\")\n",
        "        return df_final\n",
        "    else:\n",
        "        print(\"⏭️ Nenhum novo dado para processar.\")\n",
        "        print(f\"📅 Última data disponível nos dados: {df_transformado['data'].max()}\")\n",
        "        print(f\"df_transformado: {df_transformado.head(5)}\")\n",
        "        return df_transformado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados_limpos = '/content/Piloto_Day_Trade/data/dados_limpos.csv'\n",
        "    path_dados_transformados = '/content/Piloto_Day_Trade/data/dados_transformados_3103.csv'\n",
        "    df_transformado =transformar_dados(path_dados_limpos, path_dados_transformados)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH35zARUD6jA",
        "outputId": "9ce3d8fc-d574-4782-852e-2c7fe234d923"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/transformacao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.transformacao_dados import transformar_dados\n",
        "\n",
        "#@title Aplicando transformação de dados\n",
        "path_dados_limpos = '/content/Piloto_Day_Trade/data/cleaned/dados_limpos.csv'\n",
        "path_dados_transformados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "df_transformado = transformar_dados(path_dados_limpos, path_dados_transformados)\n"
      ],
      "metadata": {
        "id": "5bG6Yqpyuawu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados\n",
        "df_transformado = pd.read_csv('/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv')\n"
      ],
      "metadata": {
        "id": "6Kd2TDjqmGVo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando os tipos de dados\n",
        "df_transformado.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4G3hB-sknn-j",
        "outputId": "2845fd79-ab19-4c24-f8c1-c119a9f285c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data                       object\n",
              "hora                       object\n",
              "abertura                  float64\n",
              "minimo                    float64\n",
              "maximo                    float64\n",
              "fechamento                float64\n",
              "volume                      int64\n",
              "retorno                   float64\n",
              "volatilidade              float64\n",
              "SMA_10                    float64\n",
              "EMA_10                    float64\n",
              "MACD                      float64\n",
              "Signal_Line               float64\n",
              "rsi                       float64\n",
              "OBV                       float64\n",
              "fechamento_lag1           float64\n",
              "retorno_lag1              float64\n",
              "volume_lag1               float64\n",
              "fechamento_lag2           float64\n",
              "retorno_lag2              float64\n",
              "volume_lag2               float64\n",
              "fechamento_lag3           float64\n",
              "retorno_lag3              float64\n",
              "volume_lag3               float64\n",
              "dia_da_semana_entrada       int64\n",
              "data_previsao              object\n",
              "dia_da_semana_previsao      int64\n",
              "hora_num                    int64\n",
              "minuto                      int64\n",
              "mercado_aberto              int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>data</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abertura</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minimo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maximo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volatilidade</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MACD</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Signal_Line</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rsi</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBV</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_entrada</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_previsao</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_previsao</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora_num</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minuto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mercado_aberto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Banco de dados"
      ],
      "metadata": {
        "id": "Ap-meZswIhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n",
        "\n",
        "#@title Definição do esquema - Modelo Estrela\n",
        "\n",
        "O modelo estrela foi escolhido por sua simplicidade e clareza na organização dos dados para análise. Ele é ideal para consultas rápidas e análise preditiva. No nosso projeto, temos um único fato (preços OHLC) e múltiplas variáveis explicativas que os influenciam.\n",
        "\n",
        "A estrutura facilita agregações temporais e análises do comportamento dos preços, sendo também eficiente para alimentar o pipeline de machine learning. Ao organizar as variáveis preditoras ao redor das medidas de preço, conseguimos isolar responsabilidades e tornar as análises mais precisas e escaláveis.\n",
        "\n",
        "## Tabela Fato: `fato_precos`\n",
        "| Coluna         | Tipo   | Descrição                                   |\n",
        "|----------------|--------|---------------------------------------------|\n",
        "| id_fato_precos | int    | PK, identificador único da linha            |\n",
        "| id_tempo       | int    | FK para a dimensão tempo                    |\n",
        "| abertura       | float  | Preço de abertura                           |\n",
        "| minimo         | float  | Preço mínimo                                |\n",
        "| maximo         | float  | Preço máximo                                |\n",
        "| fechamento     | float  | Preço de fechamento (variável alvo)         |\n",
        "\n",
        "## Dimensão: `dim_tempo`\n",
        "| Coluna                | Tipo   | Descrição                                 |\n",
        "|------------------------|--------|-------------------------------------------|\n",
        "| id_tempo              | int    | PK                                        |\n",
        "| data                  | object | Data da observação                        |\n",
        "| hora                  | object | Hora da observação                        |\n",
        "| dia_da_semana_entrada | int    | Dia da semana da entrada (0=Seg, 6=Dom)   |\n",
        "\n",
        "## Dimensão: `dim_indicadores`\n",
        "| Coluna       | Tipo   | Descrição                                       |\n",
        "|--------------|--------|--------------------------------------------------|\n",
        "| id_indicadores | int  | PK                                               |\n",
        "| id_tempo     | int    | FK para a dimensão tempo                        |\n",
        "| SMA_10       | float  | Média móvel simples de 10 períodos              |\n",
        "| EMA_10       | float  | Média móvel exponencial de 10 períodos          |\n",
        "| MACD         | float  | Moving Average Convergence Divergence           |\n",
        "| Signal_Line  | float  | Linha de sinal do MACD                          |\n",
        "| rsi          | float  | Índice de força relativa                        |\n",
        "| OBV          | float  | On-Balance Volume                               |\n",
        "| retorno      | float  | Retorno do período                              |\n",
        "| volatilidade | float  | Volatilidade do período                         |\n",
        "\n",
        "## Dimensão: `dim_lags`\n",
        "| Coluna          | Tipo   | Descrição                                       |\n",
        "|-----------------|--------|--------------------------------------------------|\n",
        "| id_lags         | int    | PK                                              |\n",
        "| id_tempo        | int    | FK para a dimensão tempo                        |\n",
        "| fechamento_lag1 | float  | Fechamento no candle anterior (1 lag)          |\n",
        "| retorno_lag1    | float  | Retorno do candle anterior (1 lag)             |\n",
        "| volume_lag1     | float  | Volume do candle anterior (1 lag)              |\n",
        "| fechamento_lag2 | float  | Fechamento dois candles atrás (2 lags)         |\n",
        "| retorno_lag2    | float  | Retorno dois candles atrás (2 lags)            |\n",
        "| volume_lag2     | float  | Volume dois candles atrás (2 lags)             |\n",
        "| fechamento_lag3 | float  | Fechamento três candles atrás (3 lags)         |\n",
        "| retorno_lag3    | float  | Retorno três candles atrás (3 lags)            |\n",
        "| volume_lag3     | float  | Volume três candles atrás (3 lags)             |\n",
        "\n",
        "## Dimensão: `dim_operacional`\n",
        "| Coluna                 | Tipo   | Descrição                                      |\n",
        "|------------------------|--------|------------------------------------------------|\n",
        "| id_operacional         | int    | PK                                             |\n",
        "| id_tempo               | int    | FK para a dimensão tempo                       |\n",
        "| data_previsao          | object | Data prevista para o modelo                    |\n",
        "| dia_da_semana_previsao | int    | Dia da semana da previsão                      |\n",
        "| hora_num               | int    | Hora como número inteiro                       |\n",
        "| minuto                 | int    | Minuto da observação                           |\n",
        "| mercado_aberto         | int    | Indicador binário (1=aberto, 0=fechado)        |\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "kuxIPKOgzMvy",
        "outputId": "edb8b7a4-cc95-4076-8961-4bd709ee8ece"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n",
        "\n",
        "#@title Script para gerar o catálogo de dados\n",
        "\"\"\"\n",
        "Catálogo de Dados contendo minimamente uma descrição detalhada dos dados e seus domínios,\n",
        "contendo valores mínimos e máximos esperados para dados numéricos, e possíveis categorias para dados categóricos.\n",
        "\n",
        "Este modelo deve também descrever a linhagem dos dados, de onde os mesmos foram baixados\n",
        "e qual técnica foi utilizada para compor o conjunto de dados, caso haja.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Define colunas de cada tabela com tipos\n",
        "tabelas = {\n",
        "    \"fato_precos\": {\n",
        "        \"id_fato_precos\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"abertura\": \"float\",\n",
        "        \"minimo\": \"float\",\n",
        "        \"maximo\": \"float\",\n",
        "        \"fechamento\": \"float\"\n",
        "    },\n",
        "    \"dim_tempo\": {\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data\": \"object\",\n",
        "        \"hora\": \"object\",\n",
        "        \"dia_da_semana_entrada\": \"int\"\n",
        "    },\n",
        "    \"dim_indicadores\": {\n",
        "        \"id_indicadores\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"SMA_10\": \"float\",\n",
        "        \"EMA_10\": \"float\",\n",
        "        \"MACD\": \"float\",\n",
        "        \"Signal_Line\": \"float\",\n",
        "        \"rsi\": \"float\",\n",
        "        \"OBV\": \"float\",\n",
        "        \"retorno\": \"float\",\n",
        "        \"volatilidade\": \"float\"\n",
        "    },\n",
        "    \"dim_lags\": {\n",
        "        \"id_lags\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"fechamento_lag1\": \"float\",\n",
        "        \"retorno_lag1\": \"float\",\n",
        "        \"volume_lag1\": \"float\",\n",
        "        \"fechamento_lag2\": \"float\",\n",
        "        \"retorno_lag2\": \"float\",\n",
        "        \"volume_lag2\": \"float\",\n",
        "        \"fechamento_lag3\": \"float\",\n",
        "        \"retorno_lag3\": \"float\",\n",
        "        \"volume_lag3\": \"float\"\n",
        "    },\n",
        "    \"dim_operacional\": {\n",
        "        \"id_operacional\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data_previsao\": \"object\",\n",
        "        \"dia_da_semana_previsao\": \"int\",\n",
        "        \"hora_num\": \"int\",\n",
        "        \"minuto\": \"int\",\n",
        "        \"mercado_aberto\": \"int\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def dominio(col, tipo):\n",
        "    if tipo in [\"float\", \"int\"]:\n",
        "        if \"retorno\" in col:\n",
        "            return \"-0.05 a 0.05 (retorno percentual por intervalo de 5 min)\"\n",
        "        elif \"volatilidade\" in col:\n",
        "            return \"0 a 0.1 (desvio padrão do retorno por janela de tempo)\"\n",
        "        elif \"abertura\" in col or \"fechamento\" in col or \"minimo\" in col or \"maximo\" in col:\n",
        "            return \"10.0 a 50.0 (valores típicos para BBDC4)\"\n",
        "        elif \"MACD\" in col or \"Signal\" in col:\n",
        "            return \"-5 a 5\"\n",
        "        elif \"rsi\" in col:\n",
        "            return \"0 a 100\"\n",
        "        elif \"OBV\" in col:\n",
        "            return \"valor acumulativo, depende do ativo\"\n",
        "        elif \"volume\" in col:\n",
        "            return \"0 a 1.000.000 (valores inteiros positivos)\"\n",
        "        elif \"dia_da_semana\" in col:\n",
        "            return \"0=Segunda, ..., 6=Domingo\"\n",
        "        elif \"mercado_aberto\" in col:\n",
        "            return \"0=Fechado, 1=Aberto\"\n",
        "        else:\n",
        "            return \"valores numéricos contínuos\"\n",
        "    elif tipo == \"object\":\n",
        "        if \"data\" in col:\n",
        "            return \"formato YYYY-MM-DD\"\n",
        "        elif \"hora\" in col:\n",
        "            return \"formato HH:MM:SS\"\n",
        "        else:\n",
        "            return \"texto livre\"\n",
        "    return \"não especificado\"\n",
        "\n",
        "def descricao(col):\n",
        "    descricoes = {\n",
        "        \"abertura\": \"Preço de abertura do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"minimo\": \"Menor preço do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"maximo\": \"Maior preço do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"fechamento\": \"Preço de fechamento do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"retorno\": \"Retorno percentual do ativo no intervalo de 5 minutos\",\n",
        "        \"volatilidade\": \"Volatilidade dos retornos do ativo em janela deslizante\",\n",
        "        \"SMA_10\": \"Média móvel simples de 10 períodos calculada sobre os preços\",\n",
        "        \"EMA_10\": \"Média móvel exponencial de 10 períodos\",\n",
        "        \"MACD\": \"Moving Average Convergence Divergence, indicador técnico\",\n",
        "        \"Signal_Line\": \"Linha de sinal do MACD\",\n",
        "        \"rsi\": \"Índice de força relativa (RSI), oscilador técnico\",\n",
        "        \"OBV\": \"On Balance Volume, indicador técnico baseado em volume\",\n",
        "        \"hora_num\": \"Hora expressa como número inteiro\",\n",
        "        \"minuto\": \"Minuto do intervalo de tempo\",\n",
        "        \"mercado_aberto\": \"Indica se o mercado está aberto no horário (1) ou não (0)\"\n",
        "    }\n",
        "    for key in descricoes:\n",
        "        if key in col:\n",
        "            return descricoes[key]\n",
        "    if \"lag\" in col:\n",
        "        return f\"Valor defasado de {col.replace('_lag', '')}\"\n",
        "    if \"dia_da_semana\" in col:\n",
        "        return \"Dia da semana correspondente à data\"\n",
        "    if \"id_\" in col:\n",
        "        return \"Identificador único para relacionar com outras tabelas\"\n",
        "    return \"\"\n",
        "\n",
        "def tecnica(col):\n",
        "    if any(ind in col for ind in [\"SMA\", \"EMA\", \"MACD\", \"Signal\", \"rsi\", \"OBV\"]):\n",
        "        return \"calculado internamente via engenharia de features técnicas\"\n",
        "    if \"lag\" in col:\n",
        "        return \"calculado como valor defasado (lag)\"\n",
        "    if col in [\"data\", \"hora\", \"hora_num\", \"minuto\", \"dia_da_semana_entrada\", \"dia_da_semana_previsao\"]:\n",
        "        return \"extraído de data/hora original\"\n",
        "    if col == \"mercado_aberto\":\n",
        "        return \"derivado da data/hora com base em calendário de mercado\"\n",
        "    return \"cópia ou identificador\"\n",
        "\n",
        "linhagem = \"Fonte: Yahoo Finance via yfinance\"\n",
        "\n",
        "linhas = []\n",
        "for tabela, colunas in tabelas.items():\n",
        "    for col, tipo in colunas.items():\n",
        "        linhas.append({\n",
        "            \"tabela\": tabela,\n",
        "            \"coluna\": col,\n",
        "            \"tipo\": tipo,\n",
        "            \"descricao\": descricao(col),\n",
        "            \"dominio\": dominio(col, tipo),\n",
        "            \"tecnica\": tecnica(col),\n",
        "            \"linhagem\": linhagem\n",
        "        })\n",
        "\n",
        "catalogo_df = pd.DataFrame(linhas)\n",
        "catalogo_df.to_csv(\"/content/Piloto_Day_Trade/modelagem/catalogo_dados.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "_Gn9fb5M4S1f",
        "outputId": "043bbdb6-f76c-47fb-accb-1f6677660cca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar a geração do Catalogo de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "o6QQCeAF1qvO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Gerando catálogo de dados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC29xOqV95Z_",
        "outputId": "f59b30e7-e64a-4050-a8fc-35530eec0c5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Atualização do repositório concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n",
        "\n",
        "# @title Script para criar banco de dados e tabelas\n",
        "\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
        "\n",
        "# Conecta ao banco (cria se não existir)\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Comandos SQL para criar as tabelas\n",
        "sql_script = \"\"\"\n",
        "-- Criação da Tabela Fato\n",
        "CREATE TABLE IF NOT EXISTS fato_precos (\n",
        "    id_fato_precos INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    abertura REAL,\n",
        "    minimo REAL,\n",
        "    maximo REAL,\n",
        "    fechamento REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Criação da Dimensão Tempo\n",
        "CREATE TABLE IF NOT EXISTS dim_tempo (\n",
        "    id_tempo INTEGER PRIMARY KEY,\n",
        "    data TEXT,\n",
        "    hora TEXT,\n",
        "    dia_da_semana_entrada INTEGER\n",
        ");\n",
        "\n",
        "-- Criação da Dimensão Indicadores Técnicos\n",
        "CREATE TABLE IF NOT EXISTS dim_indicadores (\n",
        "    id_indicadores INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    SMA_10 REAL,\n",
        "    EMA_10 REAL,\n",
        "    MACD REAL,\n",
        "    Signal_Line REAL,\n",
        "    rsi REAL,\n",
        "    OBV REAL,\n",
        "    retorno REAL,\n",
        "    volatilidade REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Criação da Dimensão Lags\n",
        "CREATE TABLE IF NOT EXISTS dim_lags (\n",
        "    id_lags INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    fechamento_lag1 REAL,\n",
        "    retorno_lag1 REAL,\n",
        "    volume_lag1 REAL,\n",
        "    fechamento_lag2 REAL,\n",
        "    retorno_lag2 REAL,\n",
        "    volume_lag2 REAL,\n",
        "    fechamento_lag3 REAL,\n",
        "    retorno_lag3 REAL,\n",
        "    volume_lag3 REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Criação da Dimensão Operacional\n",
        "CREATE TABLE IF NOT EXISTS dim_operacional (\n",
        "    id_operacional INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    data_previsao TEXT,\n",
        "    dia_da_semana_previsao INTEGER,\n",
        "    hora_num INTEGER,\n",
        "    minuto INTEGER,\n",
        "    mercado_aberto INTEGER,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Executa o script SQL\n",
        "cursor.executescript(sql_script)\n",
        "\n",
        "# Confirma e fecha\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"✅ Banco e tabelas criados com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-OxeXvgYa_jC",
        "outputId": "2b9f1193-11a2-4be9-df79-733345229f2c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Excecutar criar banco e tabelas\n",
        "!python /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "NGaGzrS1AQcj",
        "outputId": "9a76aa09-9c81-4c3f-b8d0-f6a635484d16"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Banco e tabelas criados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar criação do banco\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsDCNhgeA2WU",
        "outputId": "67c3ced0-b34c-4c96-f7fa-a6d630429946"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fato_precos',), ('dim_tempo',), ('dim_indicadores',), ('dim_lags',), ('dim_operacional',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar colunas\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"PRAGMA table_info(dim_tempo);\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM7plBnSFNHp",
        "outputId": "f9fa0f48-89d7-41ae-abe1-3803038bad9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'id_tempo', 'INTEGER', 0, None, 1), (1, 'data', 'TEXT', 0, None, 0), (2, 'hora', 'TEXT', 0, None, 0), (3, 'dia_da_semana_entrada', 'INTEGER', 0, None, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Definindo script de carga de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/carga_dados.py\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Caminho para o banco de dados\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "assert os.path.exists(db_path), f\"Banco de dados não encontrado em {db_path}\"\n",
        "# Leitura dos dados a serem carregados\n",
        "df = pd.read_csv(\"/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv\")\n",
        "\n",
        "# Função para carregar dados\n",
        "def carregar_dados(df: pd.DataFrame):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        id_tempo = idx + 1\n",
        "\n",
        "        # 1. Inserir na dim_tempo\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_tempo (id_tempo, data, hora, dia_da_semana_entrada)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, row['data'], row['hora'], row['dia_da_semana_entrada']))\n",
        "\n",
        "        # 2. Inserir na dim_indicadores\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_indicadores (id_indicadores, id_tempo, SMA_10, EMA_10, MACD, Signal_Line, rsi, OBV, retorno, volatilidade)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['SMA_10'], row['EMA_10'], row['MACD'], row['Signal_Line'], row['rsi'],\n",
        "              row['OBV'], row['retorno'], row['volatilidade']))\n",
        "\n",
        "        # 3. Inserir na dim_lags\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_lags (id_lags, id_tempo, fechamento_lag1, retorno_lag1, volume_lag1,\n",
        "                                  fechamento_lag2, retorno_lag2, volume_lag2,\n",
        "                                  fechamento_lag3, retorno_lag3, volume_lag3)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo,\n",
        "              row['fechamento_lag1'], row['retorno_lag1'], row['volume_lag1'],\n",
        "              row['fechamento_lag2'], row['retorno_lag2'], row['volume_lag2'],\n",
        "              row['fechamento_lag3'], row['retorno_lag3'], row['volume_lag3']))\n",
        "\n",
        "        # 4. Inserir na dim_operacional\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_operacional (id_operacional, id_tempo, data_previsao, dia_da_semana_previsao, hora_num, minuto, mercado_aberto)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['data_previsao'], row['dia_da_semana_previsao'],\n",
        "              row['hora_num'], row['minuto'], row['mercado_aberto']))\n",
        "\n",
        "        # 5. Inserir na fato_precos\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO fato_precos (id_fato_precos, id_tempo, abertura, minimo, maximo, fechamento)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['abertura'], row['minimo'], row['maximo'], row['fechamento']))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(f\"✅ Carga concluída com {len(df)} registros.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    carregar_dados(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "injpAahyCCxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3e4e977b-8177-442d-9307-3c47dcbf47e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar realizar a carga de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zidwW0A7DfMa",
        "outputId": "cac96221-5118-47d1-9e79-11b79644c6e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Carga concluída com 2462 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a carga de dados\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "\n",
        "# Conexão e cursor\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Consulta nas tabelas principais\n",
        "tabelas = ['dim_tempo', 'dim_indicadores', 'dim_lags', 'dim_operacional', 'fato_precos']\n",
        "for tabela in tabelas:\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {tabela}\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"{tabela}: {count} registros\")\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksO0iYGrEEXF",
        "outputId": "844e25bd-e40f-4ff8-9514-7f1b5985b6cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim_tempo: 2462 registros\n",
            "dim_indicadores: 2462 registros\n",
            "dim_lags: 2462 registros\n",
            "dim_operacional: 2462 registros\n",
            "fato_precos: 2462 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os primeiros 5 registros da fato_precos\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_check = pd.read_sql_query(\"SELECT * FROM fato_precos LIMIT 5\", conn)\n",
        "print(df_check)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0OFgWADGalR",
        "outputId": "e243258d-2c88-4410-d40c-fb5565d96723"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos  id_tempo  abertura  minimo  maximo  fechamento\n",
            "0               1         1     12.47   12.40   12.47       12.41\n",
            "1               2         2     12.41   12.37   12.45       12.41\n",
            "2               3         3     12.41   12.41   12.46       12.44\n",
            "3               4         4     12.44   12.38   12.45       12.39\n",
            "4               5         5     12.40   12.39   12.45       12.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta com JOIN para verificar o relacionamento entre as tabelas\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    ft.id_fato_precos,\n",
        "    dt.data,\n",
        "    dt.hora,\n",
        "    ft.abertura,\n",
        "    ft.fechamento,\n",
        "    di.SMA_10,\n",
        "    dl.fechamento_lag1,\n",
        "    do.data_previsao,\n",
        "    do.mercado_aberto\n",
        "FROM fato_precos ft\n",
        "JOIN dim_tempo dt ON ft.id_tempo = dt.id_tempo\n",
        "JOIN dim_indicadores di ON ft.id_tempo = di.id_tempo\n",
        "JOIN dim_lags dl ON ft.id_tempo = dl.id_tempo\n",
        "JOIN dim_operacional do ON ft.id_tempo = do.id_tempo\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "# Executando e exibindo\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_verificacao = pd.read_sql_query(query, conn)\n",
        "print(df_verificacao)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrqdeR8Gq1p",
        "outputId": "d1615268-e9fe-4496-904a-54dc0b16b88f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos        data      hora  abertura  fechamento  SMA_10  \\\n",
            "0               1  2025-04-08  10:00:00     12.47       12.41  12.379   \n",
            "1               2  2025-04-08  10:05:00     12.41       12.41  12.384   \n",
            "2               3  2025-04-08  10:10:00     12.41       12.44  12.389   \n",
            "3               4  2025-04-08  10:15:00     12.44       12.39  12.390   \n",
            "4               5  2025-04-08  10:20:00     12.40       12.43  12.397   \n",
            "\n",
            "   fechamento_lag1 data_previsao  mercado_aberto  \n",
            "0            12.40    2025-04-09               1  \n",
            "1            12.41    2025-04-09               1  \n",
            "2            12.41    2025-04-09               1  \n",
            "3            12.44    2025-04-09               1  \n",
            "4            12.39    2025-04-09               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escrevendo o Readme do projeto\n",
        "%%writefile /content/Piloto_Day_Trade/README.md\n",
        "\n",
        "# Objetivo do Projeto\n",
        "\n",
        "## 1. Propósito do MVP\n",
        "\n",
        "Este projeto tem como objetivo principal a criação de um pipeline para extração, transformação, carga, análise e previsão da movimentação intradiária dos preços de um ativo financeiro em intervalos de 5 minutos. O modelo preditivo central será baseado em redes neurais recorrentes (LSTM), mas outras abordagens serão exploradas. O MVP visa garantir previsões para embasar decisões estratégicas de day trade.\n",
        "\n",
        "## 2. Problema a Ser Resolvido\n",
        "\n",
        "A alta volatilidade dos mercados financeiros exige ferramentas robustas para antecipação de movimentos de preço. A dificuldade está em capturar padrões de curto prazo e projetá-los com precisão. Traders e investidores necessitam de um modelo que consiga interpretar os padrões históricos e transformá-los em previsões úteis.\n",
        "\n",
        "## 3. Pipeline do Projeto\n",
        "\n",
        "O pipeline está estruturado em sete etapas principais:\n",
        "\n",
        "### 3.1. Extração e armazenamento dos dados brutos\n",
        "- Coleta de dados históricos do ativo BBDC4 em intervalos de 5 minutos, via API do Yahoo Finance (yfinance).\n",
        "- Armazenamento dos dados no GitHub sincronizado com Google Colab, com backup em nuvem.\n",
        "- Salvo como `dados_brutos.csv`\n",
        "\n",
        "### 3.2. Limpeza e organização dos dados\n",
        "- Padronização dos tipos de dados\n",
        "- Padronização dos nomes de colunas\n",
        "- Remoção de valores nulos ou duplicados\n",
        "- Remoção de colunas desnecessárias\n",
        "- Ordenação cronológica\n",
        "- Salvo como `dados_limpos.csv`\n",
        "\n",
        "### 3.3. Transformação de dados e engenharia de features\n",
        "- Cálculo de indicadores técnicos (SMA, EMA, MACD, RSI, OBV)\n",
        "- Cálculo de retornos e variância (volatilidade)\n",
        "- Criação de variáveis de lag de preço, volume e retorno\n",
        "- Adição de variáveis temporais (hora, dia da semana, mercado aberto)\n",
        "- Salvo como `dados_transformados.csv`\n",
        "\n",
        "### 3.4. Modelagem e estruturação do banco dimensional\n",
        "- **Fato**: `fato_precos` com preços e chave para `dim_tempo`\n",
        "- **Dimensões**:\n",
        "  - `dim_tempo`: data, hora, dia da semana\n",
        "  - `dim_indicadores`: indicadores técnicos\n",
        "  - `dim_lags`: lags de preço, volume, retorno\n",
        "  - `dim_operacional`: hora, minuto, data da previsão, mercado aberto\n",
        "- Banco gerado em SQLite via script automatizado (`banco_dimensional.db`)\n",
        "\n",
        "### 3.5. Carga (ETL)\n",
        "- **Extração:** via API (automatizada)\n",
        "- **Limpeza:** padronização, remoção de nulos/duplicatas\n",
        "- **Transformação:** features técnicas e derivadas\n",
        "- **Carga:** população das tabelas do banco dimensional\n",
        "- ETL organizado em scripts Python e automatizado\n",
        "\n",
        "### 3.6. Treinamento e ajuste do modelo preditivo\n",
        "- **Preparação dos dados**:\n",
        "  - Padronização com StandardScaler para retornos e indicadores\n",
        "  - Normalização com MinMaxScaler para preços e volumes\n",
        "  - Separar features (X) e targets (y)\n",
        "  - Divisão treino/teste com base em dias útis\n",
        "- **Modelo base:** LSTM com duas camadas ocultas, camada densa e MSE como perda\n",
        "- **Avaliação:** Métricas de MSE, R², comparação com targets reais\n",
        "\n",
        "### 3.7. Análise dos resultados\n",
        "- Comparativo entre preços previstos vs. reais\n",
        "- Validação das previsões para abertura, máxima, mínima e fechamento\n",
        "- Importância das variáveis\n",
        "- Interpretação dos erros e possíveis melhorias\n",
        "\n",
        "## 4. Perguntas a Serem Respondidas\n",
        "- É possível prever com precisão a movimentação intradiária a cada 5 minutos?\n",
        "- Os dados do dia anterior são suficientes para prever o comportamento do dia seguinte?\n",
        "- O modelo LSTM é eficaz para padrões de curtíssimo prazo?\n",
        "- É viável derivar os targets globais do dia a partir das previsões intradiárias?\n",
        "- Quais indicadores mais contribuem para a previsão?\n",
        "- Como lidar corretamente com fins de semana e feriados?\n",
        "- A padronização/normalização das variáveis afeta o desempenho?\n",
        "\n",
        "## 5. Critérios de Sucesso\n",
        "- Pipeline funcional de extração → transformação → carga → previsão\n",
        "- Modelo com bom desempenho em MSE e R²\n",
        "- Targets globais coerentes com valores reais\n",
        "- Correta gestão de datas (incluindo segundas-feiras)\n",
        "- Previsões utilizáveis para tomada de decisão\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "SCo7OFDwSG35",
        "outputId": "1abecda6-cef8-4b37-8ab8-08ecdc6257b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Escrevendo Licença do projeto\n",
        "%%writefile /content/Piloto_Day_Trade/LICENSE\n",
        "\n",
        "Copyright (c) 2025 Carolina Brescowitt\n",
        "\n",
        "Todos os direitos reservados.\n",
        "\n",
        "Este software é fornecido gratuitamente apenas para uso **pessoal, acadêmico e de pesquisa**.\n",
        "\n",
        "O uso comercial deste software é estritamente proibido sem uma **licença comercial paga**, a ser negociada com o autor.\n",
        "\n",
        "Empresas, startups, desenvolvedores ou qualquer entidade que deseje utilizar este código em produtos, serviços ou plataformas comerciais devem entrar em contato com o autor para **negociar os termos de licenciamento** (incluindo percentual, royalties ou valores fixos).\n",
        "\n",
        "É proibida a redistribuição ou sublicenciamento sem autorização por escrito.\n",
        "\n",
        "Para mais informações, entre em contato: carolbrescowitt@yahoo.com.br\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guTRpOgpsxDC",
        "outputId": "e3236b30-1401-4e22-96b1-d57c5ba4ebec"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/Piloto_Day_Trade/LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem de dados"
      ],
      "metadata": {
        "id": "ai-nFsCPCE4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Preparação de dados para LSTM\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/modelagem_machine_learning/preparar_dados_modelagem_LSTM.py\n",
        "\n",
        "\"\"\"\n",
        "Função que prepara os dados transformados para modelagem com LSTM:\n",
        "- Aplica normalização e padronização\n",
        "- Cria sequências de entrada e saída\n",
        "- Divide em treino e teste\n",
        "- Salva o scaler de preço para uso posterior nas previsões\n",
        "\n",
        "Retorna:\n",
        "    X_treino, X_teste, y_treino, y_teste: arrays prontos para modelagem LSTM\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "def preparar_dados_lstm(\n",
        "    path_dados,       # Caminho do CSV com os dados\n",
        "    tam_seq=32,       # Tamanho da sequência para entrada na LSTM\n",
        "    tx_treino=0.8     # Proporção dos dados para treino\n",
        "):\n",
        "    # Caminho do scaler\n",
        "    caminho_scaler_preco = '/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'\n",
        "\n",
        "    # Criar diretório do scaler se não existir\n",
        "    os.makedirs(os.path.dirname(caminho_scaler_preco), exist_ok=True)\n",
        "\n",
        "    # Carregar dados transformados\n",
        "    df = pd.read_csv(path_dados)\n",
        "\n",
        "    # Garantir colunas de data como datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "    df['data_previsao'] = pd.to_datetime(df['data_previsao'], errors='coerce')\n",
        "\n",
        "    # Definir colunas de preço\n",
        "    preco_cols = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Garantir que não há valores ausentes nos preços\n",
        "    df = df.dropna(subset=preco_cols)\n",
        "\n",
        "    # Salvar scaler de preço com base nos valores reais (antes da normalização)\n",
        "    scaler_preco = MinMaxScaler()\n",
        "    scaler_preco.fit(df[preco_cols])\n",
        "    joblib.dump(scaler_preco, caminho_scaler_preco)\n",
        "\n",
        "    print(\"Scaler de preço salvo com sucesso.\")\n",
        "\n",
        "    # Definir colunas para padronização e normalização\n",
        "    padronizar_cols = ['retorno', 'volatilidade', 'MACD', 'Signal_Line', 'rsi']\n",
        "    normalizar_cols = ['abertura', 'minimo', 'maximo', 'fechamento', 'volume', 'SMA_10', 'EMA_10', 'OBV',\n",
        "                       'fechamento_lag1', 'retorno_lag1', 'volume_lag1',\n",
        "                       'fechamento_lag2', 'retorno_lag2', 'volume_lag2',\n",
        "                       'fechamento_lag3', 'retorno_lag3', 'volume_lag3']\n",
        "\n",
        "    # Inicializar scalers\n",
        "    scaler_standard = StandardScaler()\n",
        "    scaler_minmax = MinMaxScaler()\n",
        "\n",
        "    # Aplicar transformações\n",
        "    df[padronizar_cols] = scaler_standard.fit_transform(df[padronizar_cols])\n",
        "    df[normalizar_cols] = scaler_minmax.fit_transform(df[normalizar_cols])\n",
        "\n",
        "    # Converter colunas categóricas para int\n",
        "    categorias = ['dia_da_semana_entrada', 'dia_da_semana_previsao', 'hora_num', 'minuto', 'mercado_aberto']\n",
        "    df[categorias] = df[categorias].astype(int)\n",
        "\n",
        "    # Manter apenas colunas numéricas\n",
        "    df = df.select_dtypes(include=['number'])\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Salvar versao dados preparados\n",
        "    caminho_csv_preparado = '/content/Piloto_Day_Trade/data/transformed/dados_preparados_para_modelagem.csv'\n",
        "    df.to_csv(caminho_csv_preparado, index=False)\n",
        "    print(f\"✅ Dados preparados salvos em: {caminho_csv_preparado}\")\n",
        "\n",
        "\n",
        "    # Função para criar sequências\n",
        "    def criar_sequencias(dados, tam_seq):\n",
        "        entradas, saidas = [], []\n",
        "        for i in range(len(dados) - tam_seq - 1):\n",
        "            entradas.append(dados.iloc[i:i+tam_seq].values)\n",
        "            saidas.append(dados.iloc[i+1:i+1+tam_seq][['abertura', 'maximo', 'minimo', 'fechamento']].values)\n",
        "        return np.array(entradas), np.array(saidas)\n",
        "\n",
        "    # Gerar X e y\n",
        "    X, y = criar_sequencias(df, tam_seq)\n",
        "\n",
        "    # Dividir entre treino e teste\n",
        "    tamanho_treino = int(tx_treino * len(X))\n",
        "    X_treino, X_teste = X[:tamanho_treino], X[tamanho_treino:]\n",
        "    y_treino, y_teste = y[:tamanho_treino], y[tamanho_treino:]\n",
        "\n",
        "    return X_treino, X_teste, y_treino, y_teste\n",
        "\n",
        "\n",
        "# Execução direta\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTR1S1f9y-f",
        "outputId": "bd6b0c80-c2b5-457e-b99f-d26e499f9b4a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/preparar_dados_modelagem_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "\n",
        "path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "    path_dados=path_dados,\n",
        "    tam_seq=96,\n",
        "    tx_treino=0.8\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9h6GHiRyiRI",
        "outputId": "da87ebf3-7c58-4d4f-f4c7-49826ca79de8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de preço salvo com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criar e treinar o modelo LSTM (Movimentação Intradiária)\n",
        "# %%writefile /content/Piloto_Day_Trade/scripts/modelo_LSTM_v1.py\n",
        "\n",
        "# Tentativa inicial - Modelo base LSTM para previsão intradiária de preços\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# 🔧 Construção do modelo\n",
        "LSTM_model = Sequential([\n",
        "\n",
        "    # Camada LSTM 1:\n",
        "    # - 100 unidades (aumentado para maior capacidade de captura de padrões temporais)\n",
        "    # - return_sequences=True para passar a sequência completa para a próxima camada\n",
        "    # - input_shape: (32, número de features) - sequência de 32 timesteps com n features\n",
        "    LSTM(100, return_sequences=True, input_shape=(X_treino.shape[1], X_treino.shape[2])),\n",
        "\n",
        "    # Dropout leve para reduzir overfitting sem perder muito sinal\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada LSTM 2:\n",
        "    # - Outra LSTM com 100 unidades\n",
        "    # - Também retorna sequência, pois a saída é uma sequência (32 timestamps com 4 preços)\n",
        "    LSTM(100, return_sequences=True),\n",
        "\n",
        "    # Outro Dropout leve\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada densa intermediária:\n",
        "    # - 64 neurônios com ativação ReLU\n",
        "    # - Introduz não-linearidade e ajuda a refinar a saída da LSTM antes da previsão final\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    # Camada de saída:\n",
        "    # - 4 unidades: prevendo abertura, máxima, mínima e fechamento por timestamp\n",
        "    # - Sem ativação, saída contínua (valores de preços normalizados)\n",
        "    Dense(4)\n",
        "])\n",
        "\n",
        "# 🧠 Compilação do modelo\n",
        "# - Otimizador Adam, bom para problemas não estacionários como séries temporais\n",
        "# - Função de perda MSE (erro quadrático médio), apropriado para regressão\n",
        "LSTM_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 🚂 Treinamento do modelo\n",
        "# - 20 épocas: número inicial para observar o desempenho\n",
        "# - batch_size=16: menor para atualizar pesos com frequência e lidar com variação dos dados\n",
        "historico = LSTM_model.fit(\n",
        "    X_treino, y_treino,\n",
        "    validation_data=(X_teste, y_teste),\n",
        "    epochs=20,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6lFmK-FMncY",
        "outputId": "140ed98d-f6ff-4f70-a3b2-1c3d6b255084"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 122ms/step - loss: 0.0654 - val_loss: 0.0076\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0059 - val_loss: 0.0049\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0023 - val_loss: 0.0040\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 0.0015 - val_loss: 0.0026\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 127ms/step - loss: 0.0013 - val_loss: 0.0021\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 115ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 0.0010 - val_loss: 0.0022\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - loss: 9.3821e-04 - val_loss: 0.0024\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 8.7632e-04 - val_loss: 0.0018\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 116ms/step - loss: 8.1019e-04 - val_loss: 0.0019\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 7.5255e-04 - val_loss: 0.0015\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 114ms/step - loss: 8.4505e-04 - val_loss: 0.0021\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 114ms/step - loss: 7.6089e-04 - val_loss: 0.0016\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - loss: 6.6421e-04 - val_loss: 0.0020\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 114ms/step - loss: 6.3165e-04 - val_loss: 0.0018\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 118ms/step - loss: 6.2296e-04 - val_loss: 0.0017\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 5.9292e-04 - val_loss: 0.0020\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - loss: 6.8025e-04 - val_loss: 0.0015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Incluindo Modelo LSTM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiGwgsI6p9IC",
        "outputId": "d8d09ca7-1920-49f9-e63a-9307fb770ae6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Nenhuma alteração para comitar.\n",
            "✅ Repositório atualizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Salvar LSTM versao 1\n",
        "# Criar diretório para modelos, se não existir\n",
        "import os\n",
        "path_modelo = '/content/Piloto_Day_Trade/models/LSTM_v1'\n",
        "os.makedirs(path_modelo, exist_ok=True)\n",
        "\n",
        "# Salvar o modelo completo (estrutura + pesos + otimizador)\n",
        "LSTM_model.save(f'{path_modelo}/modelo_completo.keras')\n",
        "\n",
        "print(\"✅ Modelo LSTM_v1 salvo com sucesso!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSGaNfmtKwU6",
        "outputId": "8cf550f2-653b-4212-f5bf-b726a277ebe0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modelo LSTM_v1 salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n",
        "\n",
        "#@title Calcular métricas e avaliar modelo LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def avaliar_modelo_lstm(modelo, X_teste, y_teste, caminho_scaler='/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'):\n",
        "    \"\"\"\n",
        "    Avalia um modelo LSTM fornecido, imprimindo as principais métricas e comparação entre previsões e valores reais.\n",
        "\n",
        "    Parâmetros:\n",
        "        modelo: modelo LSTM treinado\n",
        "        X_teste: dados de entrada de teste\n",
        "        y_teste: dados reais (targets) correspondentes ao teste\n",
        "        caminho_scaler: caminho do scaler salvo para inversão da normalização\n",
        "    \"\"\"\n",
        "\n",
        "    # Fazer previsões\n",
        "    y_previsto = modelo.predict(X_teste)\n",
        "\n",
        "    # Carregar o scaler de preços\n",
        "    scaler_precos = joblib.load(caminho_scaler)\n",
        "\n",
        "    # Colunas de preço\n",
        "    colunas_precos = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Redimensionar para (amostras, 4)\n",
        "    y_previsto_reshape = y_previsto.reshape(-1, 4)\n",
        "    y_teste_reshape = y_teste.reshape(-1, 4)\n",
        "\n",
        "    # Inverter normalização\n",
        "    y_previsto_original = scaler_precos.inverse_transform(y_previsto_reshape)\n",
        "    y_teste_original = scaler_precos.inverse_transform(y_teste_reshape)\n",
        "\n",
        "    # DataFrames nomeados\n",
        "    df_previsto = pd.DataFrame(y_previsto_original, columns=colunas_precos)\n",
        "    df_real = pd.DataFrame(y_teste_original, columns=colunas_precos)\n",
        "\n",
        "    # Comparação\n",
        "    comparacao = pd.DataFrame({\n",
        "        'Abertura_Real': df_real['abertura'],\n",
        "        'Abertura_Prevista': df_previsto['abertura'],\n",
        "        'Maximo_Real': df_real['maximo'],\n",
        "        'Maximo_Previsto': df_previsto['maximo'],\n",
        "        'Minimo_Real': df_real['minimo'],\n",
        "        'Minimo_Previsto': df_previsto['minimo'],\n",
        "        'Fechamento_Real': df_real['fechamento'],\n",
        "        'Fechamento_Previsto': df_previsto['fechamento']\n",
        "    })\n",
        "\n",
        "    print(\"\\n📊 Comparação de previsões (valores reais):\")\n",
        "    print(comparacao.head(10))\n",
        "\n",
        "    # Função auxiliar para métricas\n",
        "    def calcular_metricas(y_real, y_previsto, nome):\n",
        "        mae = mean_absolute_error(y_real, y_previsto)\n",
        "        mse = mean_squared_error(y_real, y_previsto)\n",
        "        r2 = r2_score(y_real, y_previsto)\n",
        "        print(f\"{nome} - MAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "    print(\"\\n📈 Métricas de desempenho por coluna:\")\n",
        "    calcular_metricas(df_real['abertura'], df_previsto['abertura'], \"Abertura\")\n",
        "    calcular_metricas(df_real['maximo'], df_previsto['maximo'], \"Máximo\")\n",
        "    calcular_metricas(df_real['minimo'], df_previsto['minimo'], \"Mínimo\")\n",
        "    calcular_metricas(df_real['fechamento'], df_previsto['fechamento'], \"Fechamento\")\n",
        "\n",
        "    return df_real, df_previsto, comparacao\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FOx4USVH-3l",
        "outputId": "cd06638c-f6d7-401f-c2b4-14b9521ada70",
        "cellView": "form"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.calcular_metricas_avaliar_modelo import avaliar_modelo_lstm\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Caminhos e dados preparados\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv'\n",
        "\n",
        "    # Preparar dados\n",
        "    from scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n",
        "\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1/modelo_completo.keras')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QigGTL3DWGTb",
        "outputId": "58a046aa-1ae2-4b7e-9f33-859a9b207bf8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de preço salvo com sucesso.\n",
            "✅ Dados preparados salvos em: /content/Piloto_Day_Trade/data/transformed/dados_preparados_para_modelagem.csv\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step\n",
            "\n",
            "📊 Comparação de previsões (valores reais):\n",
            "   Abertura_Real  Abertura_Prevista  Maximo_Real  Maximo_Previsto  \\\n",
            "0          11.75          11.797084        11.77        11.819266   \n",
            "1          11.75          11.738138        11.78        11.759627   \n",
            "2          11.77          11.735560        11.79        11.759824   \n",
            "3          11.78          11.764517        11.80        11.790069   \n",
            "4          11.78          11.761155        11.78        11.788537   \n",
            "5          11.75          11.758376        11.79        11.787605   \n",
            "6          11.76          11.758621        11.77        11.789828   \n",
            "7          11.75          11.727757        11.77        11.762376   \n",
            "8          11.75          11.699660        11.76        11.733210   \n",
            "9          11.75          11.666211        11.78        11.696817   \n",
            "\n",
            "   Minimo_Real  Minimo_Previsto  Fechamento_Real  Fechamento_Previsto  \n",
            "0        11.73        11.796309            11.77            11.799382  \n",
            "1        11.75        11.740110            11.78            11.744620  \n",
            "2        11.76        11.733368            11.79            11.743937  \n",
            "3        11.73        11.755706            11.76            11.771626  \n",
            "4        11.72        11.750199            11.75            11.768753  \n",
            "5        11.75        11.745906            11.76            11.765841  \n",
            "6        11.75        11.743665            11.75            11.764983  \n",
            "7        11.75        11.710895            11.75            11.734612  \n",
            "8        11.74        11.682524            11.75            11.707520  \n",
            "9        11.75        11.650184            11.78            11.675851  \n",
            "\n",
            "📈 Métricas de desempenho por coluna:\n",
            "Abertura - MAE: 0.0606, MSE: 0.0061, R²: 0.7450\n",
            "Máximo - MAE: 0.0561, MSE: 0.0056, R²: 0.7650\n",
            "Mínimo - MAE: 0.0647, MSE: 0.0065, R²: 0.7285\n",
            "Fechamento - MAE: 0.0602, MSE: 0.0060, R²: 0.7485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline de dados"
      ],
      "metadata": {
        "id": "TTzGcdW3uxIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for nome in os.listdir('/content/Piloto_Day_Trade/scripts'):\n",
        "    print(nome)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX641OOUuztF",
        "outputId": "6a417acf-8ba6-46c2-c70b-92398e23b6d0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operacional\n",
            "Pipelines\n",
            "Modelagem_machine_learning\n",
            "__pycache__\n",
            ".ipynb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def listar_arquivos_em_subpastas(pasta_base):\n",
        "    for raiz, subpastas, arquivos in os.walk(pasta_base):\n",
        "        nivel = raiz.replace(pasta_base, '').count(os.sep)\n",
        "        indent = ' ' * 4 * nivel\n",
        "        print(f\"{indent}{os.path.basename(raiz)}/\")\n",
        "        subindent = ' ' * 4 * (nivel + 1)\n",
        "        for arquivo in arquivos:\n",
        "            print(f\"{subindent}{arquivo}\")\n",
        "\n",
        "# Caminho da pasta onde estão os scripts\n",
        "pasta_scripts = \"/content/Piloto_Day_Trade/scripts\"\n",
        "listar_arquivos_em_subpastas(pasta_scripts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5_tfm2NxWQy",
        "outputId": "a938068d-3867-409d-e726-fa979b11a5bb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scripts/\n",
            "    Operacional/\n",
            "        configurar_git.py\n",
            "        .ipynb_checkpoints/\n",
            "    Pipelines/\n",
            "        criar_banco_dimensional.py\n",
            "        limpeza_dados.py\n",
            "        carga_dados.py\n",
            "        gerar_catalogo_dados.py\n",
            "        transformacao_dados.py\n",
            "        extracao_dados.py\n",
            "    Modelagem_machine_learning/\n",
            "        preparar_dados_modelagem_LSTM.py\n",
            "        previsoes_XGBoot.py\n",
            "        modelo_LSTM_v1.py\n",
            "        calcular_metricas_avaliar_modelo_LSTM.py\n",
            "        calcular_metricas_avaliar_modelo.py\n",
            "    __pycache__/\n",
            "        transformacao_dados_v2.cpython-311.pyc\n",
            "        calcular_metricas_avaliar_modelo.cpython-311.pyc\n",
            "        preparar_dados_modelagem_LSTM.cpython-311.pyc\n",
            "        extracao_dados.cpython-311.pyc\n",
            "        transformacao_dados.cpython-311.pyc\n",
            "        gerar_catalogo.cpython-311.pyc\n",
            "        limpeza_basica_dadosv2.cpython-311.pyc\n",
            "        gerar_catalogo_dados.cpython-311.pyc\n",
            "        limpeza_dados.cpython-311.pyc\n",
            "        extracao_dados_v2.cpython-311.pyc\n",
            "    .ipynb_checkpoints/\n",
            "        modelagem_dados_XGBoot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### Transformer para Capturar Tendências de Longo Prazo:\n",
        "\n",
        "\"\"\"\n",
        "Entrada: Últimos dias úteis para identificar padrões de preço.\n",
        "\n",
        "Saída: Preços de abertura, máxima, mínima e fechamento do próximo dia útil.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7oG7QwBtKqT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}