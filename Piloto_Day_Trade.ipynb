{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+bHQNYnAfwQCkx6GHfNPp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarolBw/Piloto_Day_Trade/blob/main/Piloto_Day_Trade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/MVP_Objetivo.md\n",
        "#@title **Objetivo do Projeto**\n",
        "\n",
        "### 1. Prop√≥sito do MVP\n",
        "\n",
        "Este projeto tem como objetivo principal a cria√ß√£o de um pipeline para extra√ß√£o, transforma√ß√£o, carga, an√°lise e previs√£o da movimenta√ß√£o intradi√°ria dos pre√ßos de um ativo financeiro em intervalos de 5 minutos. O modelo preditivo central ser√° baseado em redes neurais recorrentes (LSTM), mas outras abordagens ser√£o exploradas. O MVP visa garantir previs√µes para embasar decis√µes estrat√©gicas de day trade.\n",
        "\n",
        "### 2. Problema a Ser Resolvido\n",
        "\n",
        "A alta volatilidade dos mercados financeiros exige ferramentas robustas para antecipa√ß√£o de movimentos de pre√ßo. A dificuldade est√° em capturar padr√µes de curto prazo e projet√°-los com precis√£o. Traders e investidores necessitam de um modelo que consiga interpretar os padr√µes hist√≥ricos e transform√°-los em previs√µes √∫teis.\n",
        "\n",
        "### 3. Pipeline do Projeto\n",
        "\n",
        "O projeto ser√° estruturado em sete etapas principais:\n",
        "\n",
        "1. **Extra√ß√£o e armazenamento dos dados brutos:** Coleta de dados hist√≥ricos de ativos financeiros em intervalos de 15 minutos utilizando a API do Yahoo Finance (yfinance). Os dados ser√£o armazenados em um reposit√≥rio GitHub sincronizado com Google Colab, garantindo acesso remoto e backup na nuvem.\n",
        "\n",
        "2. **Limpeza e organiza√ß√£o dos dados:** Padroniza√ß√£o de colunas, tratamento de dados ausentes, elimina√ß√£o de duplicatas e organiza√ß√£o cronol√≥gica. Resultado salvo como `dados_limpos.csv`.\n",
        "\n",
        "3. **Transforma√ß√£o e engenharia de features:** Adi√ß√£o de indicadores t√©cnicos (como m√©dias m√≥veis, RSI, MACD), cria√ß√£o de vari√°veis de lag e retornos. Resultado salvo como `dados_transformados.csv`.\n",
        "\n",
        "4. **Modelagem e estrutura√ß√£o do banco de dados:**\n",
        "\n",
        "   a) Organiza√ß√£o em arquivos CSV:\n",
        "\n",
        "   - `dados_brutos.csv`: dados originais extra√≠dos da API.\n",
        "   - `dados_limpos.csv`: ap√≥s limpeza e padroniza√ß√£o.\n",
        "   - `dados_transformados.csv`: ap√≥s adi√ß√£o de features t√©cnicas.\n",
        "   - `dados_final.csv`: vers√£o padronizada e normalizada dos dados.\n",
        "\n",
        "   b) Banco de dados dimensional:\n",
        "\n",
        "   - **Fato**: `fato_precos`, contendo os valores de fechamento e chaves para dimens√µes.\n",
        "   - **Dimens√µes**:\n",
        "     - `dim_tempo`: atributos temporais.\n",
        "     - `dim_indicadores`: indicadores t√©cnicos.\n",
        "     - `dim_lags`: varia√ß√µes e lags recentes.\n",
        "\n",
        "   Um **Cat√°logo de Dados** ser√° elaborado com descri√ß√£o, dom√≠nio, categorias e linhagem de cada vari√°vel.\n",
        "\n",
        "5. **Carga e Pipeline ETL:** Pipeline estruturado com as seguintes etapas:\n",
        "\n",
        "   - **Extra√ß√£o:** via API do Yahoo Finance.\n",
        "   - **Limpeza:** tratamento e estrutura√ß√£o b√°sica.\n",
        "   - **Transforma√ß√£o:** gera√ß√£o de vari√°veis t√©cnicas e derivadas.\n",
        "   - **Carga:** integra√ß√£o dos dados transformados no banco dimensional (fato e dimens√µes).\n",
        "\n",
        "6. **Treinamento e ajuste do modelo:** Implementa√ß√£o e ajuste de modelos preditivos (LSTM como baseline), com avalia√ß√£o por m√©tricas como MSE e R¬≤.\n",
        "\n",
        "7. **Interpreta√ß√£o dos resultados e resposta √†s perguntas:** Valida√ß√£o das previs√µes, an√°lise de vari√°veis relevantes e contribui√ß√£o dos resultados para decis√µes de trading.\n",
        "\n",
        "### 4. Perguntas a Serem Respondidas\n",
        "\n",
        "- √â poss√≠vel prever com precis√£o a movimenta√ß√£o intradi√°ria de um ativo a cada 15 minutos?\n",
        "- Os dados do dia anterior fornecem informa√ß√µes suficientes para a previs√£o do dia seguinte?\n",
        "- A modelagem com LSTM captura corretamente as tend√™ncias de curto prazo?\n",
        "- A previs√£o da movimenta√ß√£o intradi√°ria tamb√©m permite derivar com precis√£o as targets globais do dia (abertura, m√≠nima, m√°xima e fechamento)?\n",
        "- Quais indicadores t√©cnicos e features s√£o mais relevantes para melhorar a acur√°cia do modelo?\n",
        "- Como considerar corretamente as quebras de fim de semana (exemplo: prever a segunda-feira usando os dados de sexta-feira)?\n",
        "- A normaliza√ß√£o e padroniza√ß√£o das vari√°veis melhora a precis√£o do modelo?\n",
        "\n",
        "### 5. Crit√©rios de Sucesso\n",
        "\n",
        "Para que o MVP seja considerado bem-sucedido o esperado √© que:\n",
        "\n",
        "1. O pipeline de extra√ß√£o, transforma√ß√£o e previs√£o funcione de forma eficiente.\n",
        "2. O modelo consiga prever a movimenta√ß√£o dos pre√ßos com um erro m√©dio aceit√°vel (avaliado por MSE ou R2).\n",
        "3. A previs√£o de targets globais (abertura, m√°xima, m√≠nima, fechamento) seja consistente com os valores reais.\n",
        "4. O modelo consiga lidar corretamente com fins de semana e feriados.\n",
        "5. As previs√µes sejam suficientes para auxiliar na tomada de decis√£o de trading.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj0A_HHDW-dj",
        "outputId": "e384eac4-e4c0-4429-e152-3583d32e10cd",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/MVP_Objetivo.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No6u9fG0h8-A",
        "outputId": "5f0b4bbd-cfb6-498c-96bb-bf47802159d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/.env\n"
          ]
        }
      ],
      "source": [
        "#@title ## Escrevendo vari√°veis sensiveis\n",
        "\n",
        "%%writefile /content/.env\n",
        "\n",
        "PROJECT_NAME=Piloto_Day_Trade\n",
        "\n",
        "# Vari√°veis de ambiente para o Github\n",
        "GITHUB_USERNAME=CarolBw\n",
        "GITHUB_TOKEN =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\n",
        "EMAIL=carolbrescowitt@yahoo.com.br\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Instalando depend√™ncias\n",
        "'''\n",
        "Usamos `-q` para ocultar a sa√≠da detalhada e mostrar apenas a barra de progresso\n",
        "\n",
        "'''\n",
        "!pip install -q tensorflow > /dev/null  # Framework para redes neurais e deep learning\n",
        "!pip install -q keras > /dev/null  # Biblioteca de alto n√≠vel para redes neurais\n",
        "!pip install -q pandas > /dev/null  # Manipula√ß√£o e an√°lise de dados\n",
        "!pip install -q numpy > /dev/null  # Computa√ß√£o num√©rica eficiente\n",
        "!pip install -q matplotlib > /dev/null  # Visualiza√ß√£o de gr√°ficos e an√°lise explorat√≥ria\n",
        "!pip install -q scikit-learn > /dev/null  # Ferramentas para pr√©-processamento e m√©tricas de avalia√ß√£o\n",
        "!pip install -q gitpython > /dev/null  # Gerenciamento de reposit√≥rios Git via Python\n",
        "!pip install -q python-dotenv > /dev/null  # Manipula√ß√£o de vari√°veis de ambiente\n",
        "!pip install -q seaborn > /dev/null  # Biblioteca de visualiza√ß√£o estat√≠stica baseada no Matplotlib\n",
        "!pip install -q yfinance > /dev/null  # Coleta de dados financeiros diretamente do Yahoo Finance\n",
        "!pip install -q sqlalchemy > /dev/null  # ORM para interagir com bancos de dados relacionais\n",
        "!pip install -q dotenv > /dev/null # Manipula√ß√£o de vari√°veis de ambiente\n",
        "\n",
        "# Importa√ß√µes das bibliotecas\n",
        "import pandas as pd  # Manipula√ß√£o de DataFrames\n",
        "import numpy as np  # C√°lculos num√©ricos e matrizes\n",
        "import matplotlib.pyplot as plt  # Gera√ß√£o de gr√°ficos\n",
        "import sqlite3  # Integra√ß√£o com banco de dados SQLite\n",
        "\n",
        "# Pr√©-processamento dos dados\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler  # Normaliza√ß√£o e padroniza√ß√£o dos dados\n",
        "from sklearn.model_selection import train_test_split  # Divis√£o dos dados em treino e teste\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error  # Avalia√ß√£o do desempenho do modelo\n",
        "\n",
        "# Constru√ß√£o do modelo preditivo\n",
        "from keras.models import Sequential  # Modelo sequencial de rede neural\n",
        "from keras.layers import Dense  # Camada densa para aprendizado profundo\n",
        "\n",
        "# Controle de vers√£o e vari√°veis de ambiente\n",
        "import git  # Gerenciamento do reposit√≥rio Git\n",
        "import dotenv  # Carregamento de vari√°veis de ambiente\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Carregar vari√°veis de ambiente\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "# Capturamdo todas as dependencias do ambiente nesta primeira etapa\n",
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LWOFHzJ6IupA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Configurando sincroniza√ß√£o com Github\n",
        "\n",
        "%%writefile /content/configurar_git.py\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(dotenv_path='/content/.env')\n",
        "\n",
        "def git_config():\n",
        "    \"\"\"Configura o Git localmente e sincroniza com o reposit√≥rio remoto no GitHub.\"\"\"\n",
        "\n",
        "    # Carregar vari√°veis de ambiente do arquivo .env\n",
        "    load_dotenv(dotenv_path='/content/.env')\n",
        "\n",
        "    # Obter as vari√°veis de ambiente do .env para o GitHub\n",
        "    GITHUB_USERNAME = os.getenv('GITHUB_USERNAME')\n",
        "    EMAIL = os.getenv('EMAIL')\n",
        "    GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')\n",
        "    PROJECT_NAME = os.getenv('PROJECT_NAME')\n",
        "    REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{PROJECT_NAME}.git\"\n",
        "\n",
        "    # Configurar o Git localmente com as credenciais\n",
        "    os.system(f'git config --global user.name \"{GITHUB_USERNAME}\"')\n",
        "    os.system(f'git config --global user.email \"{EMAIL}\"')\n",
        "\n",
        "    # Verificar se o diret√≥rio do projeto j√° existe e se √© um reposit√≥rio Git v√°lido\n",
        "    if os.path.isdir(PROJECT_NAME):\n",
        "        print(f\"O diret√≥rio '{PROJECT_NAME}' j√° existe. Entrando no diret√≥rio e sincronizando...\")\n",
        "\n",
        "        os.chdir(PROJECT_NAME)  # Entrar na pasta do projeto\n",
        "\n",
        "        # Garantir que estamos na branch main\n",
        "        os.system(\"git branch -M main\")\n",
        "\n",
        "        # Remover qualquer configura√ß√£o errada do reposit√≥rio remoto e adicionar novamente\n",
        "        os.system(\"git remote remove origin\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Puxar as √∫ltimas atualiza√ß√µes do GitHub, tratando hist√≥ricos n√£o relacionados\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "    else:\n",
        "        print(f\"Clonando o reposit√≥rio '{PROJECT_NAME}'...\")\n",
        "\n",
        "        # Clonar o reposit√≥rio remoto\n",
        "        os.system(f\"git clone {REPO_URL}\")\n",
        "        os.chdir(PROJECT_NAME)  # Entrar no diret√≥rio ap√≥s o clone\n",
        "\n",
        "        # Inicializar o reposit√≥rio Git local (se necess√°rio) e configurar remoto\n",
        "        os.system(\"git branch -M main\")\n",
        "        os.system(\"git remote add origin \" + REPO_URL)\n",
        "\n",
        "        # Realizar o pull inicial para garantir que a branch main est√° sincronizada\n",
        "        os.system(\"git pull origin main --allow-unrelated-histories --no-rebase\")\n",
        "\n",
        "    print(f\"‚úÖ Configura√ß√£o do Git conclu√≠da e sincronizada com a branch main do reposit√≥rio{REPO_URL}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    git_config()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSdFzemI9yY",
        "outputId": "d2dd9f8a-1a39-4d37-d018-8b09ecb61afb",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/configurar_git.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sincronizando reposit√≥rio\n",
        "\n",
        "from configurar_git import git_config\n",
        "git_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLWe41oYxhcr",
        "outputId": "10691fea-99f2-457f-c950-bdd9bfab3a3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando o reposit√≥rio 'Piloto_Day_Trade'...\n",
            "‚úÖ Configura√ß√£o do Git conclu√≠da e sincronizada com a branch main do reposit√≥riohttps://CarolBw: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@github.com/CarolBw/Piloto_Day_Trade.git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## üìÅ Definindo estrutura de pastas do projeto\n",
        "\n",
        "\"\"\"\n",
        "Estrutura inicial do reposit√≥rio Piloto_Day_Trade:\n",
        "\n",
        "|- notebooks/         ‚Üí Jupyter Notebooks para explora√ß√£o e an√°lises\n",
        "|- scripts/           ‚Üí Fun√ß√µes reutiliz√°veis (pr√©-processamento, modelagem, avalia√ß√£o, etc.)\n",
        "|- workflows/         ‚Üí Pipelines ou scripts principais (ex: main.py, pipeline_treinamento.py)\n",
        "|- modelagem/         ‚Üí Modelagem do banco de dados.\n",
        "|- data/              ‚Üí Dados organizados em 3 n√≠veis:\n",
        "   |- raw/            ‚Üí Dados brutos extra√≠dos diretamente de fontes externas\n",
        "   |- cleaned/        ‚Üí Dados limpos com tratamento b√°sico (ex: datas, nulos, nomes de colunas)\n",
        "   |- transformed/    ‚Üí Dados com features criadas e prontos para modelagem\n",
        "|- models/            ‚Üí Modelos treinados\n",
        "   |- scalers/        ‚Üí Scalers salvos (MinMaxScaler, StandardScaler, etc.)\n",
        "|- reports/           ‚Üí Resultados, gr√°ficos, relat√≥rios de performance\n",
        "|- MVP_Objetivo.md    ‚Üí Documento explicando o objetivo do projeto\n",
        "|- README.md          ‚Üí Instru√ß√µes gerais do projeto\n",
        "|-.env                ‚Üí Vari√°veis de ambiente e configura√ß√µes sens√≠veis\n",
        "|- requirements.txt   ‚Üí Lista de depend√™ncias\n",
        "\"\"\"\n",
        "\n",
        "# Criar estrutura de diret√≥rios\n",
        "!mkdir -p /content/Piloto_Day_Trade/notebooks\n",
        "!mkdir -p /content/Piloto_Day_Trade/scripts\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/raw\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/cleaned\n",
        "!mkdir -p /content/Piloto_Day_Trade/data/transformed\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem\n",
        "!mkdir -p /content/Piloto_Day_Trade/modelagem/catalog\n",
        "!mkdir -p /content/Piloto_Day_Trade/models\n",
        "!mkdir -p /content/Piloto_Day_Trade/models/scalers\n",
        "!mkdir -p /content/Piloto_Day_Trade/reports\n",
        "!mkdir -p /content/Piloto_Day_Trade/workflows\n",
        "\n",
        "# Criar arquivos principais\n",
        "!touch /content/Piloto_Day_Trade/.gitignore\n",
        "!touch /content/Piloto_Day_Trade/README.md\n",
        "\n",
        "# Mover arquivos existentes para suas localiza√ß√µes corretas\n",
        "!mv /content/.env /content/Piloto_Day_Trade/.env\n",
        "!mv /content/configurar_git.py /content/Piloto_Day_Trade/scripts/configurar_git.py\n",
        "!mv /content/requirements.txt /content/Piloto_Day_Trade/requirements.txt\n",
        "!mv /content/MVP_Objetivo.md /content/Piloto_Day_Trade/MVP_Objetivo.md\n"
      ],
      "metadata": {
        "id": "vVkhl3kbZKbs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando fun√ß√£o para atualizar o repositorio remoto\n",
        "\n",
        "def atualizar_repo(commit_message):\n",
        "    \"\"\"Atualiza o reposit√≥rio remoto no GitHub.\"\"\"\n",
        "    !git add .\n",
        "    !git commit -m commit_message\n",
        "    !git push origin main\n",
        "    print(\"‚úÖ Atualiza√ß√£o do reposit√≥rio conclu√≠da!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    commit_message = \"Atualiza√ß√£o de scripts\"\n",
        "    atualizar_repo(commit_message)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGqg5UeqMKbl",
        "outputId": "33333ed5-8484-4d37-fda7-088ef354aa7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 9414dd9] commit_message\n",
            " 2 files changed, 9 insertions(+), 17 deletions(-)\n",
            " rewrite .env (68%)\n",
            "Enumerating objects: 7, done.\n",
            "Counting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 370 bytes | 370.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/CarolBw/Piloto_Day_Trade.git\n",
            "   20f4c4c..9414dd9  main -> main\n",
            "‚úÖ Atualiza√ß√£o do reposit√≥rio conclu√≠da!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Extra√ß√£o de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/extracao_dados.py\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "def extrair_dados(ticker, dias, intervalo, dados_brutos):\n",
        "    \"\"\"Extrai e organiza dados do Yahoo Finance no intervalo correto.\"\"\"\n",
        "\n",
        "    df_total = pd.DataFrame()  # DataFrame para armazenar os dados\n",
        "    data_inicio = datetime.today() - timedelta(days=dias)  # Data inicial\n",
        "    data_fim = datetime.today() + timedelta(days=1)\n",
        "\n",
        "    # Verifica se o arquivo de dados brutos existe\n",
        "    if os.path.exists(dados_brutos):\n",
        "        df = pd.read_csv(dados_brutos, index_col=0, parse_dates=True)\n",
        "\n",
        "        if not df.empty:\n",
        "            # Atualiza a data de in√≠cio para a √∫ltima data dispon√≠vel nos dados brutos\n",
        "            ultima_data = pd.to_datetime(df.index.max())\n",
        "            data_inicio = ultima_data + timedelta(minutes=30)\n",
        "\n",
        "    print(f\"üîÑ Extraindo dados de {data_inicio.strftime('%Y-%m-%d %H:%M:%S')} at√© {data_fim.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # Extrai os dados do Yahoo Finance\n",
        "    df_novo = yf.download(\n",
        "        ticker,\n",
        "        start=data_inicio.strftime(\"%Y-%m-%d\"),\n",
        "        end=data_fim.strftime(\"%Y-%m-%d\"),\n",
        "        interval=intervalo,\n",
        "        progress=True\n",
        "    )\n",
        "\n",
        "    if not df_novo.empty:\n",
        "        # Apenas converte para \"America/Sao_Paulo\" se j√° tiver timezone\n",
        "        if df_novo.index.tzinfo is not None:\n",
        "            df_novo.index = df_novo.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "        # Concatena os novos dados com os existentes e remove duplicatas\n",
        "        df_total = pd.concat([df_total, df_novo]).drop_duplicates().sort_index()\n",
        "\n",
        "        # Remove linhas com mais de 50% de valores nulos\n",
        "        df_total = df_total.dropna(thresh=df_total.shape[1] * 0.5)\n",
        "\n",
        "        # Salva os dados atualizados no arquivo CSV\n",
        "        df_total.to_csv(dados_brutos)\n",
        "        print(\"‚úÖ Dados salvos com sucesso.\")\n",
        "\n",
        "    # Filtra os dados para o hor√°rio entre 10:00 e 18:00\n",
        "    df_filtrado = df_total.between_time(\"10:00\", \"18:00\")\n",
        "\n",
        "    # Exibe os 10 primeiros e os 10 √∫ltimos registros\n",
        "    print(\"√öltimos 10 dados filtrados:\")\n",
        "    print(df_filtrado.tail(10))\n",
        "    print(\"Primeiros 10 dados filtrados:\")\n",
        "    print(df_filtrado.head(10))\n",
        "\n",
        "    return df_filtrado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ticker = \"BBDC4.SA\"  # Ticker da a√ß√£o\n",
        "    intervalo = \"5m\"  # Intervalo de tempo (5 minutos)\n",
        "    dias = 45  # N√∫mero de dias a partir de hoje para buscar os dados\n",
        "    dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "    df = extrair_dados(ticker, dias, intervalo, dados_brutos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "a3JYaCsNw5fQ",
        "outputId": "daf66fa5-1f87-411f-f9b5-58800758cf8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/extracao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executando extra√ß√£o de dados extra√ß√£o de dados\n",
        "from Piloto_Day_Trade.scripts.extracao_dados import extrair_dados\n",
        "\n",
        "ticker = \"BBDC4.SA\"  # Ticker da a√ß√£o\n",
        "intervalo = \"5m\"  # Intervalo de tempo\n",
        "dias = 45  # N√∫mero de dias a partir de hoje para buscar os dados\n",
        "dados_brutos = \"/content/Piloto_Day_Trade/data/dados_brutos.csv\"  # Caminho do arquivo de dados brutos\n",
        "df = extrair_dados(ticker, dias, intervalo, dados_brutos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "OgEhS9Rwx_Im",
        "outputId": "356ec994-280b-4a29-eb1d-fe23bd748dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Extraindo dados de 2025-02-22 23:35:38 at√© 2025-04-09 23:35:38\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dados salvos com sucesso.\n",
            "√öltimos 10 dados filtrados:\n",
            "Price                        Close     High      Low     Open   Volume\n",
            "Ticker                    BBDC4.SA BBDC4.SA BBDC4.SA BBDC4.SA BBDC4.SA\n",
            "Datetime                                                              \n",
            "2025-04-08 16:05:00-03:00    11.99    11.99    11.95    11.98   303000\n",
            "2025-04-08 16:10:00-03:00    11.98    12.00    11.97    11.99   850600\n",
            "2025-04-08 16:15:00-03:00    12.01    12.05    11.97    11.97  1922000\n",
            "2025-04-08 16:20:00-03:00    12.03    12.05    12.00    12.02  1645100\n",
            "2025-04-08 16:25:00-03:00    12.05    12.07    12.03    12.03  1470500\n",
            "2025-04-08 16:30:00-03:00    12.03    12.05    12.02    12.05   459600\n",
            "2025-04-08 16:35:00-03:00    11.97    12.04    11.96    12.03   455300\n",
            "2025-04-08 16:40:00-03:00    11.97    12.00    11.96    11.97   848500\n",
            "2025-04-08 16:45:00-03:00    11.97    11.99    11.96    11.98   552100\n",
            "2025-04-08 16:50:00-03:00    11.98    11.99    11.96    11.97   445900\n",
            "Primeiros 10 dados filtrados:\n",
            "Price                        Close     High      Low     Open   Volume\n",
            "Ticker                    BBDC4.SA BBDC4.SA BBDC4.SA BBDC4.SA BBDC4.SA\n",
            "Datetime                                                              \n",
            "2025-02-24 10:00:00-03:00    11.81    11.86    11.81    11.86        0\n",
            "2025-02-24 10:05:00-03:00    11.80    11.84    11.80    11.81   189900\n",
            "2025-02-24 10:10:00-03:00    11.81    11.84    11.79    11.81   322200\n",
            "2025-02-24 10:15:00-03:00    11.78    11.81    11.77    11.81   350600\n",
            "2025-02-24 10:20:00-03:00    11.79    11.83    11.78    11.78   273700\n",
            "2025-02-24 10:25:00-03:00    11.80    11.80    11.78    11.79   272800\n",
            "2025-02-24 10:30:00-03:00    11.77    11.80    11.77    11.80   128200\n",
            "2025-02-24 10:35:00-03:00    11.78    11.79    11.76    11.78   216900\n",
            "2025-02-24 10:40:00-03:00    11.77    11.79    11.76    11.77   131100\n",
            "2025-02-24 10:45:00-03:00    11.76    11.78    11.75    11.77   183200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Limpeza de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/limpeza_dados.py\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def limpeza_dados(df):\n",
        "    # Verificar se os dados est√£o corretos\n",
        "    print(\"Dados originais:\")\n",
        "    print(df.head())\n",
        "    print(df.info())\n",
        "\n",
        "    # Remover as primeiras duas linhas (com 'Ticker' e 'Datetime')\n",
        "    df = df.iloc[2:].copy()\n",
        "\n",
        "    # Verificar ap√≥s a remo√ß√£o das linhas iniciais\n",
        "    print(\"Ap√≥s remo√ß√£o das duas primeiras linhas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que o √≠ndice esteja no formato de data e hora (timezone UTC)\n",
        "    df.index = pd.to_datetime(df.index, utc=True)\n",
        "\n",
        "    # Definir o fuso hor√°rio como \"America/Sao_Paulo\"\n",
        "    df.index = df.index.tz_convert(\"America/Sao_Paulo\")\n",
        "\n",
        "    # Remover a refer√™ncia de fuso hor√°rio (deixar o hor√°rio local sem informa√ß√£o de timezone)\n",
        "    df.index = df.index.tz_localize(None)\n",
        "\n",
        "    # Criar a coluna 'hora' com base no √≠ndice\n",
        "    df['hora'] = df.index.strftime('%H:%M:%S')\n",
        "\n",
        "    # Renomear o √≠ndice para 'data'\n",
        "    df.index.name = 'data'\n",
        "\n",
        "    # Resetar o √≠ndice para transformar o Datetime em uma coluna normal\n",
        "    df = df.reset_index()\n",
        "\n",
        "    # Verificar ap√≥s a transforma√ß√£o do √≠ndice\n",
        "    print(\"\\nAp√≥s convers√£o de √≠ndice:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Remover o hor√°rio da coluna 'data', mantendo apenas a data\n",
        "    df['data'] = df['data'].dt.date\n",
        "\n",
        "    # Mapeamento das colunas para nomes padronizados\n",
        "    mapeamento_colunas = {\n",
        "        'Close': 'fechamento',\n",
        "        'High': 'maximo',\n",
        "        'Low': 'minimo',\n",
        "        'Open': 'abertura',\n",
        "        'Volume': 'volume'\n",
        "    }\n",
        "\n",
        "    # Renomear as colunas\n",
        "    df.rename(columns=mapeamento_colunas, inplace=True)\n",
        "\n",
        "    # Converte e arredonda as colunas num√©ricas\n",
        "    for col in ['abertura', 'minimo', 'maximo', 'fechamento']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').round(2)\n",
        "\n",
        "    # Converte a coluna 'volume' para n√∫mero inteiro\n",
        "    df['volume'] = pd.to_numeric(df['volume'], errors='coerce', downcast='integer')\n",
        "\n",
        "    # Reorganiza as colunas na ordem desejada\n",
        "    df = df[['data', 'hora', 'abertura', 'minimo', 'maximo', 'fechamento', 'volume']]\n",
        "\n",
        "    # Verificar ap√≥s reorganizar as colunas\n",
        "    print(\"\\nAp√≥s reorganizar as colunas:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Verificar e remover duplicatas mantendo a primeira ocorr√™ncia\n",
        "    df = df.drop_duplicates(keep='first')\n",
        "\n",
        "    # Remover as linhas com 50% ou mais de valores nulos\n",
        "    df = df.dropna(thresh=df.shape[1] * 0.5)\n",
        "\n",
        "    # Verificar ap√≥s remo√ß√£o de duplicatas e nulos\n",
        "    print(\"\\nAp√≥s remover duplicatas e nulos:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Garantir que 'data' e 'hora' estejam no formato datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d')\n",
        "    df['hora'] = pd.to_datetime(df['hora'], format='%H:%M:%S').dt.time\n",
        "\n",
        "    # Filtra apenas os dias √∫teis (segunda a sexta)\n",
        "    df = df[df['data'].dt.weekday < 5]\n",
        "\n",
        "    # Verificar ap√≥s filtrar dias √∫teis\n",
        "    print(\"\\nAp√≥s filtrar apenas os dias √∫teis:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Filtra apenas hor√°rios entre 09:55 e 18:05\n",
        "    df = df[(df['hora'] >= pd.to_datetime('09:55:00').time()) &\n",
        "            (df['hora'] <= pd.to_datetime('18:05:00').time())]\n",
        "\n",
        "    # Verificar ap√≥s filtrar o intervalo de hor√°rio\n",
        "    print(\"\\nAp√≥s filtrar o intervalo de hor√°rio (09:55-18:05):\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Caso o DataFrame fique vazio, informar o motivo\n",
        "    if df.empty:\n",
        "        print(\"O DataFrame ficou vazio ap√≥s o filtro de hor√°rio. Verifique se os dados est√£o dentro do intervalo de 09:55-18:05.\")\n",
        "    else:\n",
        "        print(\"\\nLimpeza de dados conclu√≠da com sucesso.\")\n",
        "\n",
        "    # Ordenar os dados\n",
        "    df = df.sort_values([\"data\", \"hora\"], ascending=[False, True])\n",
        "    print(\"\\nDados limpos e ordenados:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Salva os dados limpos em CSV\n",
        "    df.to_csv(f\"/content/Piloto_Day_Trade/data/dados_limpos.csv\", index=False)\n",
        "    print(f\"\\nOs dados foram limpos e salvos em csv.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ler os dados brutos\n",
        "    dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "    # Aplicar limpeza nos dados\n",
        "    df_limpo = limpeza_dados(dados_brutos)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "DIHkNWR1-QS4",
        "outputId": "29e10304-65c3-412a-ff4f-976a6bfdde2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/limpeza_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Aplicando limpeza de dados\n",
        "from Piloto_Day_Trade.scripts.limpeza_dados import limpeza_dados\n",
        "\n",
        "dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n",
        "df_limpo = limpeza_dados(dados_brutos)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "97mwKCsf1V3x",
        "outputId": "94e47a66-0ee8-489e-db38-92a535cbd27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados originais:\n",
            "                                        Close                High  \\\n",
            "Price                                                               \n",
            "Ticker                               BBDC4.SA            BBDC4.SA   \n",
            "Datetime                                  NaN                 NaN   \n",
            "2025-02-24 10:00:00-03:00    11.8100004196167  11.859999656677246   \n",
            "2025-02-24 10:05:00-03:00  11.800000190734863   11.84000015258789   \n",
            "2025-02-24 10:10:00-03:00    11.8100004196167   11.84000015258789   \n",
            "\n",
            "                                          Low                Open    Volume  \n",
            "Price                                                                        \n",
            "Ticker                               BBDC4.SA            BBDC4.SA  BBDC4.SA  \n",
            "Datetime                                  NaN                 NaN       NaN  \n",
            "2025-02-24 10:00:00-03:00    11.8100004196167  11.859999656677246         0  \n",
            "2025-02-24 10:05:00-03:00  11.800000190734863    11.8100004196167    189900  \n",
            "2025-02-24 10:10:00-03:00  11.789999961853027    11.8100004196167    322200  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2464 entries, Ticker to 2025-04-08 16:50:00-03:00\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Close   2463 non-null   object\n",
            " 1   High    2463 non-null   object\n",
            " 2   Low     2463 non-null   object\n",
            " 3   Open    2463 non-null   object\n",
            " 4   Volume  2463 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 115.5+ KB\n",
            "None\n",
            "Ap√≥s remo√ß√£o das duas primeiras linhas:\n",
            "                                        Close                High  \\\n",
            "Price                                                               \n",
            "2025-02-24 10:00:00-03:00    11.8100004196167  11.859999656677246   \n",
            "2025-02-24 10:05:00-03:00  11.800000190734863   11.84000015258789   \n",
            "2025-02-24 10:10:00-03:00    11.8100004196167   11.84000015258789   \n",
            "2025-02-24 10:15:00-03:00  11.779999732971191    11.8100004196167   \n",
            "2025-02-24 10:20:00-03:00  11.789999961853027  11.829999923706055   \n",
            "\n",
            "                                          Low                Open  Volume  \n",
            "Price                                                                      \n",
            "2025-02-24 10:00:00-03:00    11.8100004196167  11.859999656677246       0  \n",
            "2025-02-24 10:05:00-03:00  11.800000190734863    11.8100004196167  189900  \n",
            "2025-02-24 10:10:00-03:00  11.789999961853027    11.8100004196167  322200  \n",
            "2025-02-24 10:15:00-03:00  11.770000457763672    11.8100004196167  350600  \n",
            "2025-02-24 10:20:00-03:00  11.779999732971191  11.779999732971191  273700  \n",
            "\n",
            "Ap√≥s convers√£o de √≠ndice:\n",
            "                 data               Close                High  \\\n",
            "0 2025-02-24 10:00:00    11.8100004196167  11.859999656677246   \n",
            "1 2025-02-24 10:05:00  11.800000190734863   11.84000015258789   \n",
            "2 2025-02-24 10:10:00    11.8100004196167   11.84000015258789   \n",
            "3 2025-02-24 10:15:00  11.779999732971191    11.8100004196167   \n",
            "4 2025-02-24 10:20:00  11.789999961853027  11.829999923706055   \n",
            "\n",
            "                  Low                Open  Volume      hora  \n",
            "0    11.8100004196167  11.859999656677246       0  10:00:00  \n",
            "1  11.800000190734863    11.8100004196167  189900  10:05:00  \n",
            "2  11.789999961853027    11.8100004196167  322200  10:10:00  \n",
            "3  11.770000457763672    11.8100004196167  350600  10:15:00  \n",
            "4  11.779999732971191  11.779999732971191  273700  10:20:00  \n",
            "\n",
            "Ap√≥s reorganizar as colunas:\n",
            "         data      hora  abertura  minimo  maximo  fechamento  volume\n",
            "0  2025-02-24  10:00:00     11.86   11.81   11.86       11.81       0\n",
            "1  2025-02-24  10:05:00     11.81   11.80   11.84       11.80  189900\n",
            "2  2025-02-24  10:10:00     11.81   11.79   11.84       11.81  322200\n",
            "3  2025-02-24  10:15:00     11.81   11.77   11.81       11.78  350600\n",
            "4  2025-02-24  10:20:00     11.78   11.78   11.83       11.79  273700\n",
            "\n",
            "Ap√≥s remover duplicatas e nulos:\n",
            "         data      hora  abertura  minimo  maximo  fechamento  volume\n",
            "0  2025-02-24  10:00:00     11.86   11.81   11.86       11.81       0\n",
            "1  2025-02-24  10:05:00     11.81   11.80   11.84       11.80  189900\n",
            "2  2025-02-24  10:10:00     11.81   11.79   11.84       11.81  322200\n",
            "3  2025-02-24  10:15:00     11.81   11.77   11.81       11.78  350600\n",
            "4  2025-02-24  10:20:00     11.78   11.78   11.83       11.79  273700\n",
            "\n",
            "Ap√≥s filtrar apenas os dias √∫teis:\n",
            "        data      hora  abertura  minimo  maximo  fechamento  volume\n",
            "0 2025-02-24  10:00:00     11.86   11.81   11.86       11.81       0\n",
            "1 2025-02-24  10:05:00     11.81   11.80   11.84       11.80  189900\n",
            "2 2025-02-24  10:10:00     11.81   11.79   11.84       11.81  322200\n",
            "3 2025-02-24  10:15:00     11.81   11.77   11.81       11.78  350600\n",
            "4 2025-02-24  10:20:00     11.78   11.78   11.83       11.79  273700\n",
            "\n",
            "Ap√≥s filtrar o intervalo de hor√°rio (09:55-18:05):\n",
            "        data      hora  abertura  minimo  maximo  fechamento  volume\n",
            "0 2025-02-24  10:00:00     11.86   11.81   11.86       11.81       0\n",
            "1 2025-02-24  10:05:00     11.81   11.80   11.84       11.80  189900\n",
            "2 2025-02-24  10:10:00     11.81   11.79   11.84       11.81  322200\n",
            "3 2025-02-24  10:15:00     11.81   11.77   11.81       11.78  350600\n",
            "4 2025-02-24  10:20:00     11.78   11.78   11.83       11.79  273700\n",
            "\n",
            "Limpeza de dados conclu√≠da com sucesso.\n",
            "\n",
            "Dados limpos e ordenados:\n",
            "           data      hora  abertura  minimo  maximo  fechamento  volume\n",
            "2379 2025-04-08  10:00:00     12.47   12.40   12.47       12.41  112000\n",
            "2380 2025-04-08  10:05:00     12.41   12.37   12.45       12.41  300500\n",
            "2381 2025-04-08  10:10:00     12.41   12.41   12.46       12.44  190600\n",
            "2382 2025-04-08  10:15:00     12.44   12.38   12.45       12.39  181600\n",
            "2383 2025-04-08  10:20:00     12.40   12.39   12.45       12.43  428200\n",
            "2384 2025-04-08  10:25:00     12.45   12.44   12.54       12.49  836500\n",
            "2385 2025-04-08  10:30:00     12.48   12.45   12.53       12.47  884100\n",
            "2386 2025-04-08  10:35:00     12.48   12.43   12.50       12.46  443400\n",
            "2387 2025-04-08  10:40:00     12.46   12.42   12.49       12.48  388900\n",
            "2388 2025-04-08  10:45:00     12.47   12.43   12.49       12.43  281900\n",
            "\n",
            "Os dados foram limpos e salvos em csv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-15edcd972d5a>:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  dados_brutos = pd.read_csv(f\"/content/Piloto_Day_Trade/data/dados_brutos.csv\", index_col=0, parse_dates=True, dayfirst=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Transforma√ß√£o de dados\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/transformacao_dados.py\n",
        "\n",
        "\"\"\"\n",
        "Fun√ß√£o de Transforma√ß√£o de Dados para Modelagem Preditiva\n",
        "Processa e transforma os dados para an√°lise e previs√£o, gerando um conjunto\n",
        "de caracter√≠sticas para serem utilizadas no treinamento dos modelos.\n",
        "\n",
        "Objetivos:\n",
        "- Criar um dataset com vari√°veis relevantes para o modelo.\n",
        "- Incluir indicadores t√©cnicos, estat√≠sticas de volatilidade, m√©dias m√≥veis e outras features.\n",
        "- Permitir a experimenta√ß√£o com diferentes combina√ß√µes de features.\n",
        "\n",
        "Estrat√©gia:\n",
        "- Durante os testes de parametriza√ß√£o e treinamento, ser√£o geradas diferentes vers√µes do dataset,\n",
        "refinando a sele√ß√£o de features a medida que geramos acur√°cia.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carregar vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "def carregar_dados(arquivo):\n",
        "    \"\"\"Carrega um CSV e retorna um DataFrame, ou um DataFrame vazio se o arquivo n√£o existir.\"\"\"\n",
        "    if isinstance(arquivo, pd.DataFrame):\n",
        "        return arquivo  # Se j√° for um DataFrame, retorna diretamente\n",
        "\n",
        "    if not os.path.exists(arquivo):\n",
        "        print(f\"‚ö†Ô∏è O arquivo {arquivo} n√£o existe. Criando um novo DataFrame vazio.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(arquivo, parse_dates=[\"data\"])\n",
        "        print(f\"‚úÖ Arquivo {arquivo} carregado com {len(df)} linhas.\")\n",
        "        return df if not df.empty else pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao carregar {arquivo}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def obter_ultima_data(df):\n",
        "    \"\"\"Retorna a √∫ltima data dispon√≠vel nos dados.\"\"\"\n",
        "    if \"data\" in df.columns and not df.empty:\n",
        "        ultima_data = df[\"data\"].max()\n",
        "        print(f\"üìÖ √öltima data encontrada nos dados: {ultima_data}\")\n",
        "        return ultima_data\n",
        "    return None\n",
        "\n",
        "def filtrar_novos_dados(df, ultima_data):\n",
        "    \"\"\"Filtra os dados para incluir apenas os novos registros.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado limpo dispon√≠vel.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if ultima_data:\n",
        "        df_novo = df[df[\"data\"] > ultima_data]\n",
        "        print(f\"üìä Dados novos filtrados: {len(df_novo)} registros encontrados.\")\n",
        "        return df_novo\n",
        "    return df\n",
        "\n",
        "def calcular_indicadores(df):\n",
        "    \"\"\"Calcula indicadores t√©cnicos e gera novas features para an√°lise de dados financeiros.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado dispon√≠vel para calcular indicadores.\")\n",
        "        return df\n",
        "\n",
        "    colunas_necessarias = [\"data\", \"hora\", \"abertura\", \"minimo\", \"maximo\", \"fechamento\", \"volume\"]\n",
        "\n",
        "    if not all(col in df.columns for col in colunas_necessarias):\n",
        "        print(\"‚ùå Dados insuficientes para c√°lculo de indicadores.\")\n",
        "        return df\n",
        "\n",
        "    # Ordena√ß√£o correta dos dados\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[True, True])\n",
        "\n",
        "    # C√°lculo do retorno percentual e volatilidade\n",
        "    df['retorno'] = df['fechamento'].pct_change()\n",
        "    df['volatilidade'] = df['retorno'].rolling(20).std()\n",
        "\n",
        "    # M√©dias m√≥veis\n",
        "    df['SMA_10'] = df['fechamento'].rolling(10).mean()\n",
        "    df['EMA_10'] = df['fechamento'].ewm(span=10, adjust=False).mean()\n",
        "\n",
        "    # MACD e linha de sinal\n",
        "    df['MACD'] = df['fechamento'].ewm(span=12).mean() - df['fechamento'].ewm(span=26).mean()\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=9).mean()\n",
        "\n",
        "    # RSI (√çndice de For√ßa Relativa)\n",
        "    ganho = df['retorno'].clip(lower=0)\n",
        "    perda = -df['retorno'].clip(upper=0)\n",
        "    media_ganho = ganho.ewm(span=14).mean()\n",
        "    media_perda = perda.ewm(span=14).mean() + 1e-10\n",
        "    df['rsi'] = 100 - (100 / (1 + (media_ganho / media_perda)))\n",
        "\n",
        "    # OBV (On Balance Volume)\n",
        "    df['OBV'] = (df['volume'] * np.sign(df['fechamento'].diff())).fillna(0).cumsum()\n",
        "\n",
        "    # Criar lags para fechamento, retorno e volume\n",
        "    for lag in range(1, 4):\n",
        "        df[f'fechamento_lag{lag}'] = df['fechamento'].shift(lag)\n",
        "        df[f'retorno_lag{lag}'] = df['retorno'].shift(lag)\n",
        "        df[f'volume_lag{lag}'] = df['volume'].shift(lag)\n",
        "\n",
        "    # Substituir NaN por zero onde necess√°rio\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    # Ordena√ß√£o final\n",
        "    df = df.sort_values(by=['data', 'hora'], ascending=[False, True])\n",
        "\n",
        "    print(f\"‚úÖ Indicadores calculados. Tamanho final do DataFrame: {len(df)} linhas.\")\n",
        "    return df\n",
        "\n",
        "def adicionar_features_temporais(df):\n",
        "    \"\"\"Adiciona colunas temporais para an√°lise de s√©ries temporais.\"\"\"\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado dispon√≠vel para processamento.\")\n",
        "        return df\n",
        "\n",
        "    # Converter 'data' para datetime se necess√°rio\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "\n",
        "    # Criar coluna do dia da semana para entrada e previs√£o\n",
        "    df['dia_da_semana_entrada'] = df['data'].dt.weekday  # 0 = Segunda, 6 = Domingo\n",
        "    df['data_previsao'] = df['data'] + pd.DateOffset(days=1)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Ajustar casos de sexta-feira para segunda-feira\n",
        "    df.loc[df['dia_da_semana_entrada'] == 4, 'data_previsao'] += pd.DateOffset(days=2)\n",
        "    df['dia_da_semana_previsao'] = df['data_previsao'].dt.weekday\n",
        "\n",
        "    # Verificar se 'hora' est√° presente e converter corretamente\n",
        "    if 'hora' in df.columns:\n",
        "        df['hora'] = pd.to_datetime(df['hora'].astype(str), format='%H:%M:%S', errors='coerce').dt.time\n",
        "\n",
        "        # Criar colunas de hora e minuto\n",
        "        df['hora_num'] = df['hora'].apply(lambda x: x.hour if pd.notnull(x) else np.nan)\n",
        "        df['minuto'] = df['hora'].apply(lambda x: x.minute if pd.notnull(x) else np.nan)\n",
        "\n",
        "        # Criar coluna indicando se o mercado est√° aberto (entre 10h e 17h)\n",
        "        df['mercado_aberto'] = ((df['hora_num'] >= 10) & (df['hora_num'] <= 17)).astype(int)\n",
        "    else:\n",
        "        df['hora_num'] = np.nan\n",
        "        df['minuto'] = np.nan\n",
        "        df['mercado_aberto'] = 0\n",
        "\n",
        "    return df\n",
        "\n",
        "def transformar_dados(dados_limpos, dados_transformados):\n",
        "    \"\"\"Executa o processo de transforma√ß√£o dos dados.\"\"\"\n",
        "\n",
        "    df_transformado = carregar_dados(dados_transformados)\n",
        "    df_limpo = carregar_dados(dados_limpos)\n",
        "\n",
        "\n",
        "    if df_transformado.empty:\n",
        "        print(\"üìÇ Nenhum dado transformado encontrado. Criando novo DataFrame.\")\n",
        "\n",
        "    ultima_data = obter_ultima_data(df_transformado)\n",
        "    novos_dados = filtrar_novos_dados(df_limpo, ultima_data)\n",
        "\n",
        "    if not novos_dados.empty:\n",
        "        novos_dados = calcular_indicadores(novos_dados)\n",
        "        novos_dados = adicionar_features_temporais(novos_dados)\n",
        "        df_final = pd.concat([df_transformado, novos_dados], ignore_index=True) if not df_transformado.empty else novos_dados\n",
        "\n",
        "        pasta = os.path.dirname(dados_transformados)\n",
        "        if not os.path.exists(pasta):\n",
        "            os.makedirs(pasta)\n",
        "            print(f\"üìÇ Criando diret√≥rio: {pasta}\")\n",
        "\n",
        "        df_final.to_csv(dados_transformados, index=False)\n",
        "        print(f\"‚úÖ Dados transformados salvos em {dados_transformados} ({len(df_final)} registros)\")\n",
        "        print(f\"üìÖ √öltima data dispon√≠vel nos dados: {df_final['data'].max()}\")\n",
        "        print(f\"df_final: {df_final.head(5)}\")\n",
        "        return df_final\n",
        "    else:\n",
        "        print(\"‚è≠Ô∏è Nenhum novo dado para processar.\")\n",
        "        print(f\"üìÖ √öltima data dispon√≠vel nos dados: {df_transformado['data'].max()}\")\n",
        "        print(f\"df_transformado: {df_transformado.head(5)}\")\n",
        "        return df_transformado\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados_limpos = '/content/Piloto_Day_Trade/data/dados_limpos.csv'\n",
        "    path_dados_transformados = '/content/Piloto_Day_Trade/data/dados_transformados_3103.csv'\n",
        "    df_transformado =transformar_dados(path_dados_limpos, path_dados_transformados)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH35zARUD6jA",
        "outputId": "76b78457-9b67-43da-8184-010832e6dc62",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/transformacao_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.transformacao_dados import transformar_dados\n",
        "\n",
        "#@title Aplicando transforma√ß√£o de dados\n",
        "path_dados_limpos = '/content/Piloto_Day_Trade/data/dados_limpos.csv'\n",
        "path_dados_transformados = '/content/Piloto_Day_Trade/data/dados_transformados.csv'\n",
        "df_transformado = transformar_dados(path_dados_limpos, path_dados_transformados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bG6Yqpyuawu",
        "outputId": "ee1d0943-f205-4bfc-d9f0-6332f499b06d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è O arquivo /content/Piloto_Day_Trade/data/dados_transformados.csv n√£o existe. Criando um novo DataFrame vazio.\n",
            "‚úÖ Arquivo /content/Piloto_Day_Trade/data/dados_limpos.csv carregado com 2462 linhas.\n",
            "üìÇ Nenhum dado transformado encontrado. Criando novo DataFrame.\n",
            "‚úÖ Indicadores calculados. Tamanho final do DataFrame: 2462 linhas.\n",
            "‚úÖ Dados transformados salvos em /content/Piloto_Day_Trade/data/dados_transformados.csv (2462 registros)\n",
            "üìÖ √öltima data dispon√≠vel nos dados: 2025-04-08 00:00:00\n",
            "df_final:         data      hora  abertura  minimo  maximo  fechamento  volume  \\\n",
            "0 2025-04-08  10:00:00     12.47   12.40   12.47       12.41  112000   \n",
            "1 2025-04-08  10:05:00     12.41   12.37   12.45       12.41  300500   \n",
            "2 2025-04-08  10:10:00     12.41   12.41   12.46       12.44  190600   \n",
            "3 2025-04-08  10:15:00     12.44   12.38   12.45       12.39  181600   \n",
            "4 2025-04-08  10:20:00     12.40   12.39   12.45       12.43  428200   \n",
            "\n",
            "    retorno  volatilidade  SMA_10  ...  volume_lag2  fechamento_lag3  \\\n",
            "0  0.000806      0.001881  12.379  ...     549700.0            12.35   \n",
            "1  0.000000      0.001881  12.384  ...    2188900.0            12.36   \n",
            "2  0.002417      0.001847  12.389  ...     112000.0            12.40   \n",
            "3 -0.004019      0.002050  12.390  ...     300500.0            12.41   \n",
            "4  0.003228      0.002153  12.397  ...     190600.0            12.41   \n",
            "\n",
            "   retorno_lag3  volume_lag3  dia_da_semana_entrada  data_previsao  \\\n",
            "0     -0.003228     402000.0                      1     2025-04-09   \n",
            "1      0.000810     549700.0                      1     2025-04-09   \n",
            "2      0.003236    2188900.0                      1     2025-04-09   \n",
            "3      0.000806     112000.0                      1     2025-04-09   \n",
            "4      0.000000     300500.0                      1     2025-04-09   \n",
            "\n",
            "   dia_da_semana_previsao  hora_num  minuto  mercado_aberto  \n",
            "0                       2        10       0               1  \n",
            "1                       2        10       5               1  \n",
            "2                       2        10      10               1  \n",
            "3                       2        10      15               1  \n",
            "4                       2        10      20               1  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformado = pd.read_csv('/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv')\n"
      ],
      "metadata": {
        "id": "6Kd2TDjqmGVo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformado.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4G3hB-sknn-j",
        "outputId": "ef53dacf-0902-4b34-d495-c0558a639583"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data                       object\n",
              "hora                       object\n",
              "abertura                  float64\n",
              "minimo                    float64\n",
              "maximo                    float64\n",
              "fechamento                float64\n",
              "volume                      int64\n",
              "retorno                   float64\n",
              "volatilidade              float64\n",
              "SMA_10                    float64\n",
              "EMA_10                    float64\n",
              "MACD                      float64\n",
              "Signal_Line               float64\n",
              "rsi                       float64\n",
              "OBV                       float64\n",
              "fechamento_lag1           float64\n",
              "retorno_lag1              float64\n",
              "volume_lag1               float64\n",
              "fechamento_lag2           float64\n",
              "retorno_lag2              float64\n",
              "volume_lag2               float64\n",
              "fechamento_lag3           float64\n",
              "retorno_lag3              float64\n",
              "volume_lag3               float64\n",
              "dia_da_semana_entrada       int64\n",
              "data_previsao              object\n",
              "dia_da_semana_previsao      int64\n",
              "hora_num                    int64\n",
              "minuto                      int64\n",
              "mercado_aberto              int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>data</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abertura</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minimo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maximo</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volatilidade</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMA_10</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MACD</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Signal_Line</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rsi</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBV</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag1</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag2</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fechamento_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retorno_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume_lag3</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_entrada</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_previsao</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dia_da_semana_previsao</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hora_num</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minuto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mercado_aberto</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Banco de dados"
      ],
      "metadata": {
        "id": "Ap-meZswIhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n",
        "\n",
        "#@title Defini√ß√£o do esquema - Modelo Estrela\n",
        "\n",
        "O modelo estrela foi escolhido por sua simplicidade e clareza na organiza√ß√£o dos dados para an√°lise. Ele √© ideal para consultas r√°pidas e an√°lise preditiva. No nosso projeto, temos um √∫nico fato (pre√ßos OHLC) e m√∫ltiplas vari√°veis explicativas que os influenciam.\n",
        "\n",
        "A estrutura facilita agrega√ß√µes temporais e an√°lises do comportamento dos pre√ßos, sendo tamb√©m eficiente para alimentar o pipeline de machine learning. Ao organizar as vari√°veis preditoras ao redor das medidas de pre√ßo, conseguimos isolar responsabilidades e tornar as an√°lises mais precisas e escal√°veis.\n",
        "\n",
        "## Tabela Fato: `fato_precos`\n",
        "| Coluna         | Tipo   | Descri√ß√£o                                   |\n",
        "|----------------|--------|---------------------------------------------|\n",
        "| id_fato_precos | int    | PK, identificador √∫nico da linha            |\n",
        "| id_tempo       | int    | FK para a dimens√£o tempo                    |\n",
        "| abertura       | float  | Pre√ßo de abertura                           |\n",
        "| minimo         | float  | Pre√ßo m√≠nimo                                |\n",
        "| maximo         | float  | Pre√ßo m√°ximo                                |\n",
        "| fechamento     | float  | Pre√ßo de fechamento (vari√°vel alvo)         |\n",
        "\n",
        "## Dimens√£o: `dim_tempo`\n",
        "| Coluna                | Tipo   | Descri√ß√£o                                 |\n",
        "|------------------------|--------|-------------------------------------------|\n",
        "| id_tempo              | int    | PK                                        |\n",
        "| data                  | object | Data da observa√ß√£o                        |\n",
        "| hora                  | object | Hora da observa√ß√£o                        |\n",
        "| dia_da_semana_entrada | int    | Dia da semana da entrada (0=Seg, 6=Dom)   |\n",
        "\n",
        "## Dimens√£o: `dim_indicadores`\n",
        "| Coluna       | Tipo   | Descri√ß√£o                                       |\n",
        "|--------------|--------|--------------------------------------------------|\n",
        "| id_indicadores | int  | PK                                               |\n",
        "| id_tempo     | int    | FK para a dimens√£o tempo                        |\n",
        "| SMA_10       | float  | M√©dia m√≥vel simples de 10 per√≠odos              |\n",
        "| EMA_10       | float  | M√©dia m√≥vel exponencial de 10 per√≠odos          |\n",
        "| MACD         | float  | Moving Average Convergence Divergence           |\n",
        "| Signal_Line  | float  | Linha de sinal do MACD                          |\n",
        "| rsi          | float  | √çndice de for√ßa relativa                        |\n",
        "| OBV          | float  | On-Balance Volume                               |\n",
        "| retorno      | float  | Retorno do per√≠odo                              |\n",
        "| volatilidade | float  | Volatilidade do per√≠odo                         |\n",
        "\n",
        "## Dimens√£o: `dim_lags`\n",
        "| Coluna          | Tipo   | Descri√ß√£o                                       |\n",
        "|-----------------|--------|--------------------------------------------------|\n",
        "| id_lags         | int    | PK                                              |\n",
        "| id_tempo        | int    | FK para a dimens√£o tempo                        |\n",
        "| fechamento_lag1 | float  | Fechamento no candle anterior (1 lag)          |\n",
        "| retorno_lag1    | float  | Retorno do candle anterior (1 lag)             |\n",
        "| volume_lag1     | float  | Volume do candle anterior (1 lag)              |\n",
        "| fechamento_lag2 | float  | Fechamento dois candles atr√°s (2 lags)         |\n",
        "| retorno_lag2    | float  | Retorno dois candles atr√°s (2 lags)            |\n",
        "| volume_lag2     | float  | Volume dois candles atr√°s (2 lags)             |\n",
        "| fechamento_lag3 | float  | Fechamento tr√™s candles atr√°s (3 lags)         |\n",
        "| retorno_lag3    | float  | Retorno tr√™s candles atr√°s (3 lags)            |\n",
        "| volume_lag3     | float  | Volume tr√™s candles atr√°s (3 lags)             |\n",
        "\n",
        "## Dimens√£o: `dim_operacional`\n",
        "| Coluna                 | Tipo   | Descri√ß√£o                                      |\n",
        "|------------------------|--------|------------------------------------------------|\n",
        "| id_operacional         | int    | PK                                             |\n",
        "| id_tempo               | int    | FK para a dimens√£o tempo                       |\n",
        "| data_previsao          | object | Data prevista para o modelo                    |\n",
        "| dia_da_semana_previsao | int    | Dia da semana da previs√£o                      |\n",
        "| hora_num               | int    | Hora como n√∫mero inteiro                       |\n",
        "| minuto                 | int    | Minuto da observa√ß√£o                           |\n",
        "| mercado_aberto         | int    | Indicador bin√°rio (1=aberto, 0=fechado)        |\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuxIPKOgzMvy",
        "outputId": "6c493aab-223f-4fc8-f248-537145addb5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/modelagem/definicao_esquema_estrela.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n",
        "\n",
        "#@title Script para gerar o cat√°logo de dados em conformidade com o enunciado\n",
        "\"\"\"\n",
        "Cat√°logo de Dados contendo minimamente uma descri√ß√£o detalhada dos dados e seus dom√≠nios,\n",
        "contendo valores m√≠nimos e m√°ximos esperados para dados num√©ricos, e poss√≠veis categorias para dados categ√≥ricos.\n",
        "\n",
        "Este modelo deve tamb√©m descrever a linhagem dos dados, de onde os mesmos foram baixados\n",
        "e qual t√©cnica foi utilizada para compor o conjunto de dados, caso haja.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Define colunas de cada tabela com tipos\n",
        "tabelas = {\n",
        "    \"fato_precos\": {\n",
        "        \"id_fato_precos\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"abertura\": \"float\",\n",
        "        \"minimo\": \"float\",\n",
        "        \"maximo\": \"float\",\n",
        "        \"fechamento\": \"float\"\n",
        "    },\n",
        "    \"dim_tempo\": {\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data\": \"object\",\n",
        "        \"hora\": \"object\",\n",
        "        \"dia_da_semana_entrada\": \"int\"\n",
        "    },\n",
        "    \"dim_indicadores\": {\n",
        "        \"id_indicadores\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"SMA_10\": \"float\",\n",
        "        \"EMA_10\": \"float\",\n",
        "        \"MACD\": \"float\",\n",
        "        \"Signal_Line\": \"float\",\n",
        "        \"rsi\": \"float\",\n",
        "        \"OBV\": \"float\",\n",
        "        \"retorno\": \"float\",\n",
        "        \"volatilidade\": \"float\"\n",
        "    },\n",
        "    \"dim_lags\": {\n",
        "        \"id_lags\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"fechamento_lag1\": \"float\",\n",
        "        \"retorno_lag1\": \"float\",\n",
        "        \"volume_lag1\": \"float\",\n",
        "        \"fechamento_lag2\": \"float\",\n",
        "        \"retorno_lag2\": \"float\",\n",
        "        \"volume_lag2\": \"float\",\n",
        "        \"fechamento_lag3\": \"float\",\n",
        "        \"retorno_lag3\": \"float\",\n",
        "        \"volume_lag3\": \"float\"\n",
        "    },\n",
        "    \"dim_operacional\": {\n",
        "        \"id_operacional\": \"int\",\n",
        "        \"id_tempo\": \"int\",\n",
        "        \"data_previsao\": \"object\",\n",
        "        \"dia_da_semana_previsao\": \"int\",\n",
        "        \"hora_num\": \"int\",\n",
        "        \"minuto\": \"int\",\n",
        "        \"mercado_aberto\": \"int\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def dominio(col, tipo):\n",
        "    if tipo in [\"float\", \"int\"]:\n",
        "        if \"retorno\" in col:\n",
        "            return \"-0.05 a 0.05 (retorno percentual por intervalo de 5 min)\"\n",
        "        elif \"volatilidade\" in col:\n",
        "            return \"0 a 0.1 (desvio padr√£o do retorno por janela de tempo)\"\n",
        "        elif \"abertura\" in col or \"fechamento\" in col or \"minimo\" in col or \"maximo\" in col:\n",
        "            return \"10.0 a 50.0 (valores t√≠picos para BBDC4)\"\n",
        "        elif \"MACD\" in col or \"Signal\" in col:\n",
        "            return \"-5 a 5\"\n",
        "        elif \"rsi\" in col:\n",
        "            return \"0 a 100\"\n",
        "        elif \"OBV\" in col:\n",
        "            return \"valor acumulativo, depende do ativo\"\n",
        "        elif \"volume\" in col:\n",
        "            return \"0 a 1.000.000 (valores inteiros positivos)\"\n",
        "        elif \"dia_da_semana\" in col:\n",
        "            return \"0=Segunda, ..., 6=Domingo\"\n",
        "        elif \"mercado_aberto\" in col:\n",
        "            return \"0=Fechado, 1=Aberto\"\n",
        "        else:\n",
        "            return \"valores num√©ricos cont√≠nuos\"\n",
        "    elif tipo == \"object\":\n",
        "        if \"data\" in col:\n",
        "            return \"formato YYYY-MM-DD\"\n",
        "        elif \"hora\" in col:\n",
        "            return \"formato HH:MM:SS\"\n",
        "        else:\n",
        "            return \"texto livre\"\n",
        "    return \"n√£o especificado\"\n",
        "\n",
        "def descricao(col):\n",
        "    descricoes = {\n",
        "        \"abertura\": \"Pre√ßo de abertura do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"minimo\": \"Menor pre√ßo do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"maximo\": \"Maior pre√ßo do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"fechamento\": \"Pre√ßo de fechamento do ativo BBDC4 no intervalo de 5 minutos\",\n",
        "        \"retorno\": \"Retorno percentual do ativo no intervalo de 5 minutos\",\n",
        "        \"volatilidade\": \"Volatilidade dos retornos do ativo em janela deslizante\",\n",
        "        \"SMA_10\": \"M√©dia m√≥vel simples de 10 per√≠odos calculada sobre os pre√ßos\",\n",
        "        \"EMA_10\": \"M√©dia m√≥vel exponencial de 10 per√≠odos\",\n",
        "        \"MACD\": \"Moving Average Convergence Divergence, indicador t√©cnico\",\n",
        "        \"Signal_Line\": \"Linha de sinal do MACD\",\n",
        "        \"rsi\": \"√çndice de for√ßa relativa (RSI), oscilador t√©cnico\",\n",
        "        \"OBV\": \"On Balance Volume, indicador t√©cnico baseado em volume\",\n",
        "        \"hora_num\": \"Hora expressa como n√∫mero inteiro\",\n",
        "        \"minuto\": \"Minuto do intervalo de tempo\",\n",
        "        \"mercado_aberto\": \"Indica se o mercado est√° aberto no hor√°rio (1) ou n√£o (0)\"\n",
        "    }\n",
        "    for key in descricoes:\n",
        "        if key in col:\n",
        "            return descricoes[key]\n",
        "    if \"lag\" in col:\n",
        "        return f\"Valor defasado de {col.replace('_lag', '')}\"\n",
        "    if \"dia_da_semana\" in col:\n",
        "        return \"Dia da semana correspondente √† data\"\n",
        "    if \"id_\" in col:\n",
        "        return \"Identificador √∫nico para relacionar com outras tabelas\"\n",
        "    return \"\"\n",
        "\n",
        "def tecnica(col):\n",
        "    if any(ind in col for ind in [\"SMA\", \"EMA\", \"MACD\", \"Signal\", \"rsi\", \"OBV\"]):\n",
        "        return \"calculado internamente via engenharia de features t√©cnicas\"\n",
        "    if \"lag\" in col:\n",
        "        return \"calculado como valor defasado (lag)\"\n",
        "    if col in [\"data\", \"hora\", \"hora_num\", \"minuto\", \"dia_da_semana_entrada\", \"dia_da_semana_previsao\"]:\n",
        "        return \"extra√≠do de data/hora original\"\n",
        "    if col == \"mercado_aberto\":\n",
        "        return \"derivado da data/hora com base em calend√°rio de mercado\"\n",
        "    return \"c√≥pia ou identificador\"\n",
        "\n",
        "linhagem = \"Fonte: Yahoo Finance via yfinance\"\n",
        "\n",
        "linhas = []\n",
        "for tabela, colunas in tabelas.items():\n",
        "    for col, tipo in colunas.items():\n",
        "        linhas.append({\n",
        "            \"tabela\": tabela,\n",
        "            \"coluna\": col,\n",
        "            \"tipo\": tipo,\n",
        "            \"descricao\": descricao(col),\n",
        "            \"dominio\": dominio(col, tipo),\n",
        "            \"tecnica\": tecnica(col),\n",
        "            \"linhagem\": linhagem\n",
        "        })\n",
        "\n",
        "catalogo_df = pd.DataFrame(linhas)\n",
        "catalogo_df.to_csv(\"/content/Piloto_Day_Trade/modelagem/catalogo_dados.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gn9fb5M4S1f",
        "outputId": "cdf9732e-333d-44a2-b405-f704aafd38fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar a gera√ß√£o do Catalogo de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/gerar_catalogo_dados.py\n"
      ],
      "metadata": {
        "id": "o6QQCeAF1qvO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Gerando cat√°logo de dados\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC29xOqV95Z_",
        "outputId": "ee527f26-2082-4287-938b-1a24c9508252"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main ee1cc32] commit_message\n",
            " 3 files changed, 210 insertions(+), 82 deletions(-)\n",
            " create mode 100644 modelagem/catalogo_dados.csv\n",
            " rewrite scripts/gerar_catalogo_dados.py (99%)\n",
            "Enumerating objects: 12, done.\n",
            "Counting objects: 100% (12/12), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (7/7), done.\n",
            "Writing objects: 100% (7/7), 3.74 KiB | 3.74 MiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/CarolBw/Piloto_Day_Trade.git\n",
            "   9414dd9..ee1cc32  main -> main\n",
            "‚úÖ Atualiza√ß√£o do reposit√≥rio conclu√≠da!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n",
        "\n",
        "# @title Script para criar banco de dados e tabelas\n",
        "\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
        "\n",
        "# Conecta ao banco (cria se n√£o existir)\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Comandos SQL para criar as tabelas\n",
        "sql_script = \"\"\"\n",
        "-- Cria√ß√£o da Tabela Fato\n",
        "CREATE TABLE IF NOT EXISTS fato_precos (\n",
        "    id_fato_precos INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    abertura REAL,\n",
        "    minimo REAL,\n",
        "    maximo REAL,\n",
        "    fechamento REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Tempo\n",
        "CREATE TABLE IF NOT EXISTS dim_tempo (\n",
        "    id_tempo INTEGER PRIMARY KEY,\n",
        "    data TEXT,\n",
        "    hora TEXT,\n",
        "    dia_da_semana_entrada INTEGER\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Indicadores T√©cnicos\n",
        "CREATE TABLE IF NOT EXISTS dim_indicadores (\n",
        "    id_indicadores INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    SMA_10 REAL,\n",
        "    EMA_10 REAL,\n",
        "    MACD REAL,\n",
        "    Signal_Line REAL,\n",
        "    rsi REAL,\n",
        "    OBV REAL,\n",
        "    retorno REAL,\n",
        "    volatilidade REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Lags\n",
        "CREATE TABLE IF NOT EXISTS dim_lags (\n",
        "    id_lags INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    fechamento_lag1 REAL,\n",
        "    retorno_lag1 REAL,\n",
        "    volume_lag1 REAL,\n",
        "    fechamento_lag2 REAL,\n",
        "    retorno_lag2 REAL,\n",
        "    volume_lag2 REAL,\n",
        "    fechamento_lag3 REAL,\n",
        "    retorno_lag3 REAL,\n",
        "    volume_lag3 REAL,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\n",
        "-- Cria√ß√£o da Dimens√£o Operacional\n",
        "CREATE TABLE IF NOT EXISTS dim_operacional (\n",
        "    id_operacional INTEGER PRIMARY KEY,\n",
        "    id_tempo INTEGER,\n",
        "    data_previsao TEXT,\n",
        "    dia_da_semana_previsao INTEGER,\n",
        "    hora_num INTEGER,\n",
        "    minuto INTEGER,\n",
        "    mercado_aberto INTEGER,\n",
        "    FOREIGN KEY (id_tempo) REFERENCES dim_tempo(id_tempo)\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Executa o script SQL\n",
        "cursor.executescript(sql_script)\n",
        "\n",
        "# Confirma e fecha\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"‚úÖ Banco e tabelas criados com sucesso.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OxeXvgYa_jC",
        "outputId": "5f623698-75fd-4bed-dfe2-7e1d97bdcc2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Excecutar criar banco e tabelas\n",
        "!python /content/Piloto_Day_Trade/scripts/criar_banco_dimensional.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGaGzrS1AQcj",
        "outputId": "9d189948-b43f-466a-e003-2f13bec77345"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Banco e tabelas criados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar cria√ß√£o do banco\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsDCNhgeA2WU",
        "outputId": "3c514f31-e0c9-47e3-a8ea-7ff57b243d2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('fato_precos',), ('dim_tempo',), ('dim_indicadores',), ('dim_lags',), ('dim_operacional',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"PRAGMA table_info(dim_tempo);\")\n",
        "print(cursor.fetchall())\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM7plBnSFNHp",
        "outputId": "2dbcf17c-119f-418c-fd9f-ba705800474c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'id_tempo', 'INTEGER', 0, None, 1), (1, 'data', 'TEXT', 0, None, 0), (2, 'hora', 'TEXT', 0, None, 0), (3, 'dia_da_semana_entrada', 'INTEGER', 0, None, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Definindo script de carga de dados\n",
        "\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/carga_dados.py\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Caminho para o banco de dados\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "assert os.path.exists(db_path), f\"Banco de dados n√£o encontrado em {db_path}\"\n",
        "# Leitura dos dados a serem carregados\n",
        "df = pd.read_csv(\"/content/Piloto_Day_Trade/data/transformed/dados_transformados.csv\")\n",
        "\n",
        "# Fun√ß√£o para carregar dados\n",
        "def carregar_dados(df: pd.DataFrame):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        id_tempo = idx + 1\n",
        "\n",
        "        # 1. Inserir na dim_tempo\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_tempo (id_tempo, data, hora, dia_da_semana_entrada)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, row['data'], row['hora'], row['dia_da_semana_entrada']))\n",
        "\n",
        "        # 2. Inserir na dim_indicadores\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_indicadores (id_indicadores, id_tempo, SMA_10, EMA_10, MACD, Signal_Line, rsi, OBV, retorno, volatilidade)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['SMA_10'], row['EMA_10'], row['MACD'], row['Signal_Line'], row['rsi'],\n",
        "              row['OBV'], row['retorno'], row['volatilidade']))\n",
        "\n",
        "        # 3. Inserir na dim_lags\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_lags (id_lags, id_tempo, fechamento_lag1, retorno_lag1, volume_lag1,\n",
        "                                  fechamento_lag2, retorno_lag2, volume_lag2,\n",
        "                                  fechamento_lag3, retorno_lag3, volume_lag3)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo,\n",
        "              row['fechamento_lag1'], row['retorno_lag1'], row['volume_lag1'],\n",
        "              row['fechamento_lag2'], row['retorno_lag2'], row['volume_lag2'],\n",
        "              row['fechamento_lag3'], row['retorno_lag3'], row['volume_lag3']))\n",
        "\n",
        "        # 4. Inserir na dim_operacional\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO dim_operacional (id_operacional, id_tempo, data_previsao, dia_da_semana_previsao, hora_num, minuto, mercado_aberto)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['data_previsao'], row['dia_da_semana_previsao'],\n",
        "              row['hora_num'], row['minuto'], row['mercado_aberto']))\n",
        "\n",
        "        # 5. Inserir na fato_precos\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO fato_precos (id_fato_precos, id_tempo, abertura, minimo, maximo, fechamento)\n",
        "            VALUES (?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (id_tempo, id_tempo, row['abertura'], row['minimo'], row['maximo'], row['fechamento']))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(f\"‚úÖ Carga conclu√≠da com {len(df)} registros.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    carregar_dados(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "injpAahyCCxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215a6e3b-f062-4ff2-d3f3-cf39befc5dd8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Executar realizar a carga de dados\n",
        "!python /content/Piloto_Day_Trade/scripts/carga_dados.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zidwW0A7DfMa",
        "outputId": "91ac8d63-64f6-46eb-c330-911ac693d3dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Carga conclu√≠da com 2462 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando a carga de dados\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "# Caminho para o banco\n",
        "db_path = \"/content/Piloto_Day_Trade/modelagem/database/banco_dimensional.db\"\n",
        "\n",
        "# Conex√£o e cursor\n",
        "conn = sqlite3.connect(db_path)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Consulta nas tabelas principais\n",
        "tabelas = ['dim_tempo', 'dim_indicadores', 'dim_lags', 'dim_operacional', 'fato_precos']\n",
        "for tabela in tabelas:\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM {tabela}\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"{tabela}: {count} registros\")\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksO0iYGrEEXF",
        "outputId": "c6b76fd8-c9f1-4c62-9e4b-9525933d93b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîé dim_tempo: 2462 registros\n",
            "üîé dim_indicadores: 2462 registros\n",
            "üîé dim_lags: 2462 registros\n",
            "üîé dim_operacional: 2462 registros\n",
            "üîé fato_precos: 2462 registros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os primeiros 5 registros da fato_precos\n",
        "import pandas as pd\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_check = pd.read_sql_query(\"SELECT * FROM fato_precos LIMIT 5\", conn)\n",
        "print(df_check)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0OFgWADGalR",
        "outputId": "36a76a27-cbb6-4e5e-ea36-0c497306894b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos  id_tempo  abertura  minimo  maximo  fechamento\n",
            "0               1         1     12.47   12.40   12.47       12.41\n",
            "1               2         2     12.41   12.37   12.45       12.41\n",
            "2               3         3     12.41   12.41   12.46       12.44\n",
            "3               4         4     12.44   12.38   12.45       12.39\n",
            "4               5         5     12.40   12.39   12.45       12.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consulta com JOIN para verificar o relacionamento entre as tabelas\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    ft.id_fato_precos,\n",
        "    dt.data,\n",
        "    dt.hora,\n",
        "    ft.abertura,\n",
        "    ft.fechamento,\n",
        "    di.SMA_10,\n",
        "    dl.fechamento_lag1,\n",
        "    do.data_previsao,\n",
        "    do.mercado_aberto\n",
        "FROM fato_precos ft\n",
        "JOIN dim_tempo dt ON ft.id_tempo = dt.id_tempo\n",
        "JOIN dim_indicadores di ON ft.id_tempo = di.id_tempo\n",
        "JOIN dim_lags dl ON ft.id_tempo = dl.id_tempo\n",
        "JOIN dim_operacional do ON ft.id_tempo = do.id_tempo\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "# Executando e exibindo\n",
        "conn = sqlite3.connect(db_path)\n",
        "df_verificacao = pd.read_sql_query(query, conn)\n",
        "print(df_verificacao)\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrrqdeR8Gq1p",
        "outputId": "768edc94-01ef-4b96-ca98-e923e669eaf2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id_fato_precos        data      hora  abertura  fechamento  SMA_10  \\\n",
            "0               1  2025-04-08  10:00:00     12.47       12.41  12.379   \n",
            "1               2  2025-04-08  10:05:00     12.41       12.41  12.384   \n",
            "2               3  2025-04-08  10:10:00     12.41       12.44  12.389   \n",
            "3               4  2025-04-08  10:15:00     12.44       12.39  12.390   \n",
            "4               5  2025-04-08  10:20:00     12.40       12.43  12.397   \n",
            "\n",
            "   fechamento_lag1 data_previsao  mercado_aberto  \n",
            "0            12.40    2025-04-09               1  \n",
            "1            12.41    2025-04-09               1  \n",
            "2            12.41    2025-04-09               1  \n",
            "3            12.44    2025-04-09               1  \n",
            "4            12.39    2025-04-09               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem de dados"
      ],
      "metadata": {
        "id": "ai-nFsCPCE4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Prepara√ß√£o de dados para LSTM\n",
        "%%writefile /content/Piloto_Day_Trade/scripts/preparar_dados_modelagem_LSTM.py\n",
        "\n",
        "\"\"\"\n",
        "Fun√ß√£o que prepara os dados transformados para modelagem com LSTM:\n",
        "- Aplica normaliza√ß√£o e padroniza√ß√£o\n",
        "- Cria sequ√™ncias de entrada e sa√≠da\n",
        "- Divide em treino e teste\n",
        "- Salva o scaler de pre√ßo para uso posterior nas previs√µes\n",
        "\n",
        "Retorna:\n",
        "    X_treino, X_teste, y_treino, y_teste: arrays prontos para modelagem LSTM\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "def preparar_dados_lstm(\n",
        "    path_dados,       # Caminho do CSV com os dados\n",
        "    tam_seq=32,       # Tamanho da sequ√™ncia para entrada na LSTM\n",
        "    tx_treino=0.8     # Propor√ß√£o dos dados para treino\n",
        "):\n",
        "    # Caminho do scaler\n",
        "    caminho_scaler_preco = '/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'\n",
        "\n",
        "    # Criar diret√≥rio do scaler se n√£o existir\n",
        "    os.makedirs(os.path.dirname(caminho_scaler_preco), exist_ok=True)\n",
        "\n",
        "    # Carregar dados transformados\n",
        "    df = pd.read_csv(path_dados)\n",
        "\n",
        "    # Garantir colunas de data como datetime\n",
        "    df['data'] = pd.to_datetime(df['data'], errors='coerce')\n",
        "    df['data_previsao'] = pd.to_datetime(df['data_previsao'], errors='coerce')\n",
        "\n",
        "    # Definir colunas de pre√ßo\n",
        "    preco_cols = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Garantir que n√£o h√° valores ausentes nos pre√ßos\n",
        "    df = df.dropna(subset=preco_cols)\n",
        "\n",
        "    # Salvar scaler de pre√ßo com base nos valores reais (antes da normaliza√ß√£o)\n",
        "    scaler_preco = MinMaxScaler()\n",
        "    scaler_preco.fit(df[preco_cols])\n",
        "    joblib.dump(scaler_preco, caminho_scaler_preco)\n",
        "\n",
        "    print(\"Scaler de pre√ßo salvo com sucesso.\")\n",
        "\n",
        "    # Definir colunas para padroniza√ß√£o e normaliza√ß√£o\n",
        "    padronizar_cols = ['retorno', 'volatilidade', 'MACD', 'Signal_Line', 'rsi']\n",
        "    normalizar_cols = ['abertura', 'minimo', 'maximo', 'fechamento', 'volume', 'SMA_10', 'EMA_10', 'OBV',\n",
        "                       'fechamento_lag1', 'retorno_lag1', 'volume_lag1',\n",
        "                       'fechamento_lag2', 'retorno_lag2', 'volume_lag2',\n",
        "                       'fechamento_lag3', 'retorno_lag3', 'volume_lag3']\n",
        "\n",
        "    # Inicializar scalers\n",
        "    scaler_standard = StandardScaler()\n",
        "    scaler_minmax = MinMaxScaler()\n",
        "\n",
        "    # Aplicar transforma√ß√µes\n",
        "    df[padronizar_cols] = scaler_standard.fit_transform(df[padronizar_cols])\n",
        "    df[normalizar_cols] = scaler_minmax.fit_transform(df[normalizar_cols])\n",
        "\n",
        "    # Converter colunas categ√≥ricas para int\n",
        "    categorias = ['dia_da_semana_entrada', 'dia_da_semana_previsao', 'hora_num', 'minuto', 'mercado_aberto']\n",
        "    df[categorias] = df[categorias].astype(int)\n",
        "\n",
        "    # Manter apenas colunas num√©ricas\n",
        "    df = df.select_dtypes(include=['number'])\n",
        "\n",
        "    # Fun√ß√£o para criar sequ√™ncias\n",
        "    def criar_sequencias(dados, tam_seq):\n",
        "        entradas, saidas = [], []\n",
        "        for i in range(len(dados) - tam_seq - 1):\n",
        "            entradas.append(dados.iloc[i:i+tam_seq].values)\n",
        "            saidas.append(dados.iloc[i+1:i+1+tam_seq][['abertura', 'maximo', 'minimo', 'fechamento']].values)\n",
        "        return np.array(entradas), np.array(saidas)\n",
        "\n",
        "    # Gerar X e y\n",
        "    X, y = criar_sequencias(df, tam_seq)\n",
        "\n",
        "    # Dividir entre treino e teste\n",
        "    tamanho_treino = int(tx_treino * len(X))\n",
        "    X_treino, X_teste = X[:tamanho_treino], X[tamanho_treino:]\n",
        "    y_treino, y_teste = y[:tamanho_treino], y[tamanho_treino:]\n",
        "\n",
        "    return X_treino, X_teste, y_treino, y_teste\n",
        "\n",
        "\n",
        "# Execu√ß√£o direta\n",
        "if __name__ == \"__main__\":\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/dados_transformados.csv'\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUTR1S1f9y-f",
        "outputId": "52e582dd-c7e4-42ba-d1ff-d47f5bccf8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/preparar_dados_modelagem_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Piloto_Day_Trade.scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "\n",
        "path_dados = '/content/Piloto_Day_Trade/data/dados_transformados.csv'\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "    path_dados=path_dados,\n",
        "    tam_seq=96,\n",
        "    tx_treino=0.8\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9h6GHiRyiRI",
        "outputId": "f5b9ed71-4d4a-4cfb-eb3c-1b69e5508562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de pre√ßo salvo com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Criar e treinar o modelo LSTM (Movimenta√ß√£o Intradi√°ria)\n",
        "# %%writefile /content/Piloto_Day_Trade/scripts/modelo_LSTM_v1.py\n",
        "\n",
        "# Tentativa inicial - Modelo base LSTM para previs√£o intradi√°ria de pre√ßos\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# üîß Constru√ß√£o do modelo\n",
        "LSTM_model = Sequential([\n",
        "\n",
        "    # Camada LSTM 1:\n",
        "    # - 100 unidades (aumentado para maior capacidade de captura de padr√µes temporais)\n",
        "    # - return_sequences=True para passar a sequ√™ncia completa para a pr√≥xima camada\n",
        "    # - input_shape: (32, n√∫mero de features) - sequ√™ncia de 32 timesteps com n features\n",
        "    LSTM(100, return_sequences=True, input_shape=(X_treino.shape[1], X_treino.shape[2])),\n",
        "\n",
        "    # Dropout leve para reduzir overfitting sem perder muito sinal\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada LSTM 2:\n",
        "    # - Outra LSTM com 100 unidades\n",
        "    # - Tamb√©m retorna sequ√™ncia, pois a sa√≠da √© uma sequ√™ncia (32 timestamps com 4 pre√ßos)\n",
        "    LSTM(100, return_sequences=True),\n",
        "\n",
        "    # Outro Dropout leve\n",
        "    Dropout(0.1),\n",
        "\n",
        "    # Camada densa intermedi√°ria:\n",
        "    # - 64 neur√¥nios com ativa√ß√£o ReLU\n",
        "    # - Introduz n√£o-linearidade e ajuda a refinar a sa√≠da da LSTM antes da previs√£o final\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    # Camada de sa√≠da:\n",
        "    # - 4 unidades: prevendo abertura, m√°xima, m√≠nima e fechamento por timestamp\n",
        "    # - Sem ativa√ß√£o, sa√≠da cont√≠nua (valores de pre√ßos normalizados)\n",
        "    Dense(4)\n",
        "])\n",
        "\n",
        "# üß† Compila√ß√£o do modelo\n",
        "# - Otimizador Adam, bom para problemas n√£o estacion√°rios como s√©ries temporais\n",
        "# - Fun√ß√£o de perda MSE (erro quadr√°tico m√©dio), apropriado para regress√£o\n",
        "LSTM_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# üöÇ Treinamento do modelo\n",
        "# - 20 √©pocas: n√∫mero inicial para observar o desempenho\n",
        "# - batch_size=16: menor para atualizar pesos com frequ√™ncia e lidar com varia√ß√£o dos dados\n",
        "historico = LSTM_model.fit(\n",
        "    X_treino, y_treino,\n",
        "    validation_data=(X_teste, y_teste),\n",
        "    epochs=20,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6lFmK-FMncY",
        "outputId": "692735ea-49a2-4e23-eb57-967dd4e71589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - loss: 0.0929 - val_loss: 0.0077\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 0.0071 - val_loss: 0.0058\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 115ms/step - loss: 0.0039 - val_loss: 0.0042\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - loss: 0.0027 - val_loss: 0.0030\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - loss: 0.0016 - val_loss: 0.0040\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - loss: 0.0014 - val_loss: 0.0037\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - loss: 0.0012 - val_loss: 0.0027\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 9.8270e-04 - val_loss: 0.0021\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 9.2042e-04 - val_loss: 0.0020\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - loss: 8.3374e-04 - val_loss: 0.0016\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - loss: 8.1964e-04 - val_loss: 0.0014\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 7.5165e-04 - val_loss: 0.0015\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 7.2952e-04 - val_loss: 0.0015\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 7.0647e-04 - val_loss: 0.0015\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 107ms/step - loss: 6.4967e-04 - val_loss: 0.0016\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 6.9854e-04 - val_loss: 0.0018\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 6.4292e-04 - val_loss: 0.0016\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 106ms/step - loss: 6.6786e-04 - val_loss: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Salvar LSTM versao 1\n",
        "# Criar diret√≥rio para modelos, se n√£o existir\n",
        "import os\n",
        "path_modelo = '/content/Piloto_Day_Trade/models/LSTM_v1'\n",
        "os.makedirs(path_modelo, exist_ok=True)\n",
        "\n",
        "# Salvar o modelo completo (estrutura + pesos + otimizador)\n",
        "LSTM_model.save(f'{path_modelo}/modelo_completo.keras')\n",
        "\n",
        "print(\"‚úÖ Modelo LSTM_v1 salvo com sucesso!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSGaNfmtKwU6",
        "outputId": "752aaed1-32d8-425c-c179-cd9d23804d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo LSTM_v1 salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n",
        "\n",
        "#@title Calcular m√©tricas e avaliar modelo LSTM\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def avaliar_modelo_lstm(modelo, X_teste, y_teste, caminho_scaler='/content/Piloto_Day_Trade/models/scalers/scaler_normalizacao_preco.pkl'):\n",
        "    \"\"\"\n",
        "    Avalia um modelo LSTM fornecido, imprimindo as principais m√©tricas e compara√ß√£o entre previs√µes e valores reais.\n",
        "\n",
        "    Par√¢metros:\n",
        "        modelo: modelo LSTM treinado\n",
        "        X_teste: dados de entrada de teste\n",
        "        y_teste: dados reais (targets) correspondentes ao teste\n",
        "        caminho_scaler: caminho do scaler salvo para invers√£o da normaliza√ß√£o\n",
        "    \"\"\"\n",
        "\n",
        "    # Fazer previs√µes\n",
        "    y_previsto = modelo.predict(X_teste)\n",
        "\n",
        "    # Carregar o scaler de pre√ßos\n",
        "    scaler_precos = joblib.load(caminho_scaler)\n",
        "\n",
        "    # Colunas de pre√ßo\n",
        "    colunas_precos = ['abertura', 'maximo', 'minimo', 'fechamento']\n",
        "\n",
        "    # Redimensionar para (amostras, 4)\n",
        "    y_previsto_reshape = y_previsto.reshape(-1, 4)\n",
        "    y_teste_reshape = y_teste.reshape(-1, 4)\n",
        "\n",
        "    # Inverter normaliza√ß√£o\n",
        "    y_previsto_original = scaler_precos.inverse_transform(y_previsto_reshape)\n",
        "    y_teste_original = scaler_precos.inverse_transform(y_teste_reshape)\n",
        "\n",
        "    # DataFrames nomeados\n",
        "    df_previsto = pd.DataFrame(y_previsto_original, columns=colunas_precos)\n",
        "    df_real = pd.DataFrame(y_teste_original, columns=colunas_precos)\n",
        "\n",
        "    # Compara√ß√£o\n",
        "    comparacao = pd.DataFrame({\n",
        "        'Abertura_Real': df_real['abertura'],\n",
        "        'Abertura_Prevista': df_previsto['abertura'],\n",
        "        'Maximo_Real': df_real['maximo'],\n",
        "        'Maximo_Previsto': df_previsto['maximo'],\n",
        "        'Minimo_Real': df_real['minimo'],\n",
        "        'Minimo_Previsto': df_previsto['minimo'],\n",
        "        'Fechamento_Real': df_real['fechamento'],\n",
        "        'Fechamento_Previsto': df_previsto['fechamento']\n",
        "    })\n",
        "\n",
        "    print(\"\\nüìä Compara√ß√£o de previs√µes (valores reais):\")\n",
        "    print(comparacao.head(10))\n",
        "\n",
        "    # Fun√ß√£o auxiliar para m√©tricas\n",
        "    def calcular_metricas(y_real, y_previsto, nome):\n",
        "        mae = mean_absolute_error(y_real, y_previsto)\n",
        "        mse = mean_squared_error(y_real, y_previsto)\n",
        "        r2 = r2_score(y_real, y_previsto)\n",
        "        print(f\"{nome} - MAE: {mae:.4f}, MSE: {mse:.4f}, R¬≤: {r2:.4f}\")\n",
        "\n",
        "    print(\"\\nüìà M√©tricas de desempenho por coluna:\")\n",
        "    calcular_metricas(df_real['abertura'], df_previsto['abertura'], \"Abertura\")\n",
        "    calcular_metricas(df_real['maximo'], df_previsto['maximo'], \"M√°ximo\")\n",
        "    calcular_metricas(df_real['minimo'], df_previsto['minimo'], \"M√≠nimo\")\n",
        "    calcular_metricas(df_real['fechamento'], df_previsto['fechamento'], \"Fechamento\")\n",
        "\n",
        "    return df_real, df_previsto, comparacao\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FOx4USVH-3l",
        "outputId": "0795aeaf-e2f6-4699-ed84-be2b3ad9d801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Piloto_Day_Trade/scripts/calcular_metricas_avaliar_modelo_LSTM.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.calcular_metricas_avaliar_modelo import avaliar_modelo_lstm\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Caminhos e dados preparados\n",
        "    path_dados = '/content/Piloto_Day_Trade/data/dados_transformados.csv'\n",
        "\n",
        "    # Preparar dados\n",
        "    from scripts.preparar_dados_modelagem_LSTM import preparar_dados_lstm\n",
        "    X_treino, X_teste, y_treino, y_teste = preparar_dados_lstm(\n",
        "        path_dados=path_dados,\n",
        "        tam_seq=96,\n",
        "        tx_treino=0.8\n",
        "    )\n",
        "\n",
        "    # Carregar o modelo treinado\n",
        "    from tensorflow.keras.models import load_model\n",
        "    LSTM_model = load_model('/content/Piloto_Day_Trade/models/LSTM_v1')\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    df_real, df_previsto, comparacao = avaliar_modelo_lstm(\n",
        "        modelo=LSTM_model,\n",
        "        X_teste=X_teste,\n",
        "        y_teste=y_teste\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "QigGTL3DWGTb",
        "outputId": "c290db5c-fe10-4a31-b709-86a95314c6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler de pre√ßo salvo com sucesso.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/content/Piloto_Day_Trade/models/LSTM_v1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d7b806b1831c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Carregar o modelo treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mLSTM_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Piloto_Day_Trade/models/LSTM_v1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Avaliar o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/content/Piloto_Day_Trade/models/LSTM_v1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "atualizar_repo(\"Incluindo Etapa de Modelagem\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9c5GpDp92un",
        "outputId": "d1284e4b-875d-4d15-f5e5-f9943d57300a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main b016487] commit_message\n",
            " 2 files changed, 67 insertions(+), 54 deletions(-)\n",
            " create mode 100644 models/LSTM_v1/modelo_completo.keras\n",
            " rewrite scripts/calcular_metricas_avaliar_modelo.py (92%)\n",
            "Enumerating objects: 11, done.\n",
            "Counting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (7/7), 1.49 MiB | 2.68 MiB/s, done.\n",
            "Total 7 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/CarolBw/Piloto_Day_Trade.git\n",
            "   ea2d149..b016487  main -> main\n",
            "‚úÖ Atualiza√ß√£o do reposit√≥rio conclu√≠da!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ### Transformer para Capturar Tend√™ncias de Longo Prazo:\n",
        "\n",
        "\"\"\"\n",
        "Entrada: √öltimos dias √∫teis para identificar padr√µes de pre√ßo.\n",
        "\n",
        "Sa√≠da: Pre√ßos de abertura, m√°xima, m√≠nima e fechamento do pr√≥ximo dia √∫til.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7oG7QwBtKqT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}