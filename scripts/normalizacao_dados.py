
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import os
import joblib
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

def normalizar_dados(arquivo):
    """
    Carrega os dados de um arquivo CSV, aplica normaliza√ß√£o e padroniza√ß√£o,
    e salva os scalers usados.
    """
    # Carregar dados
    if isinstance(arquivo, pd.DataFrame):
        df = arquivo  # Se j√° for um DataFrame, usa diretamente
    elif not os.path.exists(arquivo):
        print(f"‚ö†Ô∏è O arquivo {arquivo} n√£o existe. Criando um novo DataFrame vazio.")
        return pd.DataFrame()
    else:
        try:
            df = pd.read_csv(arquivo, parse_dates=["data"])
            print(f"‚úÖ Arquivo {arquivo} carregado com {len(df)} linhas.")
        except Exception as e:
            print(f"‚ùå Erro ao carregar {arquivo}: {e}")
            return pd.DataFrame()
    
    if df.empty:
        print("‚ö†Ô∏è DataFrame vazio. Nenhuma normaliza√ß√£o aplicada.")
        return df
    
    # Inicializar scalers
    scaler_padronizacao = StandardScaler()
    scaler_normalizacao = MinMaxScaler()
    
    # Colunas a serem padronizadas (m√©dia 0, desvio padr√£o 1)
    padronizar_cols = ['retorno', 'volatilidade', 'MACD', 'Signal_Line', 'rsi']
    df[padronizar_cols] = scaler_padronizacao.fit_transform(df[padronizar_cols])
    
    # Colunas a serem normalizadas (escala entre 0 e 1)
    normalizar_cols = ['abertura', 'minimo', 'maximo', 'fechamento', 'volume', 'SMA_10', 'EMA_10', 'OBV',
                       'fechamento_lag1', 'retorno_lag1', 'volume_lag1',
                       'fechamento_lag2', 'retorno_lag2', 'volume_lag2',
                       'fechamento_lag3', 'retorno_lag3', 'volume_lag3']
    df[normalizar_cols] = scaler_normalizacao.fit_transform(df[normalizar_cols])
    
    # Vari√°veis categ√≥ricas (convertidas para inteiro)
    categoricas = ['dia_da_semana_entrada', 'dia_da_semana_previsao', 'hora_num', 'minuto', 'mercado_aberto']
    df[categoricas] = df[categoricas].astype(int)
    
    # Converter datas para formato adequado
    df['data_previsao'] = pd.to_datetime(df['data_previsao'])
    df['data'] = pd.to_datetime(df['data'])

    # Salvar scaler espec√≠fico para colunas de pre√ßo
    preco_cols = ['abertura', 'maximo', 'minimo', 'fechamento']
    scaler_preco = MinMaxScaler()
    scaler_preco.fit(df[preco_cols])

    # Criar pasta de scalers se n√£o existir
    os.makedirs("/content/Piloto_Day_Trade/scalers", exist_ok=True)
    joblib.dump(scaler_preco, "/content/Piloto_Day_Trade/scalers/scaler_normalizacao_preco.pkl")


    print("üíæ Scalers salvos com sucesso.")

    print(f"‚úÖ Dataset normalizado e padronizado salvo com sucesso:")
    print(df.head(5))

    return df

if __name__ == "__main__":    
    dados_transformados = "/content/Piloto_Day_Trade/data/dados_transformados15.csv"    
    df_normalizado = normalizar_dados(dados_transformados)
    dados_normalizados = "/content/Piloto_Day_Trade/data/dados_normalizados15.csv"
    df_normalizado.to_csv(dados_normalizados, index=False)
